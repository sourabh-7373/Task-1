interactions:
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - api.semanticscholar.org
      user-agent:
      - python-httpx/0.25.2
    method: GET
    uri: https://api.semanticscholar.org/graph/v1/paper/search?query=sublinear%20near%20optimal%20edit%20distance&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=100
  response:
    content: '{"total": 85, "offset": 0, "data": [{"paperId": "169a66a031488ce0c8fdd70502945dbf69b045a5",
      "externalIds": {"MAG": "2046785857", "DBLP": "conf/soda/AndoniN10", "DOI": "10.1137/1.9781611973075.8",
      "CorpusId": 1227224}, "corpusId": 1227224, "publicationVenue": {"id": "5545566b-c0b8-418c-83a5-a986a4657572",
      "name": "ACM-SIAM Symposium on Discrete Algorithms", "type": "conference", "alternate_names":
      ["Symposium on Discrete Algorithms", "ACM-SIAM Symp Discret Algorithm", "Symp
      Discret Algorithm", "SODA"], "url": "https://en.wikipedia.org/wiki/Symposium_on_Discrete_Algorithms"},
      "url": "https://www.semanticscholar.org/paper/169a66a031488ce0c8fdd70502945dbf69b045a5",
      "title": "Near-optimal sublinear time algorithms for Ulam distance", "abstract":
      "We give near-tight bounds for estimating the edit distance between two non-repetitive
      strings (Ulam distance) with constant approximation, in sub-linear time. For
      two strings of length d and at edit distance R, our algorithm runs in time \u00d5(d/R
      + \u221ad) and outputs a constant approximation to R. We also prove a matching
      lower bound (up to logarithmic terms). Both upper and lower bounds are improvements
      over previous results from, respectively, [Andoni-Indyk-Krauthgamer, SODA''09]
      and [Batu-Ergun-Kilian-Magen-Raskhodnikova-Rubinfeld-Sami, STOC''03].", "venue":
      "ACM-SIAM Symposium on Discrete Algorithms", "year": 2010, "referenceCount":
      11, "citationCount": 27, "influentialCitationCount": 4, "isOpenAccess": true,
      "openAccessPdf": {"url": "http://www.mit.edu/%7Eandoni/papers/ulamSublinear.pdf",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2010-01-17", "journal": {"pages": "76-86"},
      "citationStyles": {"bibtex": "@Article{Andoni2010NearoptimalST,\n author = {Alexandr
      Andoni and Huy L. Nguyen},\n booktitle = {ACM-SIAM Symposium on Discrete Algorithms},\n
      pages = {76-86},\n title = {Near-optimal sublinear time algorithms for Ulam
      distance},\n year = {2010}\n}\n"}, "authors": [{"authorId": "1738395", "name":
      "Alexandr Andoni"}, {"authorId": "143679841", "name": "Huy L. Nguyen"}]}, {"paperId":
      "bcd475b206a9cbb173eb1fab726b99efc965b2f3", "externalIds": {"DBLP": "journals/corr/abs-2202-08066",
      "ArXiv": "2202.08066", "DOI": "10.1145/3519935.3519990", "CorpusId": 246867417},
      "corpusId": 246867417, "publicationVenue": {"id": "8113a511-e0d9-4231-a1bc-0bf5d0212a4e",
      "name": "Symposium on the Theory of Computing", "type": "conference", "alternate_names":
      ["Symp Theory Comput", "STOC"], "url": "http://acm-stoc.org/"}, "url": "https://www.semanticscholar.org/paper/bcd475b206a9cbb173eb1fab726b99efc965b2f3",
      "title": "Almost-optimal sublinear-time edit distance in the low distance regime",
      "abstract": "We revisit the task of computing the edit distance in sublinear
      time. In the (k,K)-gap edit distance problem we are given oracle access to two
      strings of length n and the task is to distinguish whether their edit distance
      is at most k or at least K. It has been established by Goldenberg, Krauthgamer
      and Saha (FOCS \u201919), with improvements by Kociumaka and Saha (FOCS \u201920),
      that the (k,k2)-gap problem can be solved in time O(n/k + poly(k)). One of the
      most natural questions in this line of research is whether the (k,k2)-gap is
      best-possible for the running time O(n/k + poly(k)). In this work we answer
      this question by significantly improving the gap. Specifically, we show that
      in time O(n/k + poly(k)) we can even solve the (k,k1+o(1))-gap problem. This
      is the first algorithm that breaks the (k,k2)-gap in this running time. Our
      algorithm is almost optimal in the following sense: In the low distance regime
      (k \u2264 n0.19) our running time becomes O(n/k), which matches a known n/k1+o(1)
      lower bound for the (k,k1+o(1))-gap problem up to lower order factors. Our result
      also reveals a surprising similarity of Hamming distance and edit distance in
      the low distance regime: For both, the (k,k1+o(1))-gap problem has time complexity
      n/k1\u00b1 o(1) for small k. In contrast to previous work, which employed a
      subsampled variant of the Landau-Vishkin algorithm, we instead build upon the
      algorithm of Andoni, Krauthgamer and Onak (FOCS \u201910) which approximates
      the edit distance in almost-linear time O(n1+\u03b5) within a polylogarithmic
      factor. We first simplify their approach and then show how to to effectively
      prune their computation tree in order to obtain a sublinear-time algorithm in
      the given time bound. Towards that, we use a variety of structural insights
      on the (local and global) patterns that can emerge during this process and design
      appropriate property testers to effectively detect these patterns.", "venue":
      "Symposium on the Theory of Computing", "year": 2022, "referenceCount": 29,
      "citationCount": 7, "influentialCitationCount": 1, "isOpenAccess": true, "openAccessPdf":
      {"url": "https://dl.acm.org/doi/pdf/10.1145/3519935.3519990", "status": "BRONZE"},
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle", "Book", "Conference"], "publicationDate": "2022-02-16", "journal":
      {"name": "Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing"},
      "citationStyles": {"bibtex": "@Article{Bringmann2022AlmostoptimalSE,\n author
      = {K. Bringmann and Alejandro Cassis and N. Fischer and Vasileios Nakos},\n
      booktitle = {Symposium on the Theory of Computing},\n journal = {Proceedings
      of the 54th Annual ACM SIGACT Symposium on Theory of Computing},\n title = {Almost-optimal
      sublinear-time edit distance in the low distance regime},\n year = {2022}\n}\n"},
      "authors": [{"authorId": "2535238", "name": "K. Bringmann"}, {"authorId": "2117586564",
      "name": "Alejandro Cassis"}, {"authorId": "2055530844", "name": "N. Fischer"},
      {"authorId": "3327757", "name": "Vasileios Nakos"}]}, {"paperId": "255acd4dde36a151842af8f6391a8420ed79c2c9",
      "externalIds": {"ArXiv": "2311.01793", "DBLP": "journals/corr/abs-2311-01793",
      "DOI": "10.48550/arXiv.2311.01793", "CorpusId": 265018998}, "corpusId": 265018998,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/255acd4dde36a151842af8f6391a8420ed79c2c9",
      "title": "Near-Optimal Quantum Algorithms for Bounded Edit Distance and Lempel-Ziv
      Factorization", "abstract": "Classically, the edit distance of two length-$n$
      strings can be computed in $O(n^2)$ time, whereas an $O(n^{2-\\epsilon})$-time
      procedure would falsify the Orthogonal Vectors Hypothesis. If the edit distance
      does not exceed $k$, the running time can be improved to $O(n+k^2)$, which is
      near-optimal (conditioned on OVH) as a function of $n$ and $k$. Our first main
      contribution is a quantum $\\tilde{O}(\\sqrt{nk}+k^2)$-time algorithm that uses
      $\\tilde{O}(\\sqrt{nk})$ queries, where $\\tilde{O}(\\cdot)$ hides polylogarithmic
      factors. This query complexity is unconditionally optimal, and any significant
      improvement in the time complexity would resolve a long-standing open question
      of whether edit distance admits an $O(n^{2-\\epsilon})$-time quantum algorithm.
      Our divide-and-conquer quantum algorithm reduces the edit distance problem to
      a case where the strings have small Lempel-Ziv factorizations. Then, it combines
      a quantum LZ compression algorithm with a classical edit-distance subroutine
      for compressed strings. The LZ factorization problem can be classically solved
      in $O(n)$ time, which is unconditionally optimal in the quantum setting. We
      can, however, hope for a quantum speedup if we parameterize the complexity in
      terms of the factorization size $z$. Already a generic oracle identification
      algorithm yields the optimal query complexity of $\\tilde{O}(\\sqrt{nz})$ at
      the price of exponential running time. Our second main contribution is a quantum
      algorithm that achieves the optimal time complexity of $\\tilde{O}(\\sqrt{nz})$.
      The key tool is a novel LZ-like factorization of size $O(z\\log^2n)$ whose subsequent
      factors can be efficiently computed through a combination of classical and quantum
      techniques. We can then obtain the string''s run-length encoded Burrows-Wheeler
      Transform (BWT), construct the $r$-index, and solve many fundamental string
      processing problems in time $\\tilde{O}(\\sqrt{nz})$.", "venue": "arXiv.org",
      "year": 2023, "referenceCount": 80, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Physics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
      "external"}, {"category": "Physics", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-11-03", "journal":
      {"name": "ArXiv", "volume": "abs/2311.01793"}, "citationStyles": {"bibtex":
      "@Article{Gibney2023NearOptimalQA,\n author = {Daniel Gibney and Ce Jin and
      T. Kociumaka and Sharma V. Thankachan},\n booktitle = {arXiv.org},\n journal
      = {ArXiv},\n title = {Near-Optimal Quantum Algorithms for Bounded Edit Distance
      and Lempel-Ziv Factorization},\n volume = {abs/2311.01793},\n year = {2023}\n}\n"},
      "authors": [{"authorId": "38372154", "name": "Daniel Gibney"}, {"authorId":
      "2265466647", "name": "Ce Jin"}, {"authorId": "1683073", "name": "T. Kociumaka"},
      {"authorId": "1733907", "name": "Sharma V. Thankachan"}]}, {"paperId": "7435880873bb436c0695882339b3d5e633b3ebf8",
      "externalIds": {"MAG": "2971308101", "DBLP": "journals/corr/abs-1905-01254",
      "ArXiv": "1905.01254", "DOI": "10.4230/LIPIcs.MFCS.2019.66", "CorpusId": 145048674},
      "corpusId": 145048674, "publicationVenue": {"id": "8341fde2-3e67-4fde-bb5c-6f0320d7f114",
      "name": "International Symposium on Mathematical Foundations of Computer Science",
      "type": "conference", "alternate_names": ["Int Symp Math Found Comput Sci",
      "MFCS", "Math Found Comput Sci", "Mathematical Foundations of Computer Science"],
      "url": "https://en.wikipedia.org/wiki/International_Symposium_on_Mathematical_Foundations_of_Computer_Science"},
      "url": "https://www.semanticscholar.org/paper/7435880873bb436c0695882339b3d5e633b3ebf8",
      "title": "RLE edit distance in near optimal time", "abstract": "We show that
      the edit distance between two run-length encoded strings of compressed lengths
      $m$ and $n$ respectively, can be computed in $\\mathcal{O}(mn\\log(mn))$ time.
      This improves the previous record by a factor of $\\mathcal{O}(n/\\log(mn))$.
      The running time of our algorithm is within subpolynomial factors of being optimal,
      subject to the standard SETH-hardness assumption. This effectively closes a
      line of algorithmic research first started in 1993.", "venue": "International
      Symposium on Mathematical Foundations of Computer Science", "year": 2019, "referenceCount":
      15, "citationCount": 5, "influentialCitationCount": 1, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Mathematics", "Computer Science"],
      "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category":
      "Computer Science", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2019-05-03",
      "journal": {"pages": "66:1-66:13"}, "citationStyles": {"bibtex": "@Article{Clifford2019RLEED,\n
      author = {R. Clifford and Pawe\u0142 Gawrychowski and T. Kociumaka and Daniel
      P. Martin and P. Uzna\u0144ski},\n booktitle = {International Symposium on Mathematical
      Foundations of Computer Science},\n pages = {66:1-66:13},\n title = {RLE edit
      distance in near optimal time},\n year = {2019}\n}\n"}, "authors": [{"authorId":
      "3479009", "name": "R. Clifford"}, {"authorId": "1683786", "name": "Pawe\u0142
      Gawrychowski"}, {"authorId": "1683073", "name": "T. Kociumaka"}, {"authorId":
      "3380344", "name": "Daniel P. Martin"}, {"authorId": "144469774", "name": "P.
      Uzna\u0144ski"}]}, {"paperId": "369001d256cf192759045e030645a96df5de531c", "externalIds":
      {"DBLP": "journals/corr/abs-2111-12706", "ArXiv": "2111.12706", "DOI": "10.1109/FOCS54457.2022.00070",
      "CorpusId": 244527479}, "corpusId": 244527479, "publicationVenue": {"id": "68cf0e99-5164-4480-8ed4-8b8416a091df",
      "name": "IEEE Annual Symposium on Foundations of Computer Science", "type":
      "conference", "alternate_names": ["FOCS", "IEEE Annu Symp Found Comput Sci"],
      "url": "http://ieee-focs.org/"}, "url": "https://www.semanticscholar.org/paper/369001d256cf192759045e030645a96df5de531c",
      "title": "Gap Edit Distance via Non-Adaptive Queries: Simple and Optimal", "abstract":
      "We study the problem of approximating edit distance in sublinear time. This
      is formalized as the $(k,\\ k^{\\mathrm{c}})$-GAP EDIT DISTANCE problem, where
      the input is a pair of strings $X, \\mathrm{Y}$ and parameters $k, c\\gt 1$,
      and the goal is to return YES if ED(X, Y) $\\leq k$, NO if ED(X, Y) $\\gt k^{\\mathrm{c}}$,
      and an arbitrary answer when $k\\lt $ ED(X, Y) $\\leq k^{\\mathrm{c}}$. Recent
      years have witnessed significant interest in designing sublinear-time algorithms
      for GAP EDIT DISTANCE.In this work, we resolve the non-adaptive query complexity
      of GAP EDIT DISTANCE for the entire range of parameters, improving over a sequence
      of previous results. Specifically, we design a non-adaptive algorithm with query
      complexity $\\tilde{O}(n/k^{\\mathrm{c}-\\mathrm{O}.5})$, and we further prove
      that this bound is optimal up to polylogarithmic factors.Our algorithm also
      achieves optimal time complexity $\\tilde{O}(n/k^{\\mathrm{c}-\\mathrm{O}.5})$
      whenever $ c\\geq$ 1.5. For $1 \\lt c\\lt $ 1.5, the running time of our algorithm
      is $\\tilde{O}(n/k^{2\\mathrm{c}-2})$. In the restricted case of $k^{\\mathrm{c}}=\\Omega(n)$,
      this matches a known result [Batu, Erg\u00fcn, Kilian, Magen, Raskhodnikova,
      Rubinfeld, and Sami; STOC 2003], and in all other (nontrivial) cases, our running
      time is strictly better than all previous algorithms, including the adaptive
      ones. However, independent work of Bringmann, Cassis, Fischer, and Nakos [STOC
      2022] provides an adaptive algorithm that bypasses the non-adaptive lower bound,
      but only for small enough k and c.", "venue": "IEEE Annual Symposium on Foundations
      of Computer Science", "year": 2021, "referenceCount": 37, "citationCount": 7,
      "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://arxiv.org/pdf/2111.12706", "status": "GREEN"}, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2021-11-24", "journal": {"name": "2022 IEEE 63rd Annual Symposium on Foundations
      of Computer Science (FOCS)", "pages": "674-685"}, "citationStyles": {"bibtex":
      "@Article{Goldenberg2021GapED,\n author = {Elazar Goldenberg and T. Kociumaka
      and Robert Krauthgamer and B. Saha},\n booktitle = {IEEE Annual Symposium on
      Foundations of Computer Science},\n journal = {2022 IEEE 63rd Annual Symposium
      on Foundations of Computer Science (FOCS)},\n pages = {674-685},\n title = {Gap
      Edit Distance via Non-Adaptive Queries: Simple and Optimal},\n year = {2021}\n}\n"},
      "authors": [{"authorId": "1752311", "name": "Elazar Goldenberg"}, {"authorId":
      "1683073", "name": "T. Kociumaka"}, {"authorId": "1737712", "name": "Robert
      Krauthgamer"}, {"authorId": "3269130", "name": "B. Saha"}]}, {"paperId": "bc89e7e20da2c5674e91eb6c28030def0ef2a4ff",
      "externalIds": {"MAG": "3045868777", "DBLP": "journals/corr/abs-2007-14368",
      "ArXiv": "2007.14368", "CorpusId": 220831191}, "corpusId": 220831191, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/bc89e7e20da2c5674e91eb6c28030def0ef2a4ff",
      "title": "A Simple Sublinear Algorithm for Gap Edit Distance", "abstract": "We
      study the problem of estimating the edit distance between two $n$-character
      strings. While exact computation in the worst case is believed to require near-quadratic
      time, previous work showed that in certain regimes it is possible to solve the
      following {\\em gap edit distance} problem in sub-linear time: distinguish between
      inputs of distance $\\le k$ and $>k^2$. Our main result is a very simple algorithm
      for this benchmark that runs in time $\\tilde O(n/\\sqrt{k})$, and in particular
      settles the open problem of obtaining a truly sublinear time for the entire
      range of relevant $k$. \nBuilding on the same framework, we also obtain a $k$-vs-$k^2$
      algorithm for the one-sided preprocessing model with $\\tilde O(n)$ preprocessing
      time and $\\tilde O(n/k)$ query time (improving over a recent $\\tilde O(n/k+k^2)$-query
      time algorithm for the same problem [GRS''20].", "venue": "arXiv.org", "year":
      2020, "referenceCount": 51, "citationCount": 8, "influentialCitationCount":
      1, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science",
      "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2020-07-28", "journal": {"name": "ArXiv", "volume": "abs/2007.14368"}, "citationStyles":
      {"bibtex": "@Article{Brakensiek2020ASS,\n author = {Joshua Brakensiek and M.
      Charikar and A. Rubinstein},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {A Simple Sublinear Algorithm for Gap Edit Distance},\n volume = {abs/2007.14368},\n
      year = {2020}\n}\n"}, "authors": [{"authorId": "31332532", "name": "Joshua Brakensiek"},
      {"authorId": "1745732", "name": "M. Charikar"}, {"authorId": "38651679", "name":
      "A. Rubinstein"}]}, {"paperId": "887db39a940b590140011c0e4e688b2212b0e8ee",
      "externalIds": {"DBLP": "journals/corr/abs-1910-00901", "ArXiv": "1910.00901",
      "MAG": "2971787908", "DOI": "10.1109/FOCS.2019.00070", "CorpusId": 202776351},
      "corpusId": 202776351, "publicationVenue": {"id": "68cf0e99-5164-4480-8ed4-8b8416a091df",
      "name": "IEEE Annual Symposium on Foundations of Computer Science", "type":
      "conference", "alternate_names": ["FOCS", "IEEE Annu Symp Found Comput Sci"],
      "url": "http://ieee-focs.org/"}, "url": "https://www.semanticscholar.org/paper/887db39a940b590140011c0e4e688b2212b0e8ee",
      "title": "Sublinear Algorithms for Gap Edit Distance", "abstract": "Abstract\u2014The
      edit distance is a way of quantifying how similar two strings are to one another
      by counting the minimum number of character insertions, deletions, and substitutions
      required to transform one string into the other. A simple dynamic programming
      computes the edit distance between two strings of length n in O(n2) time, and
      a more sophisticated algorithm runs in time O(n + t2) when the edit distance
      is t [Landau, Myers and Schmidt, SICOMP 1998]. In pursuit of obtaining faster
      running time, the last couple of decades have seen a flurry of research on approximating
      edit distance, including polylogarithmic approximation in near-linear time [Andoni,
      Krauthgamer and Onak, FOCS 2010], and a constant-factor approximation in subquadratic
      time [Chakrabarty, Das, Goldenberg, Kouck\u00b4y and Saks, FOCS 2018]. We study
      sublinear-time algorithms for small edit distance, which was investigated extensively
      because of its numerous applications. Our main result is an algorithm for distinguishing
      whether the edit distance is at most t or at least t^2 (the quadratic gap problem)
      in time \u00d5(n/t+t^3). This time bound is sublinear roughly for all t in [\u03c9(1),
      o(n^1/3)], which was not known before. The best previous algorithms solve this
      problem in sublinear time only for t=\u03c9(n^1/3) [Andoni and Onak, STOC 2009].
      Our algorithm is based on a new approach that adaptively switches between uniform
      sampling and reading contiguous blocks of the input strings. In contrast, all
      previous algorithms choose which coordinates to query non-adaptively. Moreover,
      it can be extended to solve the t vs t^2-\u03b5 gap problem in time \u00d5(n/t^1-\u03b5+t^3).",
      "venue": "IEEE Annual Symposium on Foundations of Computer Science", "year":
      2019, "referenceCount": 35, "citationCount": 27, "influentialCitationCount":
      1, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/1910.00901",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-10-02", "journal": {"name": "2019
      IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS)", "pages":
      "1101-1120"}, "citationStyles": {"bibtex": "@Article{Goldenberg2019SublinearAF,\n
      author = {Elazar Goldenberg and Robert Krauthgamer and B. Saha},\n booktitle
      = {IEEE Annual Symposium on Foundations of Computer Science},\n journal = {2019
      IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS)},\n pages
      = {1101-1120},\n title = {Sublinear Algorithms for Gap Edit Distance},\n year
      = {2019}\n}\n"}, "authors": [{"authorId": "1752311", "name": "Elazar Goldenberg"},
      {"authorId": "1737712", "name": "Robert Krauthgamer"}, {"authorId": "3269130",
      "name": "B. Saha"}]}, {"paperId": "6d623a468227ee0796e15579386e2f73d34700e2",
      "externalIds": {"ArXiv": "2312.01759", "DBLP": "journals/corr/abs-2312-01759",
      "DOI": "10.48550/arXiv.2312.01759", "CorpusId": 265608734}, "corpusId": 265608734,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/6d623a468227ee0796e15579386e2f73d34700e2",
      "title": "Faster Sublinear-Time Edit Distance", "abstract": "We study the fundamental
      problem of approximating the edit distance of two strings. After an extensive
      line of research led to the development of a constant-factor approximation algorithm
      in almost-linear time, recent years have witnessed a notable shift in focus
      towards sublinear-time algorithms. Here, the task is typically formalized as
      the $(k, K)$-gap edit distance problem: Distinguish whether the edit distance
      of two strings is at most $k$ or more than $K$. Surprisingly, it is still possible
      to compute meaningful approximations in this challenging regime. Nevertheless,
      in almost all previous work, truly sublinear running time of $O(n^{1-\\varepsilon})$
      (for a constant $\\varepsilon>0$) comes at the price of at least polynomial
      gap $K \\ge k \\cdot n^{\\Omega(\\varepsilon)}$. Only recently, [Bringmann,
      Cassis, Fischer, and Nakos; STOC''22] broke through this barrier and solved
      the sub-polynomial $(k, k^{1+o(1)})$-gap edit distance problem in time $O(n/k
      + k^{4+o(1)})$, which is truly sublinear if $n^{\\Omega(1)} \\le k \\le n^{\\frac14-\\Omega(1)}$.The
      $n/k$ term is inevitable (already for Hamming distance), but it remains an important
      task to optimize the $\\mathrm{poly}(k)$ term and, in general, solve the $(k,
      k^{1+o(1)})$-gap edit distance problem in sublinear-time for larger values of
      $k$. In this work, we design an improved algorithm for the $(k, k^{1+o(1)})$-gap
      edit distance problem in sublinear time $O(n/k + k^{2+o(1)})$, yielding a significant
      quadratic speed-up over the previous $O(n/k + k^{4+o(1)})$-time algorithm. Notably,
      our algorithm is unconditionally almost-optimal (up to subpolynomial factors)
      in the regime where $k \\leq n^{\\frac13}$ and improves upon the state of the
      art for $k \\leq n^{\\frac12-o(1)}$.", "venue": "arXiv.org", "year": 2023, "referenceCount":
      35, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-12-04", "journal":
      {"name": "ArXiv", "volume": "abs/2312.01759"}, "citationStyles": {"bibtex":
      "@Article{Bringmann2023FasterSE,\n author = {K. Bringmann and Alejandro Cassis
      and N. Fischer and Tomasz Kociumaka},\n booktitle = {arXiv.org},\n journal =
      {ArXiv},\n title = {Faster Sublinear-Time Edit Distance},\n volume = {abs/2312.01759},\n
      year = {2023}\n}\n"}, "authors": [{"authorId": "2535238", "name": "K. Bringmann"},
      {"authorId": "2117586564", "name": "Alejandro Cassis"}, {"authorId": "2055530844",
      "name": "N. Fischer"}, {"authorId": "2262216931", "name": "Tomasz Kociumaka"}]},
      {"paperId": "08034a0a533e1a25693970c6f6f04ad8f429c3bc", "externalIds": {"ArXiv":
      "2307.07175", "DBLP": "journals/corr/abs-2307-07175", "DOI": "10.1109/FOCS57990.2023.00098",
      "CorpusId": 259924560}, "corpusId": 259924560, "publicationVenue": {"id": "68cf0e99-5164-4480-8ed4-8b8416a091df",
      "name": "IEEE Annual Symposium on Foundations of Computer Science", "type":
      "conference", "alternate_names": ["FOCS", "IEEE Annu Symp Found Comput Sci"],
      "url": "http://ieee-focs.org/"}, "url": "https://www.semanticscholar.org/paper/08034a0a533e1a25693970c6f6f04ad8f429c3bc",
      "title": "Approximating Edit Distance in the Fully Dynamic Model", "abstract":
      "The edit distance is a fundamental measure of sequence similarity, defined
      as the minimum number of character insertions, deletions, and substitutions
      needed to transform one string into the other. Given two strings of length at
      most n, a simple dynamic programming computes their edit distance exactly in
      $\\mathcal{O}\\left(n^{2}\\right)$ time, which is also the best possible (up
      to subpolynomial factors) assuming the Strong Exponential Time Hypothesis (SETH).
      The last few decades have seen tremendous progress in edit distance approximation,
      where the runtime has been brought down to subquadratic, to near-linear, and
      even to sublinear at the cost of approximation. In this paper, we study the
      dynamic edit distance problem where the strings change dynamically as the characters
      are substituted, inserted, or deleted over time. Each change may happen at any
      location of either of the two strings. The goal is to maintain the (exact or
      approximate) edit distance of such dynamic strings while minimizing the update
      time. The exact edit distance can be maintained in $\\mathcal{O}\\left(n \\log
      ^{2} n\\right)$ time per update (Charalampopoulos, Kociumaka, Mozes; 2020),
      which is again tight assuming SETH. Unfortunately, even with the unprecedented
      progress in edit distance approximation in the static setting, strikingly little
      is known regarding dynamic edit distance approximation. Utilizing the best near-linear-time
      (Andoni, Nosatzki; 2020) and sublinear-time (Goldenberg, Kociumaka, Krauthgamer,
      Saha; 2022) approximation algorithm, an old exact algorithm (Landau and Vishkin;
      1988), and a generic dynamic strings implementation (Mehlhorn, Sundar, Uhrig;
      1996), it is possible to achieve an $\\mathcal{O}\\left(n^{c}\\right)$-approximation
      in $n^{0.5-c+o(1)}$ update time for any constant $c \\in\\left[0, \\frac{1}{6}\\right]$.
      Improving upon this trade-off, characterized by the approximation-ratio and
      update-time product $n^{0.5+o(1)}$, remains wide open. The contribution of this
      work is a dynamic $n^{o(1)}$-approximation algorithm with amortized expected
      update time of $n^{o(1)}$. In other words, we bring the approximation-ratio
      and update-time product down to $n^{o(1)}$, which is also the best possible
      with the current state of the art in static algorithms. Our solution utilizes
      an elegant framework of precision sampling trees for edit distance approximation
      (Andoni, Krauthgamer, Onak; 2010). We show how to dynamically maintain precision
      sampling trees, which comes with significant nontriviality and can be an independent
      tool of interest for further development in dynamic string algorithms.", "venue":
      "IEEE Annual Symposium on Foundations of Computer Science", "year": 2023, "referenceCount":
      80, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-07-14", "journal":
      {"name": "2023 IEEE 64th Annual Symposium on Foundations of Computer Science
      (FOCS)", "pages": "1628-1638"}, "citationStyles": {"bibtex": "@Article{Kociumaka2023ApproximatingED,\n
      author = {T. Kociumaka and A. Mukherjee and B. Saha},\n booktitle = {IEEE Annual
      Symposium on Foundations of Computer Science},\n journal = {2023 IEEE 64th Annual
      Symposium on Foundations of Computer Science (FOCS)},\n pages = {1628-1638},\n
      title = {Approximating Edit Distance in the Fully Dynamic Model},\n year = {2023}\n}\n"},
      "authors": [{"authorId": "1683073", "name": "T. Kociumaka"}, {"authorId": "3394383",
      "name": "A. Mukherjee"}, {"authorId": "3269130", "name": "B. Saha"}]}, {"paperId":
      "59ba089d36a0a07df6ae035592a17e4de269849c", "externalIds": {"DBLP": "journals/tmm/ZhouWHMYZWZ23",
      "DOI": "10.1109/TMM.2021.3132156", "CorpusId": 244854950}, "corpusId": 244854950,
      "publicationVenue": {"id": "10e76a35-58d6-443c-9683-fc16f2dd0a92", "name": "IEEE
      transactions on multimedia", "type": "journal", "alternate_names": ["IEEE Transactions
      on Multimedia", "IEEE Trans Multimedia", "IEEE trans multimedia"], "issn": "1520-9210",
      "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6046"}, "url": "https://www.semanticscholar.org/paper/59ba089d36a0a07df6ae035592a17e4de269849c",
      "title": "Caching in Dynamic Environments: A Near-Optimal Online Learning Approach",
      "abstract": "The rapid growth of rich multimedia data in today\u2019s Internet,
      especially video traffic, has challenged the content delivery networks (CDNs).
      Caching serves as an important means to reduce user access latency so as to
      enable faster content downloads. Motivated by the dynamic nature of the real-world
      edge traces, this paper introduces a provably well online caching policy in
      dynamic environments where: 1) the popularity is highly dynamic; 2) no regular
      stochastic pattern can model this dynamic evaluation process. First, we design
      an online optimization framework, which aims to minimize the dynamic regret
      that finds the distance between an online caching policy and the best dynamic
      policy in hindsight. Second, we propose a dynamic online learning method to
      solve the non-stationary caching problem formulated in the previous framework.
      Compared to the linear dynamic regret of previous methods, our proposal is proved
      to achieve a sublinear dynamic regret, from which it is guaranteed to be nearly
      optimal. We verify the design using both synthetic and real-world traces: the
      proposed policy achieves the best performance in the synthetic traces with different
      levels of dynamicity, which verifies the dynamic adaptation; our proposal consistently
      achieves at least 9.4% improvement than the baselines, including LRU, LFU, Static
      Online Learning based replacement, and Deep Reinforcement Learning based replacement,
      in random edge areas from real-world traces (from iQIYI), further verifying
      the effectiveness and robustness on the edge.", "venue": "IEEE transactions
      on multimedia", "year": 2023, "referenceCount": 46, "citationCount": 9, "influentialCitationCount":
      1, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": null, "journal": {"name": "IEEE Transactions
      on Multimedia", "pages": "792-804", "volume": "25"}, "citationStyles": {"bibtex":
      "@Article{Zhou2023CachingID,\n author = {Shiji Zhou and Zhi Wang and Chenghao
      Hu and Yinan Mao and Haopeng Yan and Shanghang Zhang and Chuan Wu and Wenwu
      Zhu},\n booktitle = {IEEE transactions on multimedia},\n journal = {IEEE Transactions
      on Multimedia},\n pages = {792-804},\n title = {Caching in Dynamic Environments:
      A Near-Optimal Online Learning Approach},\n volume = {25},\n year = {2023}\n}\n"},
      "authors": [{"authorId": "2149195194", "name": "Shiji Zhou"}, {"authorId": "2135451624",
      "name": "Zhi Wang"}, {"authorId": "46622702", "name": "Chenghao Hu"}, {"authorId":
      "1840978357", "name": "Yinan Mao"}, {"authorId": "2152208619", "name": "Haopeng
      Yan"}, {"authorId": "2437353", "name": "Shanghang Zhang"}, {"authorId": "2118839647",
      "name": "Chuan Wu"}, {"authorId": "145583986", "name": "Wenwu Zhu"}]}, {"paperId":
      "2875b388c07381aecdf620990f71394a840fbb0e", "externalIds": {"DBLP": "conf/soda/ChenDLSS22",
      "ArXiv": "2107.11530", "DOI": "10.1137/1.9781611977073.34", "CorpusId": 236428709},
      "corpusId": 236428709, "publicationVenue": {"id": "5545566b-c0b8-418c-83a5-a986a4657572",
      "name": "ACM-SIAM Symposium on Discrete Algorithms", "type": "conference", "alternate_names":
      ["Symposium on Discrete Algorithms", "ACM-SIAM Symp Discret Algorithm", "Symp
      Discret Algorithm", "SODA"], "url": "https://en.wikipedia.org/wiki/Symposium_on_Discrete_Algorithms"},
      "url": "https://www.semanticscholar.org/paper/2875b388c07381aecdf620990f71394a840fbb0e",
      "title": "Near-Optimal Average-Case Approximate Trace Reconstruction from Few
      Traces", "abstract": "In the standard trace reconstruction problem, the goal
      is to \\emph{exactly} reconstruct an unknown source string $\\mathsf{x} \\in
      \\{0,1\\}^n$ from independent\"traces\", which are copies of $\\mathsf{x}$ that
      have been corrupted by a $\\delta$-deletion channel which independently deletes
      each bit of $\\mathsf{x}$ with probability $\\delta$ and concatenates the surviving
      bits. We study the \\emph{approximate} trace reconstruction problem, in which
      the goal is only to obtain a high-accuracy approximation of $\\mathsf{x}$ rather
      than an exact reconstruction. We give an efficient algorithm, and a near-matching
      lower bound, for approximate reconstruction of a random source string $\\mathsf{x}
      \\in \\{0,1\\}^n$ from few traces. Our main algorithmic result is a polynomial-time
      algorithm with the following property: for any deletion rate $0<\\delta<1$ (which
      may depend on $n$), for almost every source string $\\mathsf{x} \\in \\{0,1\\}^n$,
      given any number $M \\leq \\Theta(1/\\delta)$ of traces from $\\mathrm{Del}_\\delta(\\mathsf{x})$,
      the algorithm constructs a hypothesis string $\\widehat{\\mathsf{x}}$ that has
      edit distance at most $n \\cdot (\\delta M)^{\\Omega(M)}$ from $\\mathsf{x}$.
      We also prove a near-matching information-theoretic lower bound showing that
      given $M \\leq \\Theta(1/\\delta)$ traces from $\\mathrm{Del}_\\delta(\\mathsf{x})$
      for a random $n$-bit string $\\mathsf{x}$, the smallest possible expected edit
      distance that any algorithm can achieve, regardless of its running time, is
      $n \\cdot (\\delta M)^{O(M)}$.", "venue": "ACM-SIAM Symposium on Discrete Algorithms",
      "year": 2021, "referenceCount": 33, "citationCount": 7, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/2107.11530",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2021-07-24",
      "journal": {"name": "ArXiv", "volume": "abs/2107.11530"}, "citationStyles":
      {"bibtex": "@Article{Chen2021NearOptimalAA,\n author = {Xi Chen and Anindya
      De and Chin Ho Lee and R. Servedio and S. Sinha},\n booktitle = {ACM-SIAM Symposium
      on Discrete Algorithms},\n journal = {ArXiv},\n title = {Near-Optimal Average-Case
      Approximate Trace Reconstruction from Few Traces},\n volume = {abs/2107.11530},\n
      year = {2021}\n}\n"}, "authors": [{"authorId": "2145307359", "name": "Xi Chen"},
      {"authorId": "145202870", "name": "Anindya De"}, {"authorId": "9392134", "name":
      "Chin Ho Lee"}, {"authorId": "1729835", "name": "R. Servedio"}, {"authorId":
      "1739180701", "name": "S. Sinha"}]}, {"paperId": "5f8a00f3eb67a7300512f1f656a67e7d0516936b",
      "externalIds": {"MAG": "2991611170", "DBLP": "journals/algorithmica/FoxL22",
      "ArXiv": "1910.00773", "DOI": "10.1007/s00453-022-00966-4", "CorpusId": 197679750},
      "corpusId": 197679750, "publicationVenue": {"id": "300eb16f-ce6c-495a-8da3-2e691bf9051d",
      "name": "Algorithmica", "type": "journal", "issn": "0178-4617", "url": "https://www.springer.com/computer/theoretical+computer+science/journal/453",
      "alternate_urls": ["https://link.springer.com/journal/453", "http://www.springer.com/computer/theoretical+computer+science/journal/453"]},
      "url": "https://www.semanticscholar.org/paper/5f8a00f3eb67a7300512f1f656a67e7d0516936b",
      "title": "Approximating the Geometric Edit Distance", "abstract": null, "venue":
      "Algorithmica", "year": 2019, "referenceCount": 40, "citationCount": 3, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://drops.dagstuhl.de/opus/volltexte/2019/11519/pdf/LIPIcs-ISAAC-2019-23.pdf",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-10-01", "journal": {"name": "Algorithmica",
      "pages": "2395 - 2413", "volume": "84"}, "citationStyles": {"bibtex": "@Article{Fox2019ApproximatingTG,\n
      author = {K. Fox and Xinyi Li},\n booktitle = {Algorithmica},\n journal = {Algorithmica},\n
      pages = {2395 - 2413},\n title = {Approximating the Geometric Edit Distance},\n
      volume = {84},\n year = {2019}\n}\n"}, "authors": [{"authorId": "40146794",
      "name": "K. Fox"}, {"authorId": "2108482157", "name": "Xinyi Li"}]}, {"paperId":
      "98781e5cab0b574d326594f377f9176be1526277", "externalIds": {"MAG": "2084812114",
      "DBLP": "conf/focs/Saha14", "DOI": "10.1109/FOCS.2014.71", "CorpusId": 14806359},
      "corpusId": 14806359, "publicationVenue": {"id": "68cf0e99-5164-4480-8ed4-8b8416a091df",
      "name": "IEEE Annual Symposium on Foundations of Computer Science", "type":
      "conference", "alternate_names": ["FOCS", "IEEE Annu Symp Found Comput Sci"],
      "url": "http://ieee-focs.org/"}, "url": "https://www.semanticscholar.org/paper/98781e5cab0b574d326594f377f9176be1526277",
      "title": "The Dyck Language Edit Distance Problem in Near-Linear Time", "abstract":
      "Given a string \u03c3 over alphabet \u03a3 and a grammar G defined over the
      same alphabet, how many minimum number of repairs (insertions, deletions and
      substitutions) are required to map \u03c3 into a valid member of G? The seminal
      work of Aho and Peterson in 1972 initiated the study of this language edit distance
      problem providing a dynamic programming algorithm for context free languages
      that runs in O(|G|2n3) time, where n is the string length and G is the grammar
      size. While later improvements reduced the running time to O(G n3), the cubic
      time complexity on the input length held a major bottleneck for applying these
      algorithms to their multitude of applications. In this paper, we study the language
      edit distance problem for a fundamental context free language, DYCK(s) representing
      the language of well-balanced parentheses of s different types, that has been
      pivotal in the development of formal language theory. We provide the very first
      near-linear time algorithm to tightly approximate the DYCK(s) language edit
      distance problem for any arbitrary s. DYCK(s) language edit distance significantly
      generalizes the well-studied string edit distance problem, and appears in most
      applications of language edit distance ranging from data quality in databases,
      generating automated error-correcting parsers in compiler optimization to structure
      prediction problems in biological sequences. Its nondeterministic counterpart
      is known as the hardest context free language. Our main result is an algorithm
      for edit distance computation to DYCK(s) for any positive integer s that runs
      in O(n1+\u03f5 polylog(n)) time and achieves an approximation factor of O(1/\u03f5\u03b2(n)
      log |OPT|), for any \u03f5 > 0. Here OPT is the optimal edit distance to DYCK(s)
      and \u03b2(n) is the best approximation factor known for the simpler problem
      of string edit distance running in analogous time. If we allow O(n1+\u03f5 +
      |OPT|2n\u03f5) time, then the approximation factor can be reduced to O(1/\u03f5
      log |OPT|). Since the best known near-linear time algorithm for the string edit
      distance problem has \u03b2(n) = polylog(n), under near-linear time computation
      model both DYCK(s) language and string edit distance problems have polylog(n)
      approximation factors. This comes as a surprise since the former is a significant
      generalization of the latter and their exact computations via dynamic programming
      show a stark difference in time complexity. Rather less surprisingly, we show
      that the framework for efficiently approximating edit distance to DYCK(s) can
      be utilized for many other languages. We illustrate this by considering various
      memory checking languages (studied extensively under distributed verification)
      such as STACK, QUEUE, PQ and DEQUE which comprise of valid transcripts of stacks,
      queues, priority queues and double-ended queues respectively. Therefore, any
      language that can be recognized by these data structures, can also be repaired
      efficiently by our algorithm.", "venue": "IEEE Annual Symposium on Foundations
      of Computer Science", "year": 2014, "referenceCount": 35, "citationCount": 27,
      "influentialCitationCount": 4, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2014-10-18", "journal": {"name": "2014 IEEE 55th Annual Symposium on Foundations
      of Computer Science", "pages": "611-620"}, "citationStyles": {"bibtex": "@Article{Saha2014TheDL,\n
      author = {B. Saha},\n booktitle = {IEEE Annual Symposium on Foundations of Computer
      Science},\n journal = {2014 IEEE 55th Annual Symposium on Foundations of Computer
      Science},\n pages = {611-620},\n title = {The Dyck Language Edit Distance Problem
      in Near-Linear Time},\n year = {2014}\n}\n"}, "authors": [{"authorId": "3269130",
      "name": "B. Saha"}]}, {"paperId": "169e73ca83f75e4c0d3d89962cffe57403553879",
      "externalIds": {"MAG": "3008045680", "CorpusId": 214222595}, "corpusId": 214222595,
      "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/169e73ca83f75e4c0d3d89962cffe57403553879",
      "title": "Pseudorandom Constructions: Computing in Parallel and Applications
      to Edit Distance Codes", "abstract": "The thesis focuses on two problems about
      pseudorandom constructions. The first problem is how to compute pseudorandom
      constructions by constant depth circuits. Pseudorandom constructions are deterministic
      functions which are used to substitute random constructions in various computational
      tasks. Constant depth circuits here refer to the computation model which can
      compute functions using circuits of AND, OR and negation gates, with constant
      depth, unbounded fan-in, taking function inputs by input wires and giving function
      outputs by output wires. They can be simulated by fast parallel algorithms.
      We study such constructions mainly for randomness extractors, secret sharing
      schemes and their applications. Randomness extractors are functions which transform
      biased random bits to uniform ones. They can be used to recycle random bits
      in computations if there are some entropies remaining. Secret sharing schemes
      efficiently share secrets among multi-parties s.t. the collusion of a bounded
      number of parties cannot recover any information of the secret while a certain
      larger number of parties can recover the secret. Our work constructs these objects
      with near optimal parameters and explores their applications. The second problem
      is about applying pseudorandom constructions to build error correcting codes
      (ECCs) for edit distance. ECCs project messages to codewords in a metric space
      s.t. one can recover the codewords even if there are bounded number of", "venue":
      "", "year": 2019, "referenceCount": 135, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": "2019-06-04",
      "journal": {"name": "", "volume": ""}, "citationStyles": {"bibtex": "@Inproceedings{Cheng2019PseudorandomCC,\n
      author = {Kuan Cheng},\n title = {Pseudorandom Constructions: Computing in Parallel
      and Applications to Edit Distance Codes},\n year = {2019}\n}\n"}, "authors":
      [{"authorId": "50204729", "name": "Kuan Cheng"}]}, {"paperId": "a41c4d650de9ca79dccf2486b7a61e40e0c2f99f",
      "externalIds": {"DBLP": "conf/icalp/AndoniK08", "MAG": "2076238476", "DOI":
      "10.1145/2344422.2344434", "CorpusId": 1135053}, "corpusId": 1135053, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/a41c4d650de9ca79dccf2486b7a61e40e0c2f99f",
      "title": "The smoothed complexity of edit distance", "abstract": "We initiate
      the study of the smoothed complexity of sequence alignment, by proposing a semi-random
      model of edit distance between two input strings, generated as follows: First,
      an adversary chooses two binary strings of length d and a longest common subsequence
      A of them. Then, every character is perturbed independently with probability
      p, except that A is perturbed in exactly the same way inside the two strings.\n
      We design two efficient algorithms that compute the edit distance on smoothed
      instances up to a constant factor approximation. The first algorithm runs in
      near-linear time, namely d{1+\u03b5} for any fixed \u03b5 > 0. The second one
      runs in time sublinear in d, assuming the edit distance is not too small. These
      approximation and runtime guarantees are significantly better than the bounds
      that were known for worst-case inputs.\n Our technical contribution is twofold.
      First, we rely on finding matches between substrings in the two strings, where
      two substrings are considered a match if their edit distance is relatively small,
      a prevailing technique in commonly used heuristics, such as PatternHunter of
      Ma et al. [2002]. Second, we effectively reduce the smoothed edit distance to
      a simpler variant of (worst-case) edit distance, namely, edit distance on permutations
      (a.k.a. Ulam''s metric). We are thus able to build on algorithms developed for
      the Ulam metric, whose much better algorithmic guarantees usually do not carry
      over to general edit distance.", "venue": "TALG", "year": 2008, "referenceCount":
      33, "citationCount": 34, "influentialCitationCount": 4, "isOpenAccess": true,
      "openAccessPdf": {"url": "http://www.wisdom.weizmann.ac.il/~robi/papers/AK-smooth-ICALP08.pdf",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2008-07-07", "journal": {"name": "ACM
      Trans. Algorithms", "pages": "44:1-44:25", "volume": "8"}, "citationStyles":
      {"bibtex": "@Article{Andoni2008TheSC,\n author = {Alexandr Andoni and Robert
      Krauthgamer},\n booktitle = {TALG},\n journal = {ACM Trans. Algorithms},\n pages
      = {44:1-44:25},\n title = {The smoothed complexity of edit distance},\n volume
      = {8},\n year = {2008}\n}\n"}, "authors": [{"authorId": "1738395", "name": "Alexandr
      Andoni"}, {"authorId": "1737712", "name": "Robert Krauthgamer"}]}, {"paperId":
      "9a71a3e70062297dca10f8c82040f303b0305e4d", "externalIds": {"DBLP": "journals/corr/abs-1804-03604",
      "MAG": "2797057688", "CorpusId": 126006971}, "corpusId": 126006971, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/9a71a3e70062297dca10f8c82040f303b0305e4d",
      "title": "Optimal Document Exchange and New Codes for Small Number of Insertions
      and Deletions", "abstract": "This paper gives a communication-optimal document
      exchange protocol and an efficient near optimal derandomization. This also implies
      drastically improved error correcting codes for small number of adversarial
      insertions and deletions. \nFor any $n$ and $k < n$ our randomized hashing scheme
      takes any $n$-bit file $F$ and computes a $O(k \\log \\frac{n}{k})$-bit summary
      from which one can reconstruct $F$ given a related file $F''$ with edit distance
      $ED(F,F'') \\leq k$. \nThe size of our summary is information-theoretically
      order optimal for all values of $k$, positively answering a question of Orlitsky.
      It also is the first non-trivial solution when a small constant fraction of
      symbols have been edited, producing an optimal summary of size $O(H(\\delta)n)$
      for $k=\\delta n$. This concludes a long series of better-and-better protocols
      which produce larger summaries for sub-linear values of $k$. In particular,
      the recent break-through of [Belazzougi, Zhang; STOC''16] assumes that $k <
      n^\\epsilon$ and produces a summary of size $O(k\\log^2 k + k\\log n)$. \nWe
      also give an efficient derandomization with near optimal summary size $O(k \\log^2
      \\frac{n}{k})$ improving, for every $k$, over a deterministic $O(k^2 + k \\log^2
      n)$ document exchange scheme by Belazzougi. This directly leads to near optimal
      systematic error correcting codes which efficiently can recover from any $k$
      insertions and deletions while having $\\Theta(k \\log^2 \\frac{n}{k})$ bits
      of redundancy. For the setting of $k=n\\epsilon$ this $O(\\epsilon \\log^2 \\frac{1}{\\epsilon}
      \\cdot n)$-bit redundancy is near optimal and a quadratic improvement over the
      binary codes of Guruswami and Li and Haeupler, Shahrasbi and Vitercik which
      have redundancy $\\Theta\\left(\\sqrt{\\epsilon} \\log^{O(1)} \\frac{1}{\\epsilon}
      \\cdot n\\right)$.", "venue": "arXiv.org", "year": 2018, "referenceCount": 0,
      "citationCount": 16, "influentialCitationCount": 1, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2018-04-10", "journal": {"name": "ArXiv",
      "volume": "abs/1804.03604"}, "citationStyles": {"bibtex": "@Article{Haeupler2018OptimalDE,\n
      author = {Bernhard Haeupler},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Optimal Document Exchange and New Codes for Small Number of Insertions
      and Deletions},\n volume = {abs/1804.03604},\n year = {2018}\n}\n"}, "authors":
      [{"authorId": "1736596", "name": "Bernhard Haeupler"}]}, {"paperId": "0f7d665dc961183f48c4a5a82b7eea5519f0d4b2",
      "externalIds": {"DBLP": "journals/jcb/JainGT22", "DOI": "10.1089/cmb.2022.0266",
      "CorpusId": 253446141, "PubMed": "36351202"}, "corpusId": 253446141, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/0f7d665dc961183f48c4a5a82b7eea5519f0d4b2",
      "title": "Algorithms for Colinear Chaining with Overlaps and Gap Costs", "abstract":
      "Colinear chaining has proven to be a powerful heuristic for finding near-optimal
      alignments of long DNA sequences (e.g., long reads or a genome assembly) to
      a reference. It is used as an intermediate step in several alignment tools that
      employ a seed-chain-extend strategy. Despite this popularity, efficient subquadratic
      time algorithms for the general case where chains support anchor overlaps and
      gap costs are not currently known. We present algorithms to solve the colinear
      chaining problem with anchor overlaps and gap costs in \u00d5(n) time, where
      n denotes the count of anchors. The degree of the polylogarithmic factor depends
      on the type of anchors used (e.g., fixed-length anchors) and the type of precedence
      an optimal anchor chain is required to satisfy. We also establish the first
      theoretical connection between colinear chaining cost and edit distance. Specifically,
      we prove that for a fixed set of anchors under a carefully designed chaining
      cost function, the optimal \"anchored\" edit distance equals the optimal colinear
      chaining cost. The anchored edit distance for two sequences and a set of anchors
      is only a slight generalization of the standard edit distance. It adds an additional
      cost of one to an alignment of two matching symbols that are not supported by
      any anchor. Finally, we demonstrate experimentally that optimal colinear chaining
      cost under the proposed cost function can be computed orders of magnitude faster
      than edit distance, and achieves correlation coefficient >0.9 with edit distance
      for closely as well as distantly related sequences.", "venue": "J. Comput. Biol.",
      "year": 2022, "referenceCount": 0, "citationCount": 2, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Medicine"], "s2FieldsOfStudy": [{"category": "Computer Science",
      "source": "external"}, {"category": "Medicine", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2022-11-01", "journal": {"name": "Journal of computational
      biology : a journal of computational molecular cell biology", "pages": "\n          1237-1251\n        ",
      "volume": "29 11"}, "citationStyles": {"bibtex": "@Article{Jain2022AlgorithmsFC,\n
      author = {Chirag Jain and Daniel Gibney and Sharma V. Thankachan},\n booktitle
      = {J. Comput. Biol.},\n journal = {Journal of computational biology : a journal
      of computational molecular cell biology},\n pages = {\n          1237-1251\n        },\n
      title = {Algorithms for Colinear Chaining with Overlaps and Gap Costs},\n volume
      = {29 11},\n year = {2022}\n}\n"}, "authors": [{"authorId": "145196266", "name":
      "Chirag Jain"}, {"authorId": "38372154", "name": "Daniel Gibney"}, {"authorId":
      "1733907", "name": "Sharma V. Thankachan"}]}, {"paperId": "2c833bb1f73abf9e7772b8f0fd9303088689aa34",
      "externalIds": {"DBLP": "journals/corr/abs-2211-12496", "ArXiv": "2211.12496",
      "DOI": "10.48550/arXiv.2211.12496", "CorpusId": 253761173}, "corpusId": 253761173,
      "publicationVenue": {"id": "7f22f2c3-81fc-4aa8-8501-b1d58b193fa5", "name": "Information
      Technology Convergence and Services", "type": "conference", "alternate_names":
      ["Innov Theor Comput Sci", "ITCS ", "Inf Technol Converg Serv", "Information
      Technology and Computer Science", "Inf Technol Comput Sci", "Conf Innov Theor
      Comput Sci", "Conference on Innovations in Theoretical Computer Science", "Innovations
      in Theoretical Computer Science", "ITCS"], "url": "http://itcs-conf.org/"},
      "url": "https://www.semanticscholar.org/paper/2c833bb1f73abf9e7772b8f0fd9303088689aa34",
      "title": "An Algorithmic Bridge Between Hamming and Levenshtein Distances",
      "abstract": "The edit distance between strings classically assigns unit cost
      to every character insertion, deletion, and substitution, whereas the Hamming
      distance only allows substitutions. In many real-life scenarios, insertions
      and deletions (abbreviated indels) appear frequently but significantly less
      so than substitutions. To model this, we consider substitutions being cheaper
      than indels, with cost $1/a$ for a parameter $a\\ge 1$. This basic variant,
      denoted $ED_a$, bridges classical edit distance ($a=1$) with Hamming distance
      ($a\\to\\infty$), leading to interesting algorithmic challenges: Does the time
      complexity of computing $ED_a$ interpolate between that of Hamming distance
      (linear time) and edit distance (quadratic time)? What about approximating $ED_a$?
      We first present a simple deterministic exact algorithm for $ED_a$ and further
      prove that it is near-optimal assuming the Orthogonal Vectors Conjecture. Our
      main result is a randomized algorithm computing a $(1+\\epsilon)$-approximation
      of $ED_a(X,Y)$, given strings $X,Y$ of total length $n$ and a bound $k\\ge ED_a(X,Y)$.
      For simplicity, let us focus on $k\\ge 1$ and a constant $\\epsilon>0$; then,
      our algorithm takes $\\tilde{O}(n/a + ak^3)$ time. Unless $a=\\tilde{O}(1)$
      and for small enough $k$, this running time is sublinear in $n$. We also consider
      a very natural version that asks to find a $(k_I, k_S)$-alignment -- an alignment
      with at most $k_I$ indels and $k_S$ substitutions. In this setting, we give
      an exact algorithm and, more importantly, an $\\tilde{O}(nk_I/k_S + k_S\\cdot
      k_I^3)$-time $(1,1+\\epsilon)$-bicriteria approximation algorithm. The latter
      solution is based on the techniques we develop for $ED_a$ for $a=\\Theta(k_S
      / k_I)$. These bounds are in stark contrast to unit-cost edit distance, where
      state-of-the-art algorithms are far from achieving $(1+\\epsilon)$-approximation
      in sublinear time, even for a favorable choice of $k$.", "venue": "Information
      Technology Convergence and Services", "year": 2022, "referenceCount": 42, "citationCount":
      1, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://arxiv.org/pdf/2211.12496", "status": "GREEN"}, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2022-11-22", "journal": {"pages": "58:1-58:23"}, "citationStyles": {"bibtex":
      "@Article{Goldenberg2022AnAB,\n author = {Elazar Goldenberg and T. Kociumaka
      and Robert Krauthgamer and B. Saha},\n booktitle = {Information Technology Convergence
      and Services},\n pages = {58:1-58:23},\n title = {An Algorithmic Bridge Between
      Hamming and Levenshtein Distances},\n year = {2022}\n}\n"}, "authors": [{"authorId":
      "1752311", "name": "Elazar Goldenberg"}, {"authorId": "1683073", "name": "T.
      Kociumaka"}, {"authorId": "1737712", "name": "Robert Krauthgamer"}, {"authorId":
      "3269130", "name": "B. Saha"}]}, {"paperId": "c1ffcc2e43bc54c238f9f066ec80014d9d07a0a5",
      "externalIds": {"MAG": "3034924176", "DBLP": "conf/stoc/ChechikC20", "DOI":
      "10.1145/3357713.3384253", "CorpusId": 219398366}, "corpusId": 219398366, "publicationVenue":
      {"id": "8113a511-e0d9-4231-a1bc-0bf5d0212a4e", "name": "Symposium on the Theory
      of Computing", "type": "conference", "alternate_names": ["Symp Theory Comput",
      "STOC"], "url": "http://acm-stoc.org/"}, "url": "https://www.semanticscholar.org/paper/c1ffcc2e43bc54c238f9f066ec80014d9d07a0a5",
      "title": "Distance sensitivity oracles with subcubic preprocessing time and
      fast query time", "abstract": "We present the first distance sensitivity oracle
      (DSO) with subcubic preprocessing time and poly-logarithmic query time for directed
      graphs with integer weights in the range [\u2212M,M]. Weimann and Yuster [FOCS
      10] presented a distance sensitivity oracle for a single vertex/edge failure
      with subcubic preprocessing time of O(Mn \u03c9+1\u2212\u03b1) and subquadratic
      query time of \u00d5(n 1+\u03b1), where \u03b1 is any parameter in [0,1], n
      is the number of vertices, m is the number of edges, the \u00d5(\u00b7) notation
      hides poly-logarithmic factors in n and \u03c9<2.373 is the matrix multiplication
      exponent. Later, Grandoni and Vassilevska Williams [FOCS 12] substantially improved
      the query time to sublinear in n. In particular, they presented a distance sensitivity
      oracle for a single vertex/edge failure with \u00d5(Mn \u03c9+1/2+ Mn \u03c9+\u03b1(4\u2212\u03c9))
      preprocessing time and \u00d5(n 1\u2212\u03b1) query time. Despite the substantial
      improvement in the query time, it still remains polynomial in the size of the
      graph, which may be undesirable in many settings where the graph is of large
      scale. A natural question is whether one can hope for a distance sensitivity
      oracle with subcubic preprocessing time and very fast query time (of poly-logarithmic
      in n). In this paper we answer this question affirmatively by presenting a distance
      sensitive oracle supporting a single vertex/edge failure in subcubic \u00d5(Mn
      2.873) preprocessing time for \u03c9=2.373, \u00d5(n 2.5) space and near optimal
      query time of \u00d5(1). For comparison, with the same \u00d5(Mn 2.873) preprocessing
      time the DSO of Grandoni and Vassilevska Williams has \u00d5(n 0.693) query
      time. In fact, the best query time their algorithm can obtain is (Mn 0.385)
      (with (Mn 3) preprocessing time).", "venue": "Symposium on the Theory of Computing",
      "year": 2020, "referenceCount": 24, "citationCount": 19, "influentialCitationCount":
      1, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["Book", "JournalArticle", "Conference"],
      "publicationDate": "2020-06-22", "journal": {"name": "Proceedings of the 52nd
      Annual ACM SIGACT Symposium on Theory of Computing"}, "citationStyles": {"bibtex":
      "@Book{Chechik2020DistanceSO,\n author = {S. Chechik and S. Cohen},\n booktitle
      = {Symposium on the Theory of Computing},\n journal = {Proceedings of the 52nd
      Annual ACM SIGACT Symposium on Theory of Computing},\n title = {Distance sensitivity
      oracles with subcubic preprocessing time and fast query time},\n year = {2020}\n}\n"},
      "authors": [{"authorId": "1725512", "name": "S. Chechik"}, {"authorId": "32626049",
      "name": "S. Cohen"}]}, {"paperId": "625fbb7ed657ca111e4eebd03bc023220d582862",
      "externalIds": {"ArXiv": "1908.10935", "DBLP": "journals/corr/abs-1908-10935",
      "MAG": "2970227627", "DOI": "10.4171/msl/29", "CorpusId": 201668974}, "corpusId":
      201668974, "publicationVenue": {"id": "d93b1d3f-e963-4181-8f5e-33f17fccae36",
      "name": "Mathematical Statistics and Learning", "alternate_names": ["Math Stat
      Learn"], "issn": "2520-2316", "url": "https://www.ems-ph.org/journals/journal.php?jrn=msl"},
      "url": "https://www.semanticscholar.org/paper/625fbb7ed657ca111e4eebd03bc023220d582862",
      "title": "Randomly initialized EM algorithm for two-component Gaussian mixture
      achieves near optimality in O(\u221an) iterations", "abstract": "We analyze
      the classical EM algorithm for parameter estimation in the symmetric two-component
      Gaussian mixtures in $d$ dimensions. We show that, even in the absence of any
      separation between components, provided that the sample size satisfies $n=\\Omega(d
      \\log^3 d)$, the randomly initialized EM algorithm converges to an estimate
      in at most $O(\\sqrt{n})$ iterations with high probability, which is at most
      $O((\\frac{d \\log^3 n}{n})^{1/4})$ in Euclidean distance from the true parameter
      and within logarithmic factors of the minimax rate of $(\\frac{d}{n})^{1/4}$.
      Both the nonparametric statistical rate and the sublinear convergence rate are
      direct consequences of the zero Fisher information in the worst case. Refined
      pointwise guarantees beyond worst-case analysis and convergence to the MLE are
      also shown under mild conditions. \nThis improves the previous result of Balakrishnan
      et al \\cite{BWY17} which requires strong conditions on both the separation
      of the components and the quality of the initialization, and that of Daskalakis
      et al \\cite{DTZ17} which requires sample splitting and restarting the EM iteration.",
      "venue": "Mathematical Statistics and Learning", "year": 2019, "referenceCount":
      48, "citationCount": 29, "influentialCitationCount": 4, "isOpenAccess": true,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Mathematics"],
      "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2019-08-28", "journal":
      {"name": "ArXiv", "volume": "abs/1908.10935"}, "citationStyles": {"bibtex":
      "@Article{Wu2019RandomlyIE,\n author = {Yihong Wu and Harrison H. Zhou},\n booktitle
      = {Mathematical Statistics and Learning},\n journal = {ArXiv},\n title = {Randomly
      initialized EM algorithm for two-component Gaussian mixture achieves near optimality
      in O(\u221an) iterations},\n volume = {abs/1908.10935},\n year = {2019}\n}\n"},
      "authors": [{"authorId": "2115665083", "name": "Yihong Wu"}, {"authorId": "144021304",
      "name": "Harrison H. Zhou"}]}, {"paperId": "c9ac4909bd56d1728034d0f6a1227b4bed0a1c69",
      "externalIds": {"DBLP": "journals/corr/abs-2309-03810", "ArXiv": "2309.03810",
      "DOI": "10.48550/arXiv.2309.03810", "CorpusId": 261582395}, "corpusId": 261582395,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/c9ac4909bd56d1728034d0f6a1227b4bed0a1c69",
      "title": "Three Hardness Results for Graph Similarity Problems", "abstract":
      "Notions of graph similarity provide alternative perspective on the graph isomorphism
      problem and vice-versa. In this paper, we consider measures of similarity arising
      from mismatch norms as studied in Gervens and Grohe: the edit distance $\\delta_{\\mathcal{E}}$,
      and the metrics arising from $\\ell_p$-operator norms, which we denote by $\\delta_p$
      and $\\delta_{|p|}$. We address the following question: can these measures of
      similarity be used to design polynomial-time approximation algorithms for graph
      isomorphism? We show that computing an optimal value of $\\delta_{\\mathcal{E}}$
      is \\NP-hard on pairs of graphs with the same number of edges. In addition,
      we show that computing optimal values of $\\delta_p$ and $\\delta_{|p|}$ is
      \\NP-hard even on pairs of $1$-planar graphs with the same degree sequence and
      bounded degree. These two results improve on previous known ones, which did
      not examine the restricted case where the pairs of graphs are required to have
      the same number of edges. Finally, we study similarity problems on strongly
      regular graphs and prove some near optimal inequalities with interesting consequences
      on the computational complexity of graph and group isomorphism.", "venue": "arXiv.org",
      "year": 2023, "referenceCount": 23, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/2309.03810",
      "status": "CLOSED"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-09-07", "journal":
      {"name": "ArXiv", "volume": "abs/2309.03810"}, "citationStyles": {"bibtex":
      "@Article{Sun2023ThreeHR,\n author = {He Sun and Danny Vagnozzi},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {Three Hardness Results for Graph
      Similarity Problems},\n volume = {abs/2309.03810},\n year = {2023}\n}\n"}, "authors":
      [{"authorId": "2238388617", "name": "He Sun"}, {"authorId": "133864599", "name":
      "Danny Vagnozzi"}]}, {"paperId": "4f6a877ba569f5ff61a56a026ce1895fb718a08b",
      "externalIds": {"DBLP": "conf/recomb/JainGT22", "DOI": "10.1101/2021.02.03.429492",
      "CorpusId": 231885560}, "corpusId": 231885560, "publicationVenue": {"id": "027ffd21-ebb0-4af8-baf5-911124292fd0",
      "name": "bioRxiv", "type": "journal", "url": "http://biorxiv.org/"}, "url":
      "https://www.semanticscholar.org/paper/4f6a877ba569f5ff61a56a026ce1895fb718a08b",
      "title": "Co-linear Chaining with Overlaps and Gap Costs", "abstract": "Co-linear
      chaining has proven to be a powerful heuristic for finding near-optimal alignments
      of long DNA sequences (e.g., long reads or a genome assembly) to a reference.
      It is used as an intermediate step in several alignment tools that employ a
      seed-chain-extend strategy. Despite this popularity, efficient subquadratic-time
      algorithms for the general case where chains support anchor overlaps and gap
      costs are not currently known. We present algorithms to solve the co-linear
      chaining problem with anchor overlaps and gap costs in \u00d5(n) time, where
      n denotes the count of anchors. We also establish the first theoretical connection
      between co-linear chaining cost and edit distance. Specifically, we prove that
      for a fixed set of anchors under a carefully designed chaining cost function,
      the optimal \u2018anchored\u2019 edit distance equals the optimal co-linear
      chaining cost. Finally, we demonstrate experimentally that optimal co-linear
      chaining cost under the proposed cost function can be computed orders of magnitude
      faster than edit distance, and achieves correlation coefficient above 0.9 with
      edit distance for closely as well as distantly related sequences.", "venue":
      "bioRxiv", "year": 2021, "referenceCount": 36, "citationCount": 18, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": null, "fieldsOfStudy": ["Biology",
      "Computer Science"], "s2FieldsOfStudy": [{"category": "Biology", "source": "external"},
      {"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2021-02-03", "journal": {"name": "bioRxiv"}, "citationStyles":
      {"bibtex": "@Article{Jain2021ColinearCW,\n author = {Chirag Jain and Daniel
      Gibney and Sharma V. Thankachan},\n booktitle = {bioRxiv},\n journal = {bioRxiv},\n
      title = {Co-linear Chaining with Overlaps and Gap Costs},\n year = {2021}\n}\n"},
      "authors": [{"authorId": "145196266", "name": "Chirag Jain"}, {"authorId": "38372154",
      "name": "Daniel Gibney"}, {"authorId": "1733907", "name": "Sharma V. Thankachan"}]},
      {"paperId": "c579d931ae83951c940d23196f8c079312dcf8c0", "externalIds": {"PubMedCentral":
      "4172526", "MAG": "2080019484", "DOI": "10.1371/journal.pone.0107510", "CorpusId":
      17199791, "PubMed": "25247892"}, "corpusId": 17199791, "publicationVenue": {"id":
      "0aed7a40-85f3-4c66-9e1b-c1556c57001b", "name": "PLoS ONE", "type": "journal",
      "alternate_names": ["Plo ONE", "PLOS ONE", "PLO ONE"], "issn": "1932-6203",
      "url": "https://journals.plos.org/plosone/", "alternate_urls": ["http://www.plosone.org/"]},
      "url": "https://www.semanticscholar.org/paper/c579d931ae83951c940d23196f8c079312dcf8c0",
      "title": "Taxamatch, an Algorithm for Near (\u2018Fuzzy\u2019) Matching of Scientific
      Names in Taxonomic Databases", "abstract": "Misspellings of organism scientific
      names create barriers to optimal storage and organization of biological data,
      reconciliation of data stored under different spelling variants of the same
      name, and appropriate responses from user queries to taxonomic data systems.
      This study presents an analysis of the nature of the problem from first principles,
      reviews some available algorithmic approaches, and describes Taxamatch, an improved
      name matching solution for this information domain. Taxamatch employs a custom
      Modified Damerau-Levenshtein Distance algorithm in tandem with a phonetic algorithm,
      together with a rule-based approach incorporating a suite of heuristic filters,
      to produce improved levels of recall, precision and execution time over the
      existing dynamic programming algorithms n-grams (as bigrams and trigrams) and
      standard edit distance. Although entirely phonetic methods are faster than Taxamatch,
      they are inferior in the area of recall since many real-world errors are non-phonetic
      in nature. Excellent performance of Taxamatch (as recall, precision and execution
      time) is demonstrated against a reference database of over 465,000 genus names
      and 1.6 million species names, as well as against a range of error types as
      present at both genus and species levels in three sets of sample data for species
      and four for genera alone. An ancillary authority matching component is included
      which can be used both for misspelled names and for otherwise matching names
      where the associated cited authorities are not identical.", "venue": "PLoS ONE",
      "year": 2014, "referenceCount": 79, "citationCount": 44, "influentialCitationCount":
      1, "isOpenAccess": true, "openAccessPdf": {"url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0107510&type=printable",
      "status": "GOLD"}, "fieldsOfStudy": ["Computer Science", "Medicine"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Medicine",
      "source": "external"}, {"category": "Biology", "source": "s2-fos-model"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
      "Review"], "publicationDate": "2014-09-23", "journal": {"name": "PLoS ONE",
      "volume": "9"}, "citationStyles": {"bibtex": "@Article{Rees2014TaxamatchAA,\n
      author = {Anthony J. J. (Tony) Rees},\n booktitle = {PLoS ONE},\n journal =
      {PLoS ONE},\n title = {Taxamatch, an Algorithm for Near (\u2018Fuzzy\u2019)
      Matching of Scientific Names in Taxonomic Databases},\n volume = {9},\n year
      = {2014}\n}\n"}, "authors": [{"authorId": "48125744", "name": "Anthony J. J.
      (Tony) Rees"}]}, {"paperId": "31c607d80105842ec9c0dc8e142cedbfd948d078", "externalIds":
      {"DBLP": "journals/corr/abs-2209-05676", "ArXiv": "2209.05676", "DOI": "10.1109/TIT.2023.3289981",
      "CorpusId": 252211913}, "corpusId": 252211913, "publicationVenue": {"id": "748e730b-add9-47ee-819d-8ae54e504ef9",
      "name": "IEEE Transactions on Information Theory", "type": "journal", "alternate_names":
      ["IEEE Trans Inf Theory"], "issn": "0018-9448", "url": "http://www.comm.utoronto.ca/trans-it/",
      "alternate_urls": ["https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?puNumber=18",
      "http://ieeexplore.ieee.org/servlet/opac?punumber=18"]}, "url": "https://www.semanticscholar.org/paper/31c607d80105842ec9c0dc8e142cedbfd948d078",
      "title": "Recovery From Non-Decomposable Distance Oracles", "abstract": "A line
      of work has looked at the problem of recovering an input from distance queries.
      In this setting, there is an unknown sequence <inline-formula> <tex-math notation=\"LaTeX\">$s
      \\in \\{0,1\\}^{\\leq n}$ </tex-math></inline-formula>, and one chooses a set
      of queries <inline-formula> <tex-math notation=\"LaTeX\">$y \\in \\{0,1\\}^{
      \\mathcal {O}(n)}$ </tex-math></inline-formula> and receives <inline-formula>
      <tex-math notation=\"LaTeX\">$d(s,y)$ </tex-math></inline-formula> for a distance
      function <inline-formula> <tex-math notation=\"LaTeX\">$d$ </tex-math></inline-formula>.
      The goal is to make as few queries as possible to recover <inline-formula> <tex-math
      notation=\"LaTeX\">$s$ </tex-math></inline-formula>. Although this problem is
      well-studied for decomposable distances, i.e., distances of the form <inline-formula>
      <tex-math notation=\"LaTeX\">$d(s,y) = \\sum _{i=1}^{n} f(s_{i}, y_{i})$ </tex-math></inline-formula>
      for some function <inline-formula> <tex-math notation=\"LaTeX\">$f$ </tex-math></inline-formula>,
      which includes the important cases of Hamming distance, <inline-formula> <tex-math
      notation=\"LaTeX\">$\\ell _{p}$ </tex-math></inline-formula>-norms, and <inline-formula>
      <tex-math notation=\"LaTeX\">$M$ </tex-math></inline-formula>-estimators, to
      the best of our knowledge this problem has not been studied for non-decomposable
      distances, for which there are important instances including edit distance,
      dynamic time warping (DTW), Fr\u00e9chet distance, earth mover\u2019s distance,
      and others. We initiate the study and develop a general framework for such distances.
      Interestingly, for some distances such as DTW or Fr\u00e9chet, exact recovery
      of the sequence <inline-formula> <tex-math notation=\"LaTeX\">$s$ </tex-math></inline-formula>
      is provably impossible, and so we show by allowing the characters in <inline-formula>
      <tex-math notation=\"LaTeX\">$y$ </tex-math></inline-formula> to be drawn from
      a slightly larger alphabet this then becomes possible. In a number of cases
      we obtain optimal or near-optimal query complexity. One motivation for understanding
      non-adaptivity is that the query sequence can be fixed and provide a non-linear
      embedding of the input, which can be used in downstream applications involving,
      e.g., neural networks for natural language processing.", "venue": "IEEE Transactions
      on Information Theory", "year": 2022, "referenceCount": 60, "citationCount":
      1, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://drops.dagstuhl.de/opus/volltexte/2023/17576/pdf/LIPIcs-ITCS-2023-73.pdf",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2022-09-13", "journal": {"name": "IEEE
      Transactions on Information Theory", "pages": "6443-6469", "volume": "69"},
      "citationStyles": {"bibtex": "@Article{Hu2022RecoveryFN,\n author = {Zhuangfei
      Hu and Xinda Li and David P. Woodruff and Hongyang Zhang and Shufan Zhang},\n
      booktitle = {IEEE Transactions on Information Theory},\n journal = {IEEE Transactions
      on Information Theory},\n pages = {6443-6469},\n title = {Recovery From Non-Decomposable
      Distance Oracles},\n volume = {69},\n year = {2022}\n}\n"}, "authors": [{"authorId":
      "2219820651", "name": "Zhuangfei Hu"}, {"authorId": "2108782531", "name": "Xinda
      Li"}, {"authorId": "143982862", "name": "David P. Woodruff"}, {"authorId": "40975176",
      "name": "Hongyang Zhang"}, {"authorId": "48691326", "name": "Shufan Zhang"}]},
      {"paperId": "9e8bb71eac9a11bc9593b64c405d066ce6da7d80", "externalIds": {"DBLP":
      "conf/icalp/BringmannD21", "ArXiv": "2106.08195", "DOI": "10.1145/3568398",
      "CorpusId": 235436184}, "corpusId": 235436184, "publicationVenue": {"id": "d024be26-06b0-4afe-8fa3-a297e04fe604",
      "name": "International Colloquium on Automata, Languages and Programming", "type":
      "conference", "alternate_names": ["Int Conf Arab Lang Process", "International
      Conference on Arabic Language Processing", "Int Colloq Autom Lang Program",
      "ICALP"], "url": "http://www.eatcs.org/"}, "url": "https://www.semanticscholar.org/paper/9e8bb71eac9a11bc9593b64c405d066ce6da7d80",
      "title": "A Linear-Time n0.4-Approximation for Longest Common Subsequence",
      "abstract": "We consider the classic problem of computing the Longest Common
      Subsequence (LCS) of two strings of length n. The 40-year-old quadratic-time
      dynamic programming algorithm has recently been shown to be near-optimal by
      Abboud, Backurs, and Vassilevska Williams [FOCS\u201915] and Bringmann and K\u00fcnnemann
      [FOCS\u201915] assuming the Strong Exponential Time Hypothesis. This has led
      the community to look for subquadratic approximation algorithms for the problem.
      Yet, unlike the edit distance problem for which a constant-factor approximation
      in almost-linear time is known, very little progress has been made on LCS, making
      it a notoriously difficult problem also in the realm of approximation. For the
      general setting, only a naive O(n\u025b/2-approximation algorithm with running
      time O\u0160(n2-\u025b has been known, for any constant 0 < \u025b \u2264 1.
      Recently, a breakthrough result by Hajiaghayi, Seddighin, Seddighin, and Sun
      [SODA\u201919] provided a linear-time algorithm that yields a O(n0.497956-approximation
      in expectation; improving upon the naive \\(O(\\sqrt {n})\\) -approximation
      for the first time. In this paper, we provide an algorithm that in time O(n2-\u025b)
      computes an O\u0160(n2\u025b/5-approximation with high probability, for any
      0 < \u025b \u2264 1. Our result (1) gives an O\u0160(n0.4-approximation in linear
      time, improving upon the bound of Hajiaghayi, Seddighin, Seddighin, and Sun,
      (2) provides an algorithm whose approximation scales with any subquadratic running
      time O(n2-\u025b), improving upon the naive bound of O(n\u025b/2) for any \u025b,
      and (3) instead of only in expectation, succeeds with high probability.", "venue":
      "International Colloquium on Automata, Languages and Programming", "year": 2021,
      "referenceCount": 46, "citationCount": 6, "influentialCitationCount": 0, "isOpenAccess":
      true, "openAccessPdf": {"url": "https://dl.acm.org/doi/pdf/10.1145/3568398",
      "status": "BRONZE"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2021-06-15",
      "journal": {"name": "ACM Transactions on Algorithms", "pages": "1 - 24", "volume":
      "19"}, "citationStyles": {"bibtex": "@Article{Bringmann2021ALN,\n author = {K.
      Bringmann and Vincent Cohen-Addad and Debarati Das},\n booktitle = {International
      Colloquium on Automata, Languages and Programming},\n journal = {ACM Transactions
      on Algorithms},\n pages = {1 - 24},\n title = {A Linear-Time n0.4-Approximation
      for Longest Common Subsequence},\n volume = {19},\n year = {2021}\n}\n"}, "authors":
      [{"authorId": "2535238", "name": "K. Bringmann"}, {"authorId": "1403027144",
      "name": "Vincent Cohen-Addad"}, {"authorId": null, "name": "Debarati Das"}]},
      {"paperId": "c6ee88b50084fa7f33a23a5e1d4ed8b30f453550", "externalIds": {"DBLP":
      "conf/fsttcs/Chakraborty0K21", "ArXiv": "2107.09497", "DOI": "10.4230/LIPIcs.FSTTCS.2021.11",
      "CorpusId": 236134500}, "corpusId": 236134500, "publicationVenue": {"id": "0398fa1f-37da-4d9e-b0a2-1cae8e598047",
      "name": "Foundations of Software Technology and Theoretical Computer Science",
      "type": "conference", "alternate_names": ["Found Softw Technol Theor Comput
      Sci", "Int Conf Found Softw Technol Theor Comput Sci", "FSTTCS", "International
      Conference on Foundation of Software Technology and Theoretical Computer Science"],
      "url": "http://www.fsttcs.org/"}, "url": "https://www.semanticscholar.org/paper/c6ee88b50084fa7f33a23a5e1d4ed8b30f453550",
      "title": "Approximate Trace Reconstruction via Median String (in Average-Case)",
      "abstract": "We consider an \\emph{approximate} version of the trace reconstruction
      problem, where the goal is to recover an unknown string $s\\in\\{0,1\\}^n$ from
      $m$ traces (each trace is generated independently by passing $s$ through a probabilistic
      insertion-deletion channel with rate $p$). We present a deterministic near-linear
      time algorithm for the average-case model, where $s$ is random, that uses only
      \\emph{three} traces. It runs in near-linear time $\\tilde O(n)$ and with high
      probability reports a string within edit distance $O(\\epsilon p n)$ from $s$
      for $\\epsilon=\\tilde O(p)$, which significantly improves over the straightforward
      bound of $O(pn)$. Technically, our algorithm computes a $(1+\\epsilon)$-approximate
      median of the three input traces. To prove its correctness, our probabilistic
      analysis shows that an approximate median is indeed close to the unknown $s$.
      To achieve a near-linear time bound, we have to bypass the well-known dynamic
      programming algorithm that computes an optimal median in time $O(n^3)$.", "venue":
      "Foundations of Software Technology and Theoretical Computer Science", "year":
      2021, "referenceCount": 54, "citationCount": 4, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle", "Conference"], "publicationDate": "2021-07-20", "journal":
      {"pages": "11:1-11:23"}, "citationStyles": {"bibtex": "@Article{Chakraborty2021ApproximateTR,\n
      author = {Diptarka Chakraborty and Debarati Das and Robert Krauthgamer},\n booktitle
      = {Foundations of Software Technology and Theoretical Computer Science},\n pages
      = {11:1-11:23},\n title = {Approximate Trace Reconstruction via Median String
      (in Average-Case)},\n year = {2021}\n}\n"}, "authors": [{"authorId": "29846222",
      "name": "Diptarka Chakraborty"}, {"authorId": null, "name": "Debarati Das"},
      {"authorId": "1737712", "name": "Robert Krauthgamer"}]}, {"paperId": "b6b55bf181beba096144aa1a16df9b6f9530c5a3",
      "externalIds": {"MAG": "3037365099", "DBLP": "conf/cpm/Charalampopoulos20a",
      "DOI": "10.4230/LIPIcs.CPM.2020.9", "CorpusId": 219553664}, "corpusId": 219553664,
      "publicationVenue": {"id": "25085e3f-671a-46a2-a7d6-dd5563940ec8", "name": "Annual
      Symposium on Combinatorial Pattern Matching", "type": "conference", "alternate_names":
      ["CPM", "Comb Pattern Matching", "Combinatorial Pattern Matching", "Annu Symp
      Comb Pattern Matching"], "url": "http://www.cs.ucr.edu/~stelo/cpm/"}, "url":
      "https://www.semanticscholar.org/paper/b6b55bf181beba096144aa1a16df9b6f9530c5a3",
      "title": "Dynamic String Alignment", "abstract": "We consider the problem of
      dynamically maintaining an optimal alignment of two strings, each of length
      at most n, as they undergo insertions, deletions, and substitutions of letters.
      The string alignment problem generalizes the longest common subsequence (LCS)
      problem and the edit distance problem (also with non-unit costs, as long as
      insertions and deletions cost the same). The conditional lower bound of Backurs
      and Indyk [J. Comput. 2018] for computing the LCS in the static case implies
      that strongly sublinear update time for the dynamic string alignment problem
      would refute the Strong Exponential Time Hypothesis. We essentially match this
      lower bound when the alignment weights are constants, by showing how to process
      each update in \u00d5(n) time.1 When the weights are integers bounded in absolute
      value by some w = nO(1), we can maintain the alignment in \u00d5(n \u00b7min{
      \u221a n, w}) time per update. For the \u00d5(nw)-time algorithm, we heavily
      rely on Tiskin\u2019s work on semi-local LCS, and in particular, in an implicit
      way, on his algorithm for computing the (min, +)-product of two simple unit-Monge
      matrices [Algorithmica 2015]. As for the \u00d5(n \u221a n)-time algorithm,
      we employ efficient data structures for computing distances in planar graphs.
      2012 ACM Subject Classification Theory of computation \u2192 Pattern matching",
      "venue": "Annual Symposium on Combinatorial Pattern Matching", "year": 2020,
      "referenceCount": 39, "citationCount": 14, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": null, "journal": {"pages": "9:1-9:13"}, "citationStyles":
      {"bibtex": "@Article{Charalampopoulos2020DynamicSA,\n author = {P. Charalampopoulos
      and T. Kociumaka and S. Mozes},\n booktitle = {Annual Symposium on Combinatorial
      Pattern Matching},\n pages = {9:1-9:13},\n title = {Dynamic String Alignment},\n
      year = {2020}\n}\n"}, "authors": [{"authorId": "3440697", "name": "P. Charalampopoulos"},
      {"authorId": "1683073", "name": "T. Kociumaka"}, {"authorId": "34762109", "name":
      "S. Mozes"}]}, {"paperId": "d8c1c979f247e57902dc7ab9ddcee4651af1feff", "externalIds":
      {"MAG": "1537954077", "DBLP": "phd/ndltd/Onak10", "CorpusId": 11604393}, "corpusId":
      11604393, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/d8c1c979f247e57902dc7ab9ddcee4651af1feff",
      "title": "New sublinear methods in the struggle against classical problems",
      "abstract": "We study the time and query complexity of approximation algorithms
      that access only a minuscule fraction of the input, focusing on two classical
      sources of problems: combinatorial graph optimization and manipulation of strings.
      The tools we develop find applications outside of the area of sublinear algorithms.
      For instance, we obtain a more efficient approximation algorithm for edit distance
      and distributed algorithms for combinatorial problems on graphs that run in
      a constant number of communication rounds. \nCombinatorial graph optimization
      problems: The graph optimization problems considered by us include vertex cover,
      maximum matching, and dominating set. A graph algorithm is traditionally called
      a constant-time algorithm if it runs in time that is a function of only the
      maximum vertex degree, and in particular, does not depend on the number of vertices
      in the graph. \nWe show a general local computation framework that allows for
      transforming many classical greedy approximation algorithms into constant-time
      approximation algorithms for the optimal solution size. By applying the framework,
      we obtain the first constant-time algorithm that approximates the maximum matching
      size up to an additive en, where e is an arbitrary positive constant, and n
      is the number of vertices in the graph. \nIt is known that a purely additive
      en approximation is not computable in constant time for vertex cover and dominating
      set. We show that nevertheless, such an approximation is possible for a wide
      class of graphs, which includes planar graphs (and other minor-free families
      of graphs) and graphs of subexponential growth (a common property of networks).
      This result is obtained via locally computing a good partition of the input
      graph in our local computation framework. \nThe tools and algorithms developed
      for these problems find several other applications: (1) Our methods can be used
      to construct local distributed approximation algorithms for some combinatorial
      optimization problems. (2) Our matching algorithm yields the first constant-time
      testing algorithm for distinguishing bounded-degree graphs that have a perfect
      matching from those far from having this property. (3) We give a simple proof
      that there is a constant-time algorithm distinguishing bounded-degree graphs
      that are planar (or in general, have a minor-closed property) from those that
      are far from planarity (or the given minor-closed property, respectively). Our
      tester is also much more efficient than the original tester of Benjamini, Schramm,
      and Shapira (STOC 2008). \nEdit distance: We study a new asymmetric query model
      for edit distance. In this model, the input consists of two strings x and y,
      and an algorithm can access y in an unrestricted manner (without charge), while
      being charged for querying every symbol of x. \nWe design an algorithm in the
      asymmetric query model that makes a small number of queries to distinguish the
      case when the edit distance between x and y is small from the case when it is
      large. Our result in the asymmetric query model gives rise to a near-linear
      time algorithm that approximates the edit distance between two strings to within
      a polylogarithmic factor. For strings of length n and every fixed e > 0, the
      algorithm computes a (log n)O(1/e) approximation in n1+e time. This is an exponential
      improvement over the previously known near-linear time approximation factor
      2Odlog n (Andoni and Onak, STOC 2009; building on Ostrovsky and Rabani, J. ACM
      2007). The algorithm of Andoni and Onak was the first to run in O(n2\u2013\u03b4)
      time, for any fixed constant \u03b4 > 0, and obtain a subpolynomial, n o(1),
      approximation factor, despite a sequence of papers. \nWe provide a nearly-matching
      lower bound on the number of queries. Our lower bound is the first to expose
      hardness of edit distance stemming from the input strings being \"repetitive\",
      which means that many of their substrings are approximately identical. Consequently,
      our lower bound provides the first rigorous separation on the complexity of
      approximation between edit distance and Ulam distance. (Copies available exclusively
      from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668;
      Fax 617-253-1690.)", "venue": "", "year": 2010, "referenceCount": 82, "citationCount":
      15, "influentialCitationCount": 4, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category":
      "Mathematics", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
      null, "journal": {"name": "", "volume": ""}, "citationStyles": {"bibtex": "@Inproceedings{Onak2010NewSM,\n
      author = {Krzysztof Onak},\n title = {New sublinear methods in the struggle
      against classical problems},\n year = {2010}\n}\n"}, "authors": [{"authorId":
      "1730859", "name": "Krzysztof Onak"}]}, {"paperId": "12d19744e03f9f1888fb2af1645cb1b8c0583cdb",
      "externalIds": {"DBLP": "conf/focs/RubinsteinSSS19", "ArXiv": "2111.10538",
      "MAG": "2971374205", "DOI": "10.1109/FOCS.2019.00071", "CorpusId": 202787397},
      "corpusId": 202787397, "publicationVenue": {"id": "68cf0e99-5164-4480-8ed4-8b8416a091df",
      "name": "IEEE Annual Symposium on Foundations of Computer Science", "type":
      "conference", "alternate_names": ["FOCS", "IEEE Annu Symp Found Comput Sci"],
      "url": "http://ieee-focs.org/"}, "url": "https://www.semanticscholar.org/paper/12d19744e03f9f1888fb2af1645cb1b8c0583cdb",
      "title": "Approximation Algorithms for LCS and LIS with Truly Improved Running
      Times", "abstract": "Longest common subsequence (LCS) is a classic and central
      problem in combinatorial optimization. While LCS admits a quadratic time solution,
      recent evidence suggests that solving the problem may be impossible in truly
      subquadratic time. A special case of LCS wherein each character appears at most
      once in every string is equivalent to the longest increasing subsequence problem
      (LIS) which can be solved in quasilinear time. In this work, we present novel
      algorithms for approximating LCS in truly subquadratic time and LIS in truly
      sublinear time. Our approximation factors depend on the ratio of the optimal
      solution size over the input size. We denote this ratio by \u03bb and obtain
      the following results for LCS and LIS without any prior knowledge of \u03bb.
      \u2022 A truly subquadratic time algorithm for LCS with approximation factor
      O(\u03bb^3). \u2022 A truly sublinear time algorithm for LIS with approximation
      factor O(\u03bb^3). Triangle inequality was recently used by Boroujeni et al.
      [1] and Chakraborty et al.[2] to present new approximation algorithms for edit
      distance. Our techniques for LCS extend the notion of triangle inequality to
      non-metric settings.", "venue": "IEEE Annual Symposium on Foundations of Computer
      Science", "year": 2019, "referenceCount": 37, "citationCount": 36, "influentialCitationCount":
      2, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/2111.10538",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-11-01", "journal": {"name": "2019
      IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS)", "pages":
      "1121-1145"}, "citationStyles": {"bibtex": "@Article{Rubinstein2019ApproximationAF,\n
      author = {A. Rubinstein and Saeed Seddighin and Zhao Song and Xiaorui Sun},\n
      booktitle = {IEEE Annual Symposium on Foundations of Computer Science},\n journal
      = {2019 IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS)},\n
      pages = {1121-1145},\n title = {Approximation Algorithms for LCS and LIS with
      Truly Improved Running Times},\n year = {2019}\n}\n"}, "authors": [{"authorId":
      "38651679", "name": "A. Rubinstein"}, {"authorId": "3087608", "name": "Saeed
      Seddighin"}, {"authorId": "143825455", "name": "Zhao Song"}, {"authorId": "1743608",
      "name": "Xiaorui Sun"}]}, {"paperId": "3c3ab51d2b9f5585d92e167338791a60a79d05ae",
      "externalIds": {"MAG": "2090320977", "DBLP": "conf/stoc/AndoniGMP13", "DOI":
      "10.1145/2488608.2488726", "CorpusId": 14930864}, "corpusId": 14930864, "publicationVenue":
      {"id": "8113a511-e0d9-4231-a1bc-0bf5d0212a4e", "name": "Symposium on the Theory
      of Computing", "type": "conference", "alternate_names": ["Symp Theory Comput",
      "STOC"], "url": "http://acm-stoc.org/"}, "url": "https://www.semanticscholar.org/paper/3c3ab51d2b9f5585d92e167338791a60a79d05ae",
      "title": "Homomorphic fingerprints under misalignments: sketching edit and shift
      distances", "abstract": "Fingerprinting is a widely-used technique for efficiently
      verifying that two files are identical. More generally, linear sketching is
      a form of lossy compression (based on random projections) that also enables
      the \"dissimilarity\" of non-identical files to be estimated. Many sketches
      have been proposed for dissimilarity measures that decompose coordinate-wise
      such as the Hamming distance between alphanumeric strings, or the Euclidean
      distance between vectors. However, virtually nothing is known on sketches that
      would accommodate alignment errors. With such errors, Hamming or Euclidean distances
      are rendered useless: a small misalignment may result in a file that looks very
      dissimilar to the original file according such measures. In this paper, we present
      the first linear sketch that is robust to a small number of alignment errors.
      Specifically, the sketch can be used to determine whether two files are within
      a small Hamming distance of being a cyclic shift of each other. Furthermore,
      the sketch is homomorphic with respect to rotations: it is possible to construct
      the sketch of a cyclic shift of a file given only the sketch of the original
      file. The relevant dissimilarity measure, known as the shift distance, arises
      in the context of embedding edit distance and our result addressed an open problem
      [Question 13 in Indyk-McGregor-Newman-Onak''11] with a rather surprising outcome.
      Our sketch projects a length $n$ file into D(n) \u22c5 polylog n dimensions
      where D(n)l n is the number of divisors of n. The striking fact is that this
      is near-optimal, i.e., the D(n) dependence is inherent to a problem that is
      ostensibly about lossy compression.\n In contrast, we then show that any sketch
      for estimating the edit distance between two files, even when small, requires
      sketches whose size is nearly linear in n. This lower bound addresses a long-standing
      open problem on the low distortion embeddings of edit distance [Question 2.15
      in Naor-Matousek''11, Indyk''01], for the case of linear embeddings.", "venue":
      "Symposium on the Theory of Computing", "year": 2013, "referenceCount": 47,
      "citationCount": 26, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy":
      [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2013-06-01", "journal":
      {"pages": "931-940"}, "citationStyles": {"bibtex": "@Article{Andoni2013HomomorphicFU,\n
      author = {Alexandr Andoni and Assaf Goldberger and A. Mcgregor and E. Porat},\n
      booktitle = {Symposium on the Theory of Computing},\n pages = {931-940},\n title
      = {Homomorphic fingerprints under misalignments: sketching edit and shift distances},\n
      year = {2013}\n}\n"}, "authors": [{"authorId": "1738395", "name": "Alexandr
      Andoni"}, {"authorId": "35243876", "name": "Assaf Goldberger"}, {"authorId":
      "144078750", "name": "A. Mcgregor"}, {"authorId": "2167957", "name": "E. Porat"}]},
      {"paperId": "f60477229cd7d2e11c1f80484dead929187a2060", "externalIds": {"DBLP":
      "journals/corr/abs-2011-06135", "MAG": "3102299369", "ArXiv": "2011.06135",
      "CorpusId": 226306672}, "corpusId": 226306672, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/f60477229cd7d2e11c1f80484dead929187a2060",
      "title": "Hardness of Approximate Nearest Neighbor Search under L-infinity",
      "abstract": "We show conditional hardness of Approximate Nearest Neighbor Search
      (ANN) under the $\\ell_\\infty$ norm with two simple reductions. Our first reduction
      shows that hardness of a special case of the Shortest Vector Problem (SVP),
      which captures many provably hard instances of SVP, implies a lower bound for
      ANN with polynomial preprocessing time under the same norm. Combined with a
      recent quantitative hardness result on SVP under $\\ell_\\infty$ (Bennett et
      al., FOCS 2017), our reduction implies that finding a $(1+\\varepsilon)$-approximate
      nearest neighbor under $\\ell_\\infty$ with polynomial preprocessing requires
      near-linear query time, unless the Strong Exponential Time Hypothesis (SETH)
      is false. This complements the results of Rubinstein (STOC 2018), who showed
      hardness of ANN under $\\ell_1$, $\\ell_2$, and edit distance. \nFurther improving
      the approximation factor for hardness, we show that, assuming SETH, near-linear
      query time is required for any approximation factor less than $3$ under $\\ell_\\infty$.
      This shows a conditional separation between ANN under the $\\ell_1/ \\ell_2$
      norm and the $\\ell_\\infty$ norm since there are sublinear time algorithms
      achieving better than $3$-approximation for the $\\ell_1$ and $\\ell_2$ norm.
      Lastly, we show that the approximation factor of $3$ is a barrier for any naive
      gadget reduction from the Orthogonal Vectors problem.", "venue": "arXiv.org",
      "year": 2020, "referenceCount": 44, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics",
      "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2020-11-12", "journal": {"name": "ArXiv", "volume": "abs/2011.06135"}, "citationStyles":
      {"bibtex": "@Article{Ko2020HardnessOA,\n author = {Young Kun Ko and M. Song},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Hardness of Approximate
      Nearest Neighbor Search under L-infinity},\n volume = {abs/2011.06135},\n year
      = {2020}\n}\n"}, "authors": [{"authorId": "2818412", "name": "Young Kun Ko"},
      {"authorId": "2110310498", "name": "M. Song"}]}, {"paperId": "2e2f6d6bedc569886fbda6ff42f2b4c05a597eda",
      "externalIds": {"MAG": "621782861", "CorpusId": 42793406}, "corpusId": 42793406,
      "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/2e2f6d6bedc569886fbda6ff42f2b4c05a597eda",
      "title": "Property testing: current research and surveys", "abstract": "Editor''s
      Introduction.- A Brief Introduction to Property Testing.- The Program of the
      Mini-Workshop.- Surveys.- Limitation on the Rate of Families of Locally Testable
      Codes.- Testing Juntas.- Sublinear-time Algorithms.- Short Locally Testable
      Codes and Proofs: A Survey in Two Parts.- Introduction to Testing Graph Properties.-
      Property Testing of Massively Parameterized Problems.- Sublinear Graph Approximation
      Algorithms.- Transitive-Closure Spanners.- Testing by Implicit Learning.- Invariance
      in Property Testing.- Extended Abstracts.- Testing Monotone Continuous Distributions
      on High-Dimensional Real Cubes.- On Constant Time Approximation of Parameters
      of Bounded Degree Graphs.- Sublinear Algorithms in the External Memory Model.-
      Polylogarithmic Approximation for Edit Distance and the Asymmetric Query Complexity.-
      Comparing the Strength of Query Types in Property Testing: The Case of Testing
      k-Colorability.- Testing Linear-Invariant Non-linear Properties: A Short Report.-
      Optimal Testing of Reed-Muller Codes.- Query-Efficient Dictatorship Testing
      with Perfect Completeness.- Composition of Low-Error 2-Query PCPs Using Decodable
      PCPs.- Hierarchy Theorems for Property Testing.- Algorithmic Aspects of Property
      Testing in the Dense Graphs Model.- Testing Euclidean Spanners.- Symmetric LDPCCodes
      and Local Testing.- Some Recent Results on Local Testing of Sparse Linear Codes.-
      Testing (Subclasses of) Halfspaces.- Dynamic Approximate Vertex Cover and Maximum
      Matching.- Local Property Reconstruction and Monotonicity.- Green''s Conjecture
      and Testing Linear Invariant Properties.", "venue": "", "year": 2010, "referenceCount":
      0, "citationCount": 99, "influentialCitationCount": 2, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Mathematics"], "s2FieldsOfStudy":
      [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["Review"], "publicationDate": null, "journal": {"name":
      "", "volume": ""}, "citationStyles": {"bibtex": "@Inproceedings{Goldreich2010PropertyTC,\n
      author = {Oded Goldreich},\n title = {Property testing: current research and
      surveys},\n year = {2010}\n}\n"}, "authors": [{"authorId": "1707322", "name":
      "Oded Goldreich"}]}, {"paperId": "42e6da096c606f638e51d7d5730e402c6e9d84eb",
      "externalIds": {"MAG": "3112348608", "DBLP": "journals/corr/abs-2012-06961",
      "ArXiv": "2012.06961", "CorpusId": 229153027}, "corpusId": 229153027, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/42e6da096c606f638e51d7d5730e402c6e9d84eb",
      "title": "Online Stochastic Optimization with Wasserstein Based Non-stationarity",
      "abstract": "We consider a general online stochastic optimization problem with
      multiple budget constraints over a horizon of finite time periods. At each time
      period, a reward function and multiple cost functions, where each cost function
      is involved in the consumption of one corresponding budget, are drawn from an
      unknown distribution, which is assumed to be non-stationary across time. Then,
      a decision maker needs to specify an action from a convex and compact action
      set to collect the reward, and the consumption each budget is determined jointly
      by the cost functions and the taken action. The objective of the decision maker
      is to maximize the cumulative reward subject to the budget constraints. Our
      model captures a wide range of applications including online linear programming
      and network revenue management, among others. In this paper, we design near-optimal
      policies for the decision maker under the following two specific settings: a
      data-driven setting where the decision maker is given prior estimates of the
      distributions beforehand and a no information setting where the distributions
      are completely unknown to the decision maker. Under each setting, we propose
      a new Wasserstein-distance based measure to measure the non-stationarity of
      the distributions at different time periods and show that this measure leads
      to a necessary and sufficient condition for the attainability of a sublinear
      regret. For the first setting, we propose a new algorithm which blends gradient
      descent steps with the prior estimates. We then adapt our algorithm for the
      second setting and propose another gradient descent based algorithm. We show
      that under both settings, our polices achieve a regret upper bound of optimal
      order. Moreover, our policies could be naturally incorporated with a re-solving
      procedure which further boosts the empirical performance in numerical experiments.",
      "venue": "arXiv.org", "year": 2020, "referenceCount": 88, "citationCount": 19,
      "influentialCitationCount": 1, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category":
      "Mathematics", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2020-12-13", "journal": {"name": "ArXiv", "volume": "abs/2012.06961"},
      "citationStyles": {"bibtex": "@Article{Jiang2020OnlineSO,\n author = {Jiashuo
      Jiang and Xiaocheng Li and Jiawei Zhang},\n booktitle = {arXiv.org},\n journal
      = {ArXiv},\n title = {Online Stochastic Optimization with Wasserstein Based
      Non-stationarity},\n volume = {abs/2012.06961},\n year = {2020}\n}\n"}, "authors":
      [{"authorId": "152634563", "name": "Jiashuo Jiang"}, {"authorId": "47056752",
      "name": "Xiaocheng Li"}, {"authorId": "1739956009", "name": "Jiawei Zhang"}]},
      {"paperId": "23fd98b2e11e540a2aaf09d8194115ffb8e41d13", "externalIds": {"MAG":
      "1950045300", "DBLP": "conf/spdp/EgeciogluI96", "DOI": "10.1109/SPDP.1996.570374",
      "CorpusId": 14719601}, "corpusId": 14719601, "publicationVenue": {"id": "31306872-361d-4fd0-84ff-0e14a1a6a416",
      "name": "IEEE Symposium on Parallel and Distributed Processing", "type": "conference",
      "alternate_names": ["SPDP", "IEEE Symp Parallel Distrib Process"]}, "url": "https://www.semanticscholar.org/paper/23fd98b2e11e540a2aaf09d8194115ffb8e41d13",
      "title": "Parallel algorithms for fast computation of normalized edit distances",
      "abstract": "The authors give work-optimal and polylogarithmic time parallel
      algorithms for solving the normalized edit distance problem. The normalized
      edit distance between two strings X and Y with lengths n/spl ges/m is the minimum
      quotient of the sum of the costs of edit operations transforming X into Y by
      the length of the edit path corresponding to those edit operations. Marzal and
      Vidal (1993) proposed a sequential algorithm with a time complexity of O(nm/sup
      2/). They show that this algorithm can be parallelized work-optimally on an
      array of n (or m) processors, and on a mesh of n/spl times/m processors. They
      then propose a sublinear time algorithm that is almost work-optimal: using O(mn/sup
      1.75/) processors, the time complexity of the algorithm is O(n/sup 0.75/ log
      n) and the total number of operations is O (mn/sup 2.5/ log n). This algorithm
      runs on a CREW PRAM, but is likely to work on weaker PRAM models and hypercubes
      with minor modifications. Finally, they present a polylogarithmic O(log/sup
      2/ n) time algorithm based on matrix multiplication which runs on a O(n/sup
      6//log n) processor hypercube.", "venue": "IEEE Symposium on Parallel and Distributed
      Processing", "year": 1996, "referenceCount": 14, "citationCount": 5, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "1996-10-23", "journal": {"name": "Proceedings
      of SPDP ''96: 8th IEEE Symposium on Parallel and Distributed Processing", "pages":
      "496-503"}, "citationStyles": {"bibtex": "@Article{E\u011fecio\u011flu1996ParallelAF,\n
      author = {\u00d6. E\u011fecio\u011flu and Maximilian Ibel},\n booktitle = {IEEE
      Symposium on Parallel and Distributed Processing},\n journal = {Proceedings
      of SPDP ''96: 8th IEEE Symposium on Parallel and Distributed Processing},\n
      pages = {496-503},\n title = {Parallel algorithms for fast computation of normalized
      edit distances},\n year = {1996}\n}\n"}, "authors": [{"authorId": "3139667",
      "name": "\u00d6. E\u011fecio\u011flu"}, {"authorId": "2100819", "name": "Maximilian
      Ibel"}]}, {"paperId": "dd5e8b94ce05d14b59e31d0a76545a368653cf44", "externalIds":
      {"CorpusId": 54795972}, "corpusId": 54795972, "publicationVenue": null, "url":
      "https://www.semanticscholar.org/paper/dd5e8b94ce05d14b59e31d0a76545a368653cf44",
      "title": "1 2 N ov 2 01 7 Longest Alignment with Edits in Data Streams", "abstract":
      "Analyzing patterns in data streams generated by network traffic, sensor networks,
      or satellite feeds is a challenge for systems in which the available storage
      is limited. In addition, real data is noisy, which makes designing data stream
      algorithms even more challenging. Motivated by such challenges, we study algorithms
      for detecting the similarity of two data streams that can be read in sync. Two
      strings S, T \u2208 \u03a3n form a d-near-alignment if the distance between
      them in some given metric is at most d. We study the problem of identifying
      a longest substring of S and T that forms a d-near-alignment under the edit
      distance, in the simultaneous streaming model. In this model, symbols of strings
      S and T are streamed at the same time, and the amount of available processing
      space is sublinear in the length of the strings. We give several algorithms,
      including an exact one-pass algorithm that uses O (", "venue": "", "year": 2018,
      "referenceCount": 31, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
      null, "journal": null, "citationStyles": {"bibtex": "@Inproceedings{Grigorescu201812N,\n
      author = {Elena Grigorescu and Erfan Sadeqi Azer and Samson Zhou},\n title =
      {1 2 N ov 2 01 7 Longest Alignment with Edits in Data Streams},\n year = {2018}\n}\n"},
      "authors": [{"authorId": "145714076", "name": "Elena Grigorescu"}, {"authorId":
      "2627314", "name": "Erfan Sadeqi Azer"}, {"authorId": "3393628", "name": "Samson
      Zhou"}]}, {"paperId": "a92d3d6cca10fd83a4306130a9aca0f04c24fd02", "externalIds":
      {"MAG": "1952032343", "DBLP": "journals/ijswis/CostabelloG14", "DOI": "10.4018/IJSWIS.2014100103",
      "CorpusId": 19005789}, "corpusId": 19005789, "publicationVenue": {"id": "34225f0b-ef59-4a36-913f-cca0e47930f0",
      "name": "International Journal on Semantic Web and Information Systems (IJSWIS)",
      "type": "journal", "alternate_names": ["Int J Semantic Web Inf Syst", "International
      Journal on Semantic Web and Information Systems", "Int J Semantic Web Inf Syst
      (IJSWIS"], "issn": "1552-6283", "url": "http://www.igi-global.com/ijswis", "alternate_urls":
      ["https://www.igi-global.com/journal/international-journal-semantic-web-information/1092"]},
      "url": "https://www.semanticscholar.org/paper/a92d3d6cca10fd83a4306130a9aca0f04c24fd02",
      "title": "Context-Aware Presentation of Linked Data on Mobile", "abstract":
      "In this paper the authors focus on context-aware adaptation for linked data
      on mobile. They split up the problem in two sub-questions: how to declaratively
      describe context at RDF presentation level, and how to overcome context imprecisions
      and incompleteness when selecting the proper context description at runtime.
      The authors answer their two-fold research question with PRISSMA, a context-aware
      presentation layer for Linked Data. PRISSMA extends the Fresnel vocabulary with
      the notion of mobile context. Besides, it includes an algorithm that determines
      whether the sensed context is compatible with some context declarations. The
      algorithm finds optimal error-tolerant subgraph isomorphisms between RDF graphs
      using the notion of graph edit distance and is sublinear in the number of context
      declarations in the system.", "venue": "International Journal on Semantic Web
      and Information Systems (IJSWIS)", "year": 2014, "referenceCount": 36, "citationCount":
      5, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2014-10-01", "journal": {"name": "Int. J. Semantic Web Inf. Syst.", "pages":
      "45-76", "volume": "10"}, "citationStyles": {"bibtex": "@Article{Costabello2014ContextAwarePO,\n
      author = {Luca Costabello and Fabien L. Gandon},\n booktitle = {International
      Journal on Semantic Web and Information Systems (IJSWIS)},\n journal = {Int.
      J. Semantic Web Inf. Syst.},\n pages = {45-76},\n title = {Context-Aware Presentation
      of Linked Data on Mobile},\n volume = {10},\n year = {2014}\n}\n"}, "authors":
      [{"authorId": "3021495", "name": "Luca Costabello"}, {"authorId": "1753013",
      "name": "Fabien L. Gandon"}]}, {"paperId": "eb3d34e1fb97a00e5be195ee75840da673480bea",
      "externalIds": {"MAG": "1808180440", "DBLP": "conf/esws/Costabello14", "DOI":
      "10.1007/978-3-319-07443-6_4", "CorpusId": 13175213}, "corpusId": 13175213,
      "publicationVenue": {"id": "c7bde2ee-6ad5-49c7-9498-a01e46c162eb", "name": "Extended
      Semantic Web Conference", "type": "conference", "alternate_names": ["Eur Semantic
      Web Conf", "Ext Semantic Web Conf", "European Semantic Web Conference", "ESWC"],
      "url": "https://link.springer.com/conference/esws"}, "url": "https://www.semanticscholar.org/paper/eb3d34e1fb97a00e5be195ee75840da673480bea",
      "title": "Error-Tolerant RDF Subgraph Matching for Adaptive Presentation of
      Linked Data on Mobile", "abstract": null, "venue": "Extended Semantic Web Conference",
      "year": 2014, "referenceCount": 35, "citationCount": 5, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://link.springer.com/content/pdf/10.1007/978-3-319-07443-6_4.pdf",
      "status": "BRONZE"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2014-05-25", "journal": {"pages": "36-51"}, "citationStyles":
      {"bibtex": "@Article{Costabello2014ErrorTolerantRS,\n author = {Luca Costabello},\n
      booktitle = {Extended Semantic Web Conference},\n pages = {36-51},\n title =
      {Error-Tolerant RDF Subgraph Matching for Adaptive Presentation of Linked Data
      on Mobile},\n year = {2014}\n}\n"}, "authors": [{"authorId": "3021495", "name":
      "Luca Costabello"}]}, {"paperId": "c88c4d167da4a2c61668883dfa50552b2ecd60dc",
      "externalIds": {"ArXiv": "1312.5105", "MAG": "1794340831", "DBLP": "journals/corr/BonchiGK13",
      "CorpusId": 10680176}, "corpusId": 10680176, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/c88c4d167da4a2c61668883dfa50552b2ecd60dc",
      "title": "Local correlation clustering", "abstract": "Correlation clustering
      is perhaps the most natural formulation of clustering. Given $n$ objects and
      a pairwise similarity measure, the goal is to cluster the objects so that, to
      the best possible extent, similar objects are put in the same cluster and dissimilar
      objects are put in different clusters. Despite its theoretical appeal, the practical
      relevance of correlation clustering still remains largely unexplored, mainly
      due to the fact that correlation clustering requires the $\\Theta(n^2)$ pairwise
      similarities as input. \nIn this paper we initiate the investigation into \\emph{local}
      algorithms for correlation clustering. In \\emph{local correlation clustering}
      we are given the identifier of a single object and we want to return the cluster
      to which it belongs in some globally consistent near-optimal clustering, using
      a small number of similarity queries. Local algorithms for correlation clustering
      open the door to \\emph{sublinear-time} algorithms, which are particularly useful
      when the similarity between items is costly to compute, as it is often the case
      in many practical application domains. They also imply $(i)$ distributed and
      streaming clustering algorithms, $(ii)$ constant-time estimators and testers
      for cluster edit distance, and $(iii)$ property-preserving parallel reconstruction
      algorithms for clusterability. \nSpecifically, we devise a local clustering
      algorithm attaining a $(3, \\varepsilon)$-approximation in time $O(1/\\varepsilon^2)$
      independently of the dataset size. An explicit approximate clustering for all
      objects can be produced in time $O(n/\\varepsilon)$ (which is provably optimal).
      We also provide a fully additive $(1,\\varepsilon)$-approximation with local
      query complexity $poly(1/\\varepsilon)$ and time complexity $2^{poly(1/\\varepsilon)}$.
      The latter yields the fastest polynomial-time approximation scheme for correlation
      clustering known to date.", "venue": "arXiv.org", "year": 2013, "referenceCount":
      42, "citationCount": 9, "influentialCitationCount": 1, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Mathematics"],
      "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2013-12-18", "journal":
      {"name": "ArXiv", "volume": "abs/1312.5105"}, "citationStyles": {"bibtex": "@Article{Bonchi2013LocalCC,\n
      author = {F. Bonchi and David Garc\u00eda-Soriano and Konstantin Kutzkov},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Local correlation clustering},\n
      volume = {abs/1312.5105},\n year = {2013}\n}\n"}, "authors": [{"authorId": "1705764",
      "name": "F. Bonchi"}, {"authorId": "1398620943", "name": "David Garc\u00eda-Soriano"},
      {"authorId": "1712289", "name": "Konstantin Kutzkov"}]}, {"paperId": "2b7b220be3bad47af114e7daa3b96fd4a2936f55",
      "externalIds": {"MAG": "2963063124", "DBLP": "journals/corr/abs-1711-04367",
      "ArXiv": "1711.04367", "DOI": "10.1109/ALLERTON.2017.8262766", "CorpusId": 10554346},
      "corpusId": 10554346, "publicationVenue": {"id": "e3e363b2-60f3-46d7-9067-5deaddc3f3f2",
      "name": "Allerton Conference on Communication, Control, and Computing", "type":
      "conference", "alternate_names": ["Allerton", "T Conf Commun Control Comput"]},
      "url": "https://www.semanticscholar.org/paper/2b7b220be3bad47af114e7daa3b96fd4a2936f55",
      "title": "Longest alignment with edits in data streams", "abstract": "Analyzing
      patterns in data streams generated by network traffic, sensor networks, or satellite
      feeds is a challenge for systems in which the available storage is limited.
      In addition, real data is noisy, which makes designing data stream algorithms
      even more challenging. Motivated by such challenges, we study algorithms for
      detecting the similarity of two data streams that can be read in sync. Two strings
      S, T \u220a \u2211n form a d-near-alignment if the distance between them in
      some given metric is at most d. We study the problem of identifying a longest
      substring of S and T that forms a d-near-alignment under the edit distance,
      in the simultaneous streaming model. In this model, symbols of strings S and
      T are streamed at the same time, and the amount of available processing space
      is sublinear in the length of the strings. We give several algorithms, including
      an exact one-pass algorithm that uses O (d2 + d log n) bits of space. We couple
      these results with comparable lower bounds.", "venue": "Allerton Conference
      on Communication, Control, and Computing", "year": 2017, "referenceCount": 33,
      "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf":
      {"url": "https://arxiv.org/pdf/1711.04367", "status": "GREEN"}, "fieldsOfStudy":
      ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Mathematics", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle", "Conference"], "publicationDate": "2017-10-01", "journal":
      {"name": "2017 55th Annual Allerton Conference on Communication, Control, and
      Computing (Allerton)", "pages": "405-412"}, "citationStyles": {"bibtex": "@Article{Grigorescu2017LongestAW,\n
      author = {Elena Grigorescu and Erfan Sadeqi Azer and Samson Zhou},\n booktitle
      = {Allerton Conference on Communication, Control, and Computing},\n journal
      = {2017 55th Annual Allerton Conference on Communication, Control, and Computing
      (Allerton)},\n pages = {405-412},\n title = {Longest alignment with edits in
      data streams},\n year = {2017}\n}\n"}, "authors": [{"authorId": "145714076",
      "name": "Elena Grigorescu"}, {"authorId": "2627314", "name": "Erfan Sadeqi Azer"},
      {"authorId": "3393628", "name": "Samson Zhou"}]}, {"paperId": "bd447e019450d9eabd9e39b838e910842ea523a2",
      "externalIds": {"MAG": "2106587277", "DBLP": "conf/iros/AsadpourSBDI08", "DOI":
      "10.1109/IROS.2008.4650673", "CorpusId": 12702686}, "corpusId": 12702686, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/bd447e019450d9eabd9e39b838e910842ea523a2",
      "title": "Graph signature for self-reconfiguration planning", "abstract": "This
      project incorporates modular robots as building blocks for furniture that moves
      and self-reconfigures. The reconfiguration is done using dynamic connection
      / disconnection of modules and rotations of the degrees of freedom. This paper
      introduces a new approach to self-reconfiguration planning for modular robots
      based on the graph signature and the graph edit-distance. The method has been
      tested in simulation on two type of modules: YaMoR and M-TRAN. The simulation
      results shows interesting features of the approach, namely rapidly finding a
      near-optimal solution.", "venue": "2008 IEEE/RSJ International Conference on
      Intelligent Robots and Systems", "year": 2008, "referenceCount": 24, "citationCount":
      28, "influentialCitationCount": 1, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://infoscience.epfl.ch/record/130728/files/mAsadpour08.pdf", "status":
      "GREEN"}, "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy":
      [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Engineering", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle", "Conference"], "publicationDate": "2008-10-14", "journal":
      {"name": "2008 IEEE/RSJ International Conference on Intelligent Robots and Systems",
      "pages": "863-869"}, "citationStyles": {"bibtex": "@Article{Asadpour2008GraphSF,\n
      author = {M. Asadpour and Alexander Spr\u00f6witz and A. Billard and P. Dillenbourg
      and A. Ijspeert},\n booktitle = {2008 IEEE/RSJ International Conference on Intelligent
      Robots and Systems},\n journal = {2008 IEEE/RSJ International Conference on
      Intelligent Robots and Systems},\n pages = {863-869},\n title = {Graph signature
      for self-reconfiguration planning},\n year = {2008}\n}\n"}, "authors": [{"authorId":
      "1771574", "name": "M. Asadpour"}, {"authorId": "3210778", "name": "Alexander
      Spr\u00f6witz"}, {"authorId": "1807928", "name": "A. Billard"}, {"authorId":
      "1799133", "name": "P. Dillenbourg"}, {"authorId": "8038419", "name": "A. Ijspeert"}]},
      {"paperId": "135ea9aac86cc83d7c979eeefcf479cfcdeed7fe", "externalIds": {"MAG":
      "1486707681", "DBLP": "phd/ethos/Cormode03", "CorpusId": 8210461}, "corpusId":
      8210461, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/135ea9aac86cc83d7c979eeefcf479cfcdeed7fe",
      "title": "Sequence distance embeddings", "abstract": "Sequences represent a
      large class of fundamental objects in Computer Science sets, strings, vectors
      and permutations are considered to be sequences. Distances between sequences
      measure their similarity, and computations based on distances are ubiquitous:
      either to compute the distance, or to use distance computation as part of a
      more complex problem. This thesis takes a very specific approach to solving
      questions of sequence distance: sequences are embedded into other distance measures,
      so that distance in the new space approximates the original distance. This allows
      the solution of a variety of problems including: Fast computation of short sketches
      in a variety of computing models, which allow sequences to be compared in constant
      time and space irrespective of the size of the original sequences. Approximate
      nearest neighbor and clustering problems, significantly faster than the naive
      exact solutions. Algorithms to find approximate occurrences of pattern sequences
      in long text sequences in near linear time. Efficient communication schemes
      to approximate the distance between, and exchange, sequences in close to the
      optimal amount of communication. Solutions are given for these problems for
      a variety of distances, including fundamental distances on sets and vectors;
      distances inspired by biological problems for permutations; and certain text
      editing distances for strings. Many of these embeddings are computable in a
      streaming model where the data is too large to store in memory, and instead
      has to be processed as and when it arrives, piece by piece. The embeddings are
      also shown to be practical, with a series of large scale experiments which demonstrate
      that given only a small space, approximate solutions to several similarity and
      clustering problems can be found that are as good as or better than those found
      with prior methods.", "venue": "", "year": 2003, "referenceCount": 163, "citationCount":
      68, "influentialCitationCount": 6, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category":
      "Mathematics", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
      null, "journal": {"name": "", "volume": ""}, "citationStyles": {"bibtex": "@Inproceedings{Cormode2003SequenceDE,\n
      author = {Graham Cormode},\n title = {Sequence distance embeddings},\n year
      = {2003}\n}\n"}, "authors": [{"authorId": "1709589", "name": "Graham Cormode"}]},
      {"paperId": "1bfc53742bec159e78db6d45ac9a4ea0ae08d7db", "externalIds": {"MAG":
      "2793332341", "DOI": "10.1145/3166186", "CorpusId": 67274739}, "corpusId": 67274739,
      "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/1bfc53742bec159e78db6d45ac9a4ea0ae08d7db",
      "title": "The Sparse Fourier Transform: Theory and Practice", "abstract": "The
      Fourier transform is one of the most fundamental tools for computing the frequency
      representation of signals. It plays a central role in signal processing, communications,
      audio and video compression, medical imaging, genomics, astronomy, as well as
      many other areas. Because of its widespread use, fast algorithms for computing
      the Fourier transform can benefit a large number of applications. The fastest
      algorithm for computing the Fourier transform is the Fast Fourier Transform
      (FFT) which runs in near-linear time making it an indispensable tool for many
      applications. However, today, the runtime of the FFT algorithm is no longer
      fast enough especially for big data problems where each dataset can be few terabytes.
      Hence, faster algorithms that run in sublinear time, i.e., do not even sample
      all the data points, have become necessary. \n \nThe Sparse Fourier Transform:
      Theory and Practice book shows how to address the above problem by developing
      the Sparse Fourier Transform algorithms and building practical systems that
      use these algorithms to solve key problems in six different applications. \n
      \nPart I of the book focuses on the theory front. It introduces the Sparse Fourier
      Transform algorithms: a family of sublinear time algorithms for computing the
      Fourier transform faster than FFT. The Sparse Fourier Transform is based on
      the insight that many real-world signals are sparse, i.e., most of the frequencies
      have negligible contribution to the overall signal. Exploiting this sparsity,
      the book introduces several new algorithms which encompass two main axes: runtime
      complexity and sampling complexity. The book presents nearly optimal Sparse
      Fourier Transform algorithms that are faster than FFT and have the lowest runtime
      complexity known to date. It also presents Sparse Fourier Transform algorithms
      with optimal sampling complexity in the average case and the same nearly optimal
      runtime complexity. These algorithms use the minimum number of input data samples
      and hence, reduce acquisition cost and I/O overhead. \n \nPart II of the book
      focuses on the systems front. It describes software and hardware architectures
      for leveraging the Sparse Fourier Transform to address practical problems in
      six applied fields. In the area of wireless networks, it demonstrates how to
      use the Sparse Fourier Transform to build a wireless receiver that captures
      GHz-wide signals without sampling at the Nyquist rate enabling wideband spectrum
      sensing and acquisition using cheap commodity hardware. In mobile systems, the
      book introduces a new GPS receiver design that both reduces the delay to find
      the location and decreases the power consumption. In computer graphics, light
      fields enable new virtual reality and computational photography applications
      like interactive viewpoint changes, depth extraction and refocusing. The book
      shows that reconstructing light field images using the Sparse Fourier Transform
      reduces camera sampling requirements and improves image reconstruction quality.
      In the area of medical imaging, the book described how to enable efficient magnetic
      resonance spectroscopy (MRS), a new medical imaging technique that can reveal
      biomarkers for diseases like autism and cancer. In Biochemistry, it shows how
      the Sparse Fourier Transform can reduce Nuclear Magnetic Resonance (NMR) experiment
      time from weeks to days, enabling high dimensional NMR needed for discovering
      complex protein structures. Finally, in digital circuits, the book develops
      a chip with the largest Fourier Transform to date for sparse data. It delivers
      a 0.75 million point Sparse Fourier Transform chip that consumes 40x less power
      than prior FFT VLSI implementations. All these systems customize the theoretical
      algorithms to capture the structure of sparsity in each application, and hence
      maximize the resulting gains. The book also presents prototypes and evaluations
      of these systems in accordance with the standards of each application domain.
      \n \nThis book is a revised version of the author''s 2016 ACM Dissertation Award
      winning Ph.D. thesis. The revisions include editing, formatting, and minor corrections.",
      "venue": "", "year": 2018, "referenceCount": 0, "citationCount": 9, "influentialCitationCount":
      1, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}, {"category": "Physics", "source": "s2-fos-model"}],
      "publicationTypes": null, "publicationDate": "2018-02-22", "journal": {"name":
      "", "volume": ""}, "citationStyles": {"bibtex": "@Inproceedings{Hassanieh2018TheSF,\n
      author = {Haitham Hassanieh},\n title = {The Sparse Fourier Transform: Theory
      and Practice},\n year = {2018}\n}\n"}, "authors": [{"authorId": "2349340", "name":
      "Haitham Hassanieh"}]}, {"paperId": "055b549d6235675e8b512f51a6d07f2bd2203869",
      "externalIds": {"DBLP": "journals/tit/VenkataramananS15", "ArXiv": "1310.2026",
      "MAG": "1941245335", "DOI": "10.1109/TIT.2015.2466635", "CorpusId": 15728206},
      "corpusId": 15728206, "publicationVenue": {"id": "748e730b-add9-47ee-819d-8ae54e504ef9",
      "name": "IEEE Transactions on Information Theory", "type": "journal", "alternate_names":
      ["IEEE Trans Inf Theory"], "issn": "0018-9448", "url": "http://www.comm.utoronto.ca/trans-it/",
      "alternate_urls": ["https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?puNumber=18",
      "http://ieeexplore.ieee.org/servlet/opac?punumber=18"]}, "url": "https://www.semanticscholar.org/paper/055b549d6235675e8b512f51a6d07f2bd2203869",
      "title": "Low-Complexity Interactive Algorithms for Synchronization From Deletions,
      Insertions, and Substitutions", "abstract": "Consider two remote nodes having
      binary sequences X and Y, respectively. Y is an edited version of X, where the
      editing involves random deletions, insertions, and substitutions, possibly in
      bursts. The goal is for the node with Y to reconstruct X with minimal exchange
      of information over a noiseless link. The communication is measured in terms
      of both the total number of bits exchanged and the number of interactive rounds
      of communication. This paper focuses on the setting where the number of edits
      is o(n/log n), where n is the length of X. We first consider the case where
      the edits are a mixture of insertions and deletions (indels), and propose an
      interactive synchronization algorithm with near-optimal communication rate and
      average computational complexity of O(n) arithmetic operations. The algorithm
      uses interaction to efficiently split the source sequence into substrings containing
      exactly one deletion or insertion. Each of these substrings is then synchronized
      using an optimal one-way algorithm based on the single-deletion correcting channel
      codes of Varshamov and Tenengolts. We then build on this synchronization algorithm
      in three different ways. First, it is modified to work with a single round of
      interaction. The reduction in the number of rounds comes at the expense of higher
      communication, which is quantified. Next, we present an extension to the practically
      important case where the insertions and deletions may occur in (potentially
      large) bursts. Finally, we show how to synchronize the sources to within a target
      Hamming distance. This feature can be used to differentiate between substitution
      and indel edits. In addition to theoretical performance bounds, we provide several
      validating simulation results for the proposed algorithms.", "venue": "IEEE
      Transactions on Information Theory", "year": 2013, "referenceCount": 35, "citationCount":
      32, "influentialCitationCount": 4, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://www.repository.cam.ac.uk/bitstream/1810/249100/1/Venkataramanan%20et%20al%202015%20IEEE%20Transactions%20on%20Information%20Theory.pdf",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2013-10-08", "journal":
      {"name": "IEEE Transactions on Information Theory", "pages": "5670-5689", "volume":
      "61"}, "citationStyles": {"bibtex": "@Article{Venkataramanan2013LowComplexityIA,\n
      author = {R. Venkataramanan and Vasuki Narasimha Swamy and K. Ramchandran},\n
      booktitle = {IEEE Transactions on Information Theory},\n journal = {IEEE Transactions
      on Information Theory},\n pages = {5670-5689},\n title = {Low-Complexity Interactive
      Algorithms for Synchronization From Deletions, Insertions, and Substitutions},\n
      volume = {61},\n year = {2013}\n}\n"}, "authors": [{"authorId": "145720083",
      "name": "R. Venkataramanan"}, {"authorId": "3751982", "name": "Vasuki Narasimha
      Swamy"}, {"authorId": "144161012", "name": "K. Ramchandran"}]}, {"paperId":
      "109cc4ba10598400b2818693dfc9edfde6254ebd", "externalIds": {"MAG": "2070409660",
      "DBLP": "journals/algorithmica/HyyroN05", "DOI": "10.1007/s00453-004-1108-z",
      "CorpusId": 7307909}, "corpusId": 7307909, "publicationVenue": {"id": "300eb16f-ce6c-495a-8da3-2e691bf9051d",
      "name": "Algorithmica", "type": "journal", "issn": "0178-4617", "url": "https://www.springer.com/computer/theoretical+computer+science/journal/453",
      "alternate_urls": ["https://link.springer.com/journal/453", "http://www.springer.com/computer/theoretical+computer+science/journal/453"]},
      "url": "https://www.semanticscholar.org/paper/109cc4ba10598400b2818693dfc9edfde6254ebd",
      "title": "Bit-Parallel Witnesses and Their Applications \n to Approximate String
      Matching", "abstract": null, "venue": "Algorithmica", "year": 2004, "referenceCount":
      25, "citationCount": 33, "influentialCitationCount": 3, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Mathematics", "Computer Science"],
      "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category":
      "Computer Science", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      null, "journal": {"name": "Algorithmica", "pages": "203-231", "volume": "41"},
      "citationStyles": {"bibtex": "@Article{Hyyr\u00f62004BitParallelWA,\n author
      = {Heikki Hyyr\u00f6 and G. Navarro},\n booktitle = {Algorithmica},\n journal
      = {Algorithmica},\n pages = {203-231},\n title = {Bit-Parallel Witnesses and
      Their Applications \n to Approximate String Matching},\n volume = {41},\n year
      = {2004}\n}\n"}, "authors": [{"authorId": "1828763", "name": "Heikki Hyyr\u00f6"},
      {"authorId": "143678972", "name": "G. Navarro"}]}, {"paperId": "f58239e210caae820ae0bdbc0d4d64421577d67f",
      "externalIds": {"MAG": "2789943307", "DOI": "10.1109/I2C2.2017.8321962", "CorpusId":
      4107794}, "corpusId": 4107794, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/f58239e210caae820ae0bdbc0d4d64421577d67f",
      "title": "A font style classification system for English OCR", "abstract": "The
      inclination of optical technologies like OCR lies in achieving higher recognition
      rates with optimal or reduced computational complexities. At present there exist
      optical technologies for automation of reading the text from document images
      with almost nearing to 100% accuracy. Especially, the Roman language OCR''s
      are reliable and robust enough in producing higher accuracies by being able
      to recognize varying font styles of varying sizes. However for the font style/
      size independent OCR''s one of the main aspect is its computational complexity.
      It is significant concern to reduce the computational complexities involved
      in the process of character recognition through a font style / size independent
      OCR. In this paper, a technique for classification of the font style based on
      character image is proposed by employing the distance profile features with
      respect to left, right and diagonal directions of a character image. The major
      objective of this work is to reduce the complexity of the generic OCR systems
      by font style recognition. The distance profile features of character images
      are fed to a support vector machine classifier. For experimentation, the training
      data sets are comprised of around 10 widely used font styles of upper case letters
      as well as lower case letters. The testing is conducted with the character images
      that are extracted from various non editable document sources comprising of
      5 different font styles. The performance of algorithm is found to be satisfactory
      with an accuracy of 80%.", "venue": "2017 International Conference on Intelligent
      Computing and Control (I2C2)", "year": 2017, "referenceCount": 11, "citationCount":
      24, "influentialCitationCount": 6, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["Conference"], "publicationDate": "2017-06-01",
      "journal": {"name": "2017 International Conference on Intelligent Computing
      and Control (I2C2)", "pages": "1-5"}, "citationStyles": {"bibtex": "@Conference{Bharath2017AFS,\n
      author = {V. Bharath and N. Rani},\n booktitle = {2017 International Conference
      on Intelligent Computing and Control (I2C2)},\n journal = {2017 International
      Conference on Intelligent Computing and Control (I2C2)},\n pages = {1-5},\n
      title = {A font style classification system for English OCR},\n year = {2017}\n}\n"},
      "authors": [{"authorId": "144531464", "name": "V. Bharath"}, {"authorId": "147702218",
      "name": "N. Rani"}]}, {"paperId": "950902253427acd162f3dbd0d0544b34aadca548",
      "externalIds": {"DBLP": "conf/allerton/VenkataramananZR10", "MAG": "2555411750",
      "DOI": "10.1109/ALLERTON.2010.5707079", "CorpusId": 15511988}, "corpusId": 15511988,
      "publicationVenue": {"id": "e3e363b2-60f3-46d7-9067-5deaddc3f3f2", "name": "Allerton
      Conference on Communication, Control, and Computing", "type": "conference",
      "alternate_names": ["Allerton", "T Conf Commun Control Comput"]}, "url": "https://www.semanticscholar.org/paper/950902253427acd162f3dbd0d0544b34aadca548",
      "title": "Interactive low-complexity codes for synchronization from deletions
      and insertions", "abstract": "We study the problem of synchronization of two
      remotely located data sources, which are mis-synchronized due to deletions and
      insertions. This is an important problem since a small number of synchronization
      errors can induce a large Hamming distance between the two sources. The goal
      is to effect synchronization with the rate-efficient use of lossless bidirectional
      links between the two sources. In this work, we focus on the following model.
      A binary sequence X of length n is edited to generate the sequence at the remote
      end, say Y, where the editing involves random deletions and insertions, possibly
      in small bursts. The problem is to synchronize Y with X with minimal exchange
      of information (in terms of both the average communication rate and the average
      number of interactive rounds of communication). We focus here on the case where
      the number of edits is much smaller than n, and propose an interactive algorithm
      which is computationally simple and has near-optimal communication complexity.
      Our algorithm works by efficiently splitting the source sequence into pieces
      containing either just a single deletion/insertion or a single burst deletion/insertion.
      Each of these pieces is then synchronized using an optimal one-way synchronization
      code, based on the single-deletion correcting channel codes of Varshamov and
      Tenengolts (VT codes).", "venue": "Allerton Conference on Communication, Control,
      and Computing", "year": 2010, "referenceCount": 16, "citationCount": 34, "influentialCitationCount":
      7, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle", "Conference"], "publicationDate": "2010-09-01", "journal":
      {"name": "2010 48th Annual Allerton Conference on Communication, Control, and
      Computing (Allerton)", "pages": "1412-1419"}, "citationStyles": {"bibtex": "@Article{Venkataramanan2010InteractiveLC,\n
      author = {R. Venkataramanan and Hao Zhang and K. Ramchandran},\n booktitle =
      {Allerton Conference on Communication, Control, and Computing},\n journal =
      {2010 48th Annual Allerton Conference on Communication, Control, and Computing
      (Allerton)},\n pages = {1412-1419},\n title = {Interactive low-complexity codes
      for synchronization from deletions and insertions},\n year = {2010}\n}\n"},
      "authors": [{"authorId": "145720083", "name": "R. Venkataramanan"}, {"authorId":
      "46702482", "name": "Hao Zhang"}, {"authorId": "144161012", "name": "K. Ramchandran"}]},
      {"paperId": "780eb7a94068377852c5a89deadc2c4697bc38c5", "externalIds": {"MAG":
      "1543611576", "DOI": "10.1007/3-540-68530-8", "CorpusId": 117765714}, "corpusId":
      117765714, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/780eb7a94068377852c5a89deadc2c4697bc38c5",
      "title": "Algorit[h]ms - ESA ''98 : 6th Annual European Symposium, Venice, Italy,
      August 24-26, 1998 : proceedings", "abstract": null, "venue": "", "year": 1998,
      "referenceCount": 0, "citationCount": 62, "influentialCitationCount": 0, "isOpenAccess":
      true, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics"], "s2FieldsOfStudy":
      [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": null, "publicationDate": null, "journal": {"name": "", "volume":
      "1461"}, "citationStyles": {"bibtex": "@Inproceedings{Bilardi1998AlgorithmsE,\n
      author = {G. Bilardi and G. Italiano and A. Pietracaprina and G. Pucci},\n title
      = {Algorit[h]ms - ESA ''98 : 6th Annual European Symposium, Venice, Italy, August
      24-26, 1998 : proceedings},\n volume = {1461},\n year = {1998}\n}\n"}, "authors":
      [{"authorId": "2708239", "name": "G. Bilardi"}, {"authorId": "1688493", "name":
      "G. Italiano"}, {"authorId": "1750351", "name": "A. Pietracaprina"}, {"authorId":
      "7688370", "name": "G. Pucci"}]}, {"paperId": "86ececa5aca5bf43442a84723a2c4b88ceccecc9",
      "externalIds": {"DBLP": "journals/taslp/CaseyRS08", "MAG": "2130865646", "DOI":
      "10.1109/TASL.2008.925883", "CorpusId": 206601845}, "corpusId": 206601845, "publicationVenue":
      {"id": "96b92082-eb93-4682-be66-0a8fa5f2511c", "name": "IEEE Transactions on
      Audio, Speech, and Language Processing", "type": "journal", "alternate_names":
      ["IEEE Trans Audio Speech Lang Process"], "issn": "1558-7916", "alternate_issns":
      ["1558-7924"], "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=10376",
      "alternate_urls": ["https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=10376"]},
      "url": "https://www.semanticscholar.org/paper/86ececa5aca5bf43442a84723a2c4b88ceccecc9",
      "title": "Analysis of Minimum Distances in High-Dimensional Musical Spaces",
      "abstract": "We propose an automatic method for measuring content-based music
      similarity, enhancing the current generation of music search engines and recommended
      systems. Many previous approaches to track similarity require brute-force, pair-wise
      processing between all audio features in a database and therefore are not practical
      for large collections. However, in an Internet-connected world, where users
      have access to millions of musical tracks, efficiency is crucial. Our approach
      uses features extracted from unlabeled audio data and near-neigbor retrieval
      using a distance threshold, determined by analysis, to solve a range of retrieval
      tasks. The tasks require temporal features-analogous to the technique of shingling
      used for text retrieval. To measure similarity, we count pairs of audio shingles,
      between a query and target track, that are below a distance threshold. The distribution
      of between-shingle distances is different for each database; therefore, we present
      an analysis of the distribution of minimum distances between shingles and a
      method for estimating a distance threshold for optimal retrieval performance.
      The method is compatible with locality-sensitive hashing (LSH)-allowing implementation
      with retrieval times several orders of magnitude faster than those using exhaustive
      distance computations. We evaluate the performance of our proposed method on
      three contrasting music similarity tasks: retrieval of mis-attributed recordings
      (fingerprint), retrieval of the same work performed by different artists (cover
      songs), and retrieval of edited and sampled versions of a query track by remix
      artists (remixes). Our method achieves near-perfect performance in the first
      two tasks and 75% precision at 70% recall in the third task. Each task was performed
      on a test database comprising 4.5 million audio shingles.", "venue": "IEEE Transactions
      on Audio, Speech, and Language Processing", "year": 2008, "referenceCount":
      47, "citationCount": 106, "influentialCitationCount": 12, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2008-07-01", "journal": {"name": "IEEE Transactions on Audio,
      Speech, and Language Processing", "pages": "1015-1028", "volume": "16"}, "citationStyles":
      {"bibtex": "@Article{Casey2008AnalysisOM,\n author = {M. Casey and Christophe
      Rhodes and M. Slaney},\n booktitle = {IEEE Transactions on Audio, Speech, and
      Language Processing},\n journal = {IEEE Transactions on Audio, Speech, and Language
      Processing},\n pages = {1015-1028},\n title = {Analysis of Minimum Distances
      in High-Dimensional Musical Spaces},\n volume = {16},\n year = {2008}\n}\n"},
      "authors": [{"authorId": "1734296", "name": "M. Casey"}, {"authorId": "20522319",
      "name": "Christophe Rhodes"}, {"authorId": "145290352", "name": "M. Slaney"}]},
      {"paperId": "44c3c4da8b0606695e819547da8fc05521f0241b", "externalIds": {"PubMedCentral":
      "3765529", "MAG": "2058124910", "DBLP": "journals/bmcbi/MeyerKB13", "DOI": "10.1186/1471-2105-14-226",
      "CorpusId": 255795319, "PubMed": "23865810"}, "corpusId": 255795319, "publicationVenue":
      {"id": "be3f884c-b44a-496a-a593-1cad3f89d254", "name": "BMC Bioinformatics",
      "type": "journal", "alternate_names": ["BMC Bioinform"], "issn": "1471-2105",
      "url": "http://www.biomedcentral.com/bmcbioinformatics", "alternate_urls": ["http://www.pubmedcentral.nih.gov/tocrender.fcgi?journal=13",
      "http://www.biomedcentral.com/bmcbioinformatics/"]}, "url": "https://www.semanticscholar.org/paper/44c3c4da8b0606695e819547da8fc05521f0241b",
      "title": "Fast online and index-based algorithms for approximate search of RNA
      sequence-structure patterns", "abstract": null, "venue": "BMC Bioinformatics",
      "year": 2013, "referenceCount": 43, "citationCount": 6, "influentialCitationCount":
      1, "isOpenAccess": true, "openAccessPdf": {"url": "https://bmcbioinformatics.biomedcentral.com/counter/pdf/10.1186/1471-2105-14-226",
      "status": "GOLD"}, "fieldsOfStudy": ["Medicine", "Computer Science"], "s2FieldsOfStudy":
      [{"category": "Medicine", "source": "external"}, {"category": "Computer Science",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Biology", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2013-07-17", "journal": {"name": "BMC Bioinformatics", "pages":
      "226 - 226", "volume": "14"}, "citationStyles": {"bibtex": "@Article{Meyer2013FastOA,\n
      author = {F. Meyer and S. Kurtz and M. Beckstette},\n booktitle = {BMC Bioinformatics},\n
      journal = {BMC Bioinformatics},\n pages = {226 - 226},\n title = {Fast online
      and index-based algorithms for approximate search of RNA sequence-structure
      patterns},\n volume = {14},\n year = {2013}\n}\n"}, "authors": [{"authorId":
      "47100055", "name": "F. Meyer"}, {"authorId": "8419159", "name": "S. Kurtz"},
      {"authorId": "49483183", "name": "M. Beckstette"}]}, {"paperId": "f599c57cbd424f73bb61d9363cda4ffd98a1f9a7",
      "externalIds": {"MAG": "2769077354", "DOI": "10.12783/DTCSE/AITA2017/16038",
      "CorpusId": 196021610}, "corpusId": 196021610, "publicationVenue": null, "url":
      "https://www.semanticscholar.org/paper/f599c57cbd424f73bb61d9363cda4ffd98a1f9a7",
      "title": "Structural Stability for User Interfaces", "abstract": "In this article
      the author proposes a method to perform necessary changes in an interface while
      retaining its efficiency and \u201cfamiliar appearance\u201d. Introduction Combinatorial
      optimization problems arise in Human-Computer Interaction (HCI) in general and
      in User Interfaces (UI) in particular with increasing evidence [1,2,3,4]. One
      of the most challenging parts of the research efforts in this direction is to
      combine two weakly compatible criteria: to make the structure of an interface
      flexible and open for the future changes without serious shuffle\u2014which
      always shocks the users\u2014on one hand, and to provide an efficient near-optimal
      access time on the other. In this article I approach this problem from the \u201cadaptive
      stability\u201d viewpoint [5,6]. Definitions and Designations Let \u03b1 denote
      a solution (for example, an interface, layout or menu system) and let A be the
      set of all solutions. It can be the set of the solutions that are already \u201cgood\u201d
      in some formal sense. For example, those that possess a certain level of efficiency
      formalized by some function 1 ) ( T F > \u03b1 for some threshold 1 T . Let
      i be an item (item of a menu system, rectangular picture-link of a layout, button
      of a keyboard). Those, combined in a proper way, form a solution, so an item
      is a \u201cbrick\u201d of each \u03b1 . All possible (both available for now
      and potentially in the future) items form the set I . Each item of I is assigned
      its probability to occur: ) (i p . This value can also be treated as importance.
      For simplicity, below we consider only the interfaces that consist of the slots
      j s that are to be filled with items from I . Despite such a narrowing, we still
      have a lot of Human-Computer Interaction problems here: e.g., layouts, menus,
      keyboards. The position of each slot s is characterized by its \u201cavailability\u201d
      ) (s d (e.g., Fitt\u2019s law distance [7] to it from some fixed starting point).
      Below we suppose that the slots are ordered by d and form a sequence. Since
      the ordered slots form a linear sequence, the corresponding assignment of the
      items to the slot may be considered as a long string, where the items are the
      letters and the slots are the positions. To compare the structural closeness
      of two interfaces we may benefit from this linear representation by applying
      one of the well-known edit distances (e.g. Levenshtein distance ) , ( 2 1 \u03b1
      \u03b1 l e (insertion, deletion, substitution) or Hamming distance ) , ( 2 1
      \u03b1 \u03b1 h e (only substitution) [8, 9]). Let ) , ( \u03b1 i Distortion
      be the operator that takes an existing solution \u03b1 , a new item i and produces
      a new solution by some formalized algorithm, integrating i into \u03b1 , or
      removing it, or producing something more complicated. Let D be the set of all
      \u201cavailable\u201d distortion operators (somehow preselected). For the discussion
      below, I will stick to the addition of a new item, although the approach may
      have wider applications. There may be many ways to define this distortion operator.
      I give two simple examples for a layout interface (see Figure 1). The rectangles
      represent the slots and the colors represent the items (more red", "venue":
      "", "year": 2017, "referenceCount": 9, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      null, "publicationDate": "2017-11-28", "journal": {"name": "DEStech Transactions
      on Computer Science and Engineering", "volume": ""}, "citationStyles": {"bibtex":
      "@Article{Ivanko2017StructuralSF,\n author = {E. Ivanko},\n journal = {DEStech
      Transactions on Computer Science and Engineering},\n title = {Structural Stability
      for User Interfaces},\n year = {2017}\n}\n"}, "authors": [{"authorId": "144862190",
      "name": "E. Ivanko"}]}, {"paperId": "2cd166b60816d4ec076eef684b139c1989999d22",
      "externalIds": {"MAG": "2187092961", "CorpusId": 14893442}, "corpusId": 14893442,
      "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/2cd166b60816d4ec076eef684b139c1989999d22",
      "title": "A Comparative Performance Analysis of Approximate String Matching",
      "abstract": "This paper presents a comparative study to evaluate experimental
      results for approximate string matching algorithms on the basis of edit distance.
      We compare the algorithms in terms of the number of character comparisons and
      the running time for molecular data, binary alphabets English alphabets etc.
      The terms like word processors, web search engine, molecular sequence, DNA sequence
      analysis and natural language processing have lead to the development of many
      algorithms in the field of pattern matching in a string. Amongst the various
      string searching algorithms being used, here the focus is mainly approximate
      implementation of pattern matching algorithms such as Knuth-Morris-Pratt, Boyer-Moore,
      Raita, Horspool based on PHP. The comparison between these algorithms is done
      with the help of Levenshtein distance. It also describes the importance of design
      of efficient \"Approximate Pattern Search Algorithms in molecular database,
      binary alphabets, English alphabets and so on\". This approach is advantageous
      from all other string-pattern matching algorithms in terms of time complexity.
      Therefore this procedure improves the efficiency of approximate string matching
      and gives the near-optimal results.", "venue": "", "year": 2013, "referenceCount":
      5, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
      null, "journal": {"name": "", "volume": ""}, "citationStyles": {"bibtex": "@Inproceedings{Jain2013ACP,\n
      author = {Shivani Jain},\n title = {A Comparative Performance Analysis of Approximate
      String Matching},\n year = {2013}\n}\n"}, "authors": [{"authorId": "46815131",
      "name": "Shivani Jain"}]}, {"paperId": "aaadcdc2f1964957f587e780d4a66fe8770fa6e6",
      "externalIds": {"CorpusId": 212531853}, "corpusId": 212531853, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/aaadcdc2f1964957f587e780d4a66fe8770fa6e6",
      "title": "Fig-1: Locate all occurrence of the pattern P in a text T. II. IMPLEMENTATION
      OF DIFFERENT PATTERN MATCHING", "abstract": "123 Abstract\u2014 This paper presents
      a comparative study to evaluate experimental results for approximate string
      matching algorithms on the basis of edit distance. We compare the algorithms
      in terms of the number of character comparisons and the running time for molecular
      data, binary alphabets English alphabets etc. The terms like word processors,
      web search engine, molecular sequence, DNA sequence analysis and natural language
      processing have lead to the development of many algorithms in the field of pattern
      matching in a string. Amongst the various string searching algorithms being
      used, here the focus is mainly approximate implementation of pattern matching
      algorithms such as Knuth-Morris-Pratt, Boyer-Moore, Raita, Horspool based on
      PHP. The comparison between these algorithms is done with the help of Levenshtein
      distance. It also describes the importance of design of efficient \u201cApproximate
      Pattern Search Algorithms in molecular database, binary alphabets, English alphabets
      and so on\u201d. This approach is advantageous from all other string-pattern
      matching algorithms in terms of time complexity. Therefore this procedure improves
      the efficiency of approximate string matching and gives the near-optimal results.",
      "venue": "", "year": 2013, "referenceCount": 8, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      null, "publicationDate": null, "journal": null, "citationStyles": {"bibtex":
      "@Inproceedings{Jain2013Fig1LA,\n author = {Shivani Jain and A. Rao},\n title
      = {Fig-1: Locate all occurrence of the pattern P in a text T. II. IMPLEMENTATION
      OF DIFFERENT PATTERN MATCHING},\n year = {2013}\n}\n"}, "authors": [{"authorId":
      "46815131", "name": "Shivani Jain"}, {"authorId": "2113654250", "name": "A.
      Rao"}]}, {"paperId": "173499656cb9f1e37445398b4c8ea9d9f7867e67", "externalIds":
      {"ArXiv": "1711.02035", "MAG": "2767396238", "DBLP": "journals/corr/abs-1711-02035",
      "CorpusId": 125835323}, "corpusId": 125835323, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/173499656cb9f1e37445398b4c8ea9d9f7867e67",
      "title": "FAMOUS: Fast Approximate string Matching using OptimUm search Schemes",
      "abstract": "Finding approximate occurrences of a pattern in a text using a
      full-text index is a central problem in bioinformatics. Bidirectional indices
      have opened new possibilities for solving the problem as they allow the search
      to be started from anywhere within the pattern and extended in both directions.
      In particular, use of search schemes (partitioning the pattern into several
      pieces and searching the pieces in certain orders with bounds on the number
      of errors in each piece) has shown significant potential in speeding up approximate
      matching. However, finding the optimal search scheme to maximize the search
      speed is a difficult combinatorial optimization problem. In this paper, we propose,
      for the first time, a method to solve the optimal search scheme problem for
      Hamming distance with given number of pieces. Our method is based on formulating
      the problem as a mixed integer program (MIP). We show that the optimal solutions
      found by our MIP significantly improve upon previously published ad-hoc solutions.
      Our MIP can solve problems of considerable size to optimality in reasonable
      time and has the attractive property of finding near-optimal solutions for much
      larger problems in a very short amount of time. In addition, we present FAMOUS
      (Fast Approximate string Matching using OptimUm search Schemes), a bidirectional
      search (for Hamming and edit distance) implemented in SeqAn that performs the
      search based on the optimal search schemes from our MIP. We show that FAMOUS
      is up to 35 times faster than standard backtracking and anticipate that it will
      improve many tools as a new core component for approximate matching and NGS
      data analysis. We exemplify this by searching Illumina reads completely in our
      index at a speed comparable to or faster than current read mapping tools. Finally,
      we pose several open problems regarding our MIP formulation and use of its solutions
      in bidirectional search.", "venue": "arXiv.org", "year": 2017, "referenceCount":
      18, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Biology", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2017-11-06", "journal":
      {"name": "ArXiv", "volume": "abs/1711.02035"}, "citationStyles": {"bibtex":
      "@Article{Kianfar2017FAMOUSFA,\n author = {Kiavash Kianfar and Christopher Pockrandt
      and Bahman Torkamandi and Haochen Luo and K. Reinert},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {FAMOUS: Fast Approximate string Matching using
      OptimUm search Schemes},\n volume = {abs/1711.02035},\n year = {2017}\n}\n"},
      "authors": [{"authorId": "2398260", "name": "Kiavash Kianfar"}, {"authorId":
      "3451200", "name": "Christopher Pockrandt"}, {"authorId": "30109403", "name":
      "Bahman Torkamandi"}, {"authorId": "30152292", "name": "Haochen Luo"}, {"authorId":
      "2031588", "name": "K. Reinert"}]}, {"paperId": "42bb7a1af10aedf832ee0c963aaca4071dd6f49a",
      "externalIds": {"CorpusId": 14814805}, "corpusId": 14814805, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/42bb7a1af10aedf832ee0c963aaca4071dd6f49a",
      "title": "New Models and Algorithms for Multidimensional Approximate Pattern
      Matching", "abstract": "We focus on how to compute the edit distance (or similarity)
      b etween two images and the problem of approximate string matching in two dimens
      ions, that is, to find a pattern of sizem m in a text of sizen n with at mostk
      errors (character substitutions, insertions and deletions). Pattern and text
      are matrices over an alphabet o f size . We present new models and give the
      first sublinear time search algorithms for the new an d the existing models.
      The only existing model just considers errors along one dime nsion. The associated
      approximate search algorithms use dynamic programming and are rel ativ ly expensive
      ( O(m2n2) or O(k2n2)). For this model we present a filtering algorithm which
      avoid s verifying most of the text with dynamic programming. This filter is
      based on one-di mensional multipattern approximate searching. The average complexity
      of our resulting alg orithm isO(n2k log m =m2) for k < m(m+ 1)=(5 log m), which
      is optimal and matches the best previous result that a llows only substitutions.
      We present other slower filtration algo rithms that however work for higher
      error levels. We then consider more general models to compare images. We pr
      es nt new similarity measures and the algorithms to compute them. We then focus
      on one of th models, which allows the errors to occur along any dimension, and
      extend it to the g en ral case where pattern and text ared-dimensional. This
      edit distance can be computed in O(d!m2d) time andO(d!m2d 1) space. We also
      present the first sublinear-time (on average) searching algorithm (i.e. not
      all text cells are inspected), which is O(knd=md 1) time fork < (m=(d(log (m=d))))d
      1.", "venue": "", "year": 2000, "referenceCount": 46, "citationCount": 8, "influentialCitationCount":
      1, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": null,
      "journal": null, "citationStyles": {"bibtex": "@Inproceedings{Baeza-Yates2000NewMA,\n
      author = {R. Baeza-Yates and G. Navarro},\n title = {New Models and Algorithms
      for Multidimensional Approximate Pattern Matching},\n year = {2000}\n}\n"},
      "authors": [{"authorId": "1389957009", "name": "R. Baeza-Yates"}, {"authorId":
      "143678972", "name": "G. Navarro"}]}, {"paperId": "c07f5037f20004cd14f9fae6261e86ba11b13994",
      "externalIds": {"DBLP": "conf/IEEEcit/YoonPC10", "MAG": "1986921409", "DOI":
      "10.1109/CIT.2010.129", "CorpusId": 7051504}, "corpusId": 7051504, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/c07f5037f20004cd14f9fae6261e86ba11b13994",
      "title": "A Smart Filtering System for Newly Coined Profanities by Using Approximate
      String Alignment", "abstract": "Verbal abuse is becoming a serious social problem
      in online communication, because anonymity makes it easier to use profanities.
      Detecting and removing some words that have been registered in a forbidden list
      is a straightforward filtering method. This is simple, but preparing the forbidden
      word list is difficult as newly coined words have to be added to the lexicon.
      Especially Korean is a type of agglutinative language, so the construction of
      new variations of a vulgar word is easy without causing difficulties in textual
      communications in an online environment. In this paper we propose a new method
      to detect all variations of a vulgar word with phoneme modification by applying
      a phoneme based string alignment. However, aligning a query word against all
      vulgar words registered in a database takes time and its computation is difficult.
      We propose a R*-tree based searching algorithm to overcome this expensive computation.
      The method applies the metric space property of string edit distance. We prepared
      a word database with more than 9300 prototype vulgar words for experiment. For
      a given query word, our algorithm quickly finds the best-aligned candidate word(0.006
      sec. with 1000 words), which are within an edit distance equals of one unit.
      Our contribution is that we empirically found the number of pivot words to create
      a near optimal searching space.", "venue": "2010 10th IEEE International Conference
      on Computer and Information Technology", "year": 2010, "referenceCount": 14,
      "citationCount": 15, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Linguistics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle", "Conference"], "publicationDate": "2010-06-29",
      "journal": {"name": "2010 10th IEEE International Conference on Computer and
      Information Technology", "pages": "643-650"}, "citationStyles": {"bibtex": "@Article{Yoon2010ASF,\n
      author = {T. Yoon and Sun-young Park and Hwan-Gue Cho},\n booktitle = {2010
      10th IEEE International Conference on Computer and Information Technology},\n
      journal = {2010 10th IEEE International Conference on Computer and Information
      Technology},\n pages = {643-650},\n title = {A Smart Filtering System for Newly
      Coined Profanities by Using Approximate String Alignment},\n year = {2010}\n}\n"},
      "authors": [{"authorId": "2373532", "name": "T. Yoon"}, {"authorId": "2115534065",
      "name": "Sun-young Park"}, {"authorId": "144767439", "name": "Hwan-Gue Cho"}]},
      {"paperId": "4a33f17125d41fcfbc75928cc0ea98e9360434f8", "externalIds": {"MAG":
      "643665888", "DBLP": "conf/esa/2008", "DOI": "10.1007/978-3-540-87744-8", "CorpusId":
      1561833}, "corpusId": 1561833, "publicationVenue": {"id": "da625a67-4bac-4737-81b6-af5459021b72",
      "name": "Embedded Systems and Applications", "type": "conference", "alternate_names":
      ["ESA", "European Symposium on Algorithms", "Embed Syst Appl", "Eur Symp Algorithm"],
      "url": "http://esa-symposium.org/"}, "url": "https://www.semanticscholar.org/paper/4a33f17125d41fcfbc75928cc0ea98e9360434f8",
      "title": "Algorithms - ESA 2008, 16th Annual European Symposium, Karlsruhe,
      Germany, September 15-17, 2008. Proceedings", "abstract": null, "venue": "Embedded
      Systems and Applications", "year": 2008, "referenceCount": 0, "citationCount":
      91, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category":
      "Mathematics", "source": "s2-fos-model"}], "publicationTypes": ["Conference"],
      "publicationDate": null, "journal": {"volume": "5193"}, "citationStyles": {"bibtex":
      "@Conference{None,\n booktitle = {Embedded Systems and Applications},\n title
      = {Algorithms - ESA 2008, 16th Annual European Symposium, Karlsruhe, Germany,
      September 15-17, 2008. Proceedings},\n volume = {5193},\n year = {2008}\n}\n"},
      "authors": []}, {"paperId": "1227b8f92236ea90d1a0716ce47c18d589b1fdb8", "externalIds":
      {"MAG": "29414154", "CorpusId": 1325849}, "corpusId": 1325849, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/1227b8f92236ea90d1a0716ce47c18d589b1fdb8",
      "title": "Application of the -Nearest-Neighbour Rule to the Classification of
      Banded Chromosomes", "abstract": "The-nearest-neighbour rule based on the edit
      distance is applied to the classification of human chromosomes represented as
      strings. Results are clearly better than those reported with other general-purpose
      pattern classification techniques, and also considerably better than those achieved
      by approaches that have been tightly tuned for this task. The-nearest-neighbour
      rule is a simple, well-known pattern classification technique [1]. This rule
      requires a metric, a positive integer , and a set of labeled patterns or \"
      prototypes \". A new (unlabeled) test pattern is assigned to the label most
      frequently represented among its nearest neighbours; that is, the set of prototypes
      that are closest to it with respect to the metric. (Ties are resolved by an
      appropriate auxiliary procedure.) This technique has attracted considerable
      interest due to its simplicity and near-optimal asymptotic behaviour. It is
      also remarkable that it does not require patterns to be represented in a suitable
      vector space, since only a dissimilarity measure or distance function is required
      to compare any pair of patterns. In this paper we consider the application of
      the-nearest-neighbour rule to the classification of human chromosomes, a task
      of central importance in the study of chromosomes and chromosome abnormalities
      (Cytogenetics). The normal human \" karyotype \" or set of chromosomes consists
      of 22 homologous pairs of \" autosomes \" and one pair of sex chromosomes. Although
      chromosomes are somewhat less condensed and are not visible during most of the
      cell cycle, they become highly condensed during cell division, specially at
      the metaphase stage, and are then visible as dark distinct bodies within the
      nuclei of cells. Their characteristic banding is obtained by staining with various
      dyes. The band width and the order of bands facilitates recognition of different
      chromosome types. The data used in our experiments was extracted from a database
      of approximately \u00bc\u00bc\u00bc chromosomes that have been classified by
      cytogenetic experts [4]. Each digitized chromosome image was transformed into
      a string through a procedure that starts obtaining an idealized, one-dimensional
      density profile that emphasizes the band pattern along the chromosome. The ide-alized
      profile is then mapped nonlinearly into a string composed of symbols from the
      alphabet \u00bd \u00be \u00bf. This string is difference coded to represent
      signed differences of successive symbols, using the alphabet \u00a6 (\" = \"
      for a difference of 0; \" A \" for +1; \" a \" for-1; etc.). Optionally, the
      centromere (transition between the \u00d4-arm and the longer \u2026", "venue":
      "", "year": 1999, "referenceCount": 6, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics"],
      "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category":
      "Biology", "source": "s2-fos-model"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": null, "publicationDate": null, "journal":
      {"name": "", "volume": ""}, "citationStyles": {"bibtex": "@Inproceedings{Juan1999ApplicationOT,\n
      author = {A. Juan},\n title = {Application of the -Nearest-Neighbour Rule to
      the Classification of Banded Chromosomes},\n year = {1999}\n}\n"}, "authors":
      [{"authorId": "144240902", "name": "A. Juan"}]}, {"paperId": "615194fc4725c7a44c6d80e8b3747453ecf6b3ec",
      "externalIds": {"CorpusId": 1569884}, "corpusId": 1569884, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/615194fc4725c7a44c6d80e8b3747453ecf6b3ec",
      "title": "6 Antennas of RFID Tags", "abstract": "Radio Frequency Identification
      (RFID) is a rapidly developing technology which uses RF signals for automatic
      identification of objects. RFID system generally consists of three components:
      1) A small electronic data carrying device called a transponder or tag that
      is attached to the item to be identified, 2) A reader that communicates with
      the tag using radio frequency signals, 3) A host data processing system that
      contains the information of the identified item and distributes the information
      between other remote data processing systems. A typical passive RFID tag consists
      of an antenna and RFID chip. RFID tags can be active (with battery) or passive
      (without battery). In particular, passive UHF (860 ~ 960) MHz tags represent
      a near optimal combination of cost and performance (Hunt et al., 2007). Generally,
      omni directionality for the tag antenna is preferred to ensure the identification
      from all directions. The structure of the tag antenna should also be low cost,
      small in size, have good impedance matching and insensitive to the attached
      objects to keep performance consistent (Curty et al., 2007). A passive RFID
      system operates in the following way: RFID reader transmits a modulated RF signal
      to the RFID tag consisting of an antenna and an integrated circuit chip. The
      chip receives power from the antenna and responds by varying its input impedance
      and thus modulating the backscattered signal. Modulation type often used in
      RFID is amplitude shift keying (ASK) where the chip impedance switches between
      two states: one is matched to the antenna (chip collects power in that state)
      and another one is strongly mismatched. The most important RFID system performance
      characteristic is tag range \u2013 the maximum distance at which RFID reader
      can either read or write information to the tag. Tag range is defined with respect
      to a certain read/write rate (percentage of successful reads/writes) which varies
      with a distance and depends on RFID reader characteristics and propagation environment
      (Nikitin & Rao, 2006). In this chapter, the operation theory of the RFID system
      is described. The antenna in RFID system is discussed, and the designing considerations
      of the antennas for RFID applications are presented. Also the design, simulation
      and implementation of some commonly used antennas in the RFID system are presented
      and investigated. IE3D electromagnetic simulator based on Method of Moment (MoM)
      is used to design some of these antennas. Source: Radio Frequency Identification
      Fundamentals and Applications, Design Methods and Solutions, Book edited by:
      Cristina Turcu, ISBN 978-953-7619-72-5, pp. 324, February 2010, INTECH, Croatia,
      downloaded from SCIYO.COM", "venue": "", "year": 2012, "referenceCount": 17,
      "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category": "Engineering",
      "source": "s2-fos-model"}, {"category": "Physics", "source": "s2-fos-model"}],
      "publicationTypes": null, "publicationDate": null, "journal": null, "citationStyles":
      {"bibtex": "@Inproceedings{Salama20126AO,\n author = {A. Salama},\n title =
      {6 Antennas of RFID Tags},\n year = {2012}\n}\n"}, "authors": [{"authorId":
      "2065059667", "name": "A. Salama"}]}, {"paperId": "681a0a18725a959a53266940bd76fafd3121ed61",
      "externalIds": {"MAG": "1603063140", "CorpusId": 117005914}, "corpusId": 117005914,
      "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/681a0a18725a959a53266940bd76fafd3121ed61",
      "title": "Algorithms and computation : 17th International Symposium, ISAAC 2006,
      Kolkata, India, December 18-20, 2006 : proceedings", "abstract": "Invited Talks.-
      Stable Matching Problems.- Delaunay Meshing of Surfaces.- Best Paper 2006.-
      Algorithmic Graph Minor Theory: Improved Grid Minor Bounds and Wagner''s Contraction.-
      Best Student Paper 2006.- Branching and Treewidth Based Exact Algorithms.- Session
      1A: Algorithms and Data Structures.- Deterministic Splitter Finding in a Stream
      with Constant Storage and Guarantees.- Optimal Algorithms for Tower of Hanoi
      Problems with Relaxed Placement Rules.- Flexible Word Design and Graph Labeling.-
      Session 1B: Online Algorithms.- Frequency Allocation Problems for Linear Cellular
      Networks.- Finite-State Online Algorithms and Their Automated Competitive Analysis.-
      Offline Sorting Buffers on Line.- Session 2A: Approximation Algorithms.- Approximating
      Tree Edit Distance Through String Edit Distance.- A 6-Approximation Algorithm
      for Computing Smallest Common AoN-Supertree with Application to the Reconstruction
      of Glycan Trees.- Improved Approximation for Single-Sink Buy-at-Bulk.- Approximability
      of Partitioning Graphs with Supply and Demand.- Session 2B: Graphs.- Convex
      Grid Drawings of Plane Graphs with Rectangular Contours.- Algorithms on Graphs
      with Small Dominating Targets.- Efficient Algorithms for Weighted Rank-Maximal
      Matchings and Related Problems.- On Estimating Path Aggregates over Streaming
      Graphs.- Session 3A: Computational Geometry.- Diamond Triangulations Contain
      Spanners of Bounded Degree.- Optimal Construction of the City Voronoi Diagram.-
      Relations Between Two Common Types of Rectangular Tilings.- Quality Tetrahedral
      Mesh Generation for Macromolecules.- On Approximating the TSP with Intersecting
      Neighborhoods.- Session 3B: Computational Complexity.- Negation-Limited Complexity
      of Parity and Inverters.- The Complexity of Quasigroup Isomorphism and the Minimum
      Generating Set Problem.- Inverse HAMILTONIAN CYCLE and Inverse 3-D MATCHING
      Are coNP-Complete.- Parameterized Problems on Coincidence Graphs.- On 2-Query
      Codeword Testing with Near-Perfect Completeness.- Session 4A: Algorithms and
      Data Structures.- Poketree: A Dynamically Competitive Data Structure with Good
      Worst-Case Performance.- Efficient Algorithms for the Optimal-Ratio Region Detection
      Problems in Discrete Geometry with Applications.- On Locating Disjoint Segments
      with Maximum Sum of Densities.- Two-Tier Relaxed Heaps.- Session 4B: Games and
      Networks.- The Interval Liar Game.- How Much Independent Should Individual Contacts
      Be to Form a Small-World?.- Faster Centralized Communication in Radio Networks.-
      On the Runtime and Robustness of Randomized Broadcasting.- Session 5A: Combinatorial
      Optimization and Computational Biology.- Local Search in Evolutionary Algorithms:
      The Impact of the Local Search Frequency.- Non-cooperative Facility Location
      and Covering Games.- Optimal Algorithms for the Path/Tree-Shaped Facility Location
      Problems in Trees.- Multiobjective Optimization: Improved FPTAS for Shortest
      Paths and Non-linear Objectives with Applications.- Algorithms for Computing
      Variants of the Longest Common Subsequence Problem.- Session 5B: Graphs.- Constructing
      Labeling Schemes Through Universal Matrices.- Making Arbitrary Graphs Transitively
      Orientable: Minimal Comparability Completions.- Analyzing Disturbed Diffusion
      on Networks.- Exact Algorithms for Finding the Minimum Independent Dominating
      Set in Graphs.- On Isomorphism and Canonization of Tournaments and Hypertournaments.-
      Session 6A: Algorithms and Data Structures.- Efficient Algorithms for the Sum
      Selection Problem and K Maximum Sums Problem.- Deterministic Random Walks on
      the Two-Dimensional Grid.- Improving Time and Space Complexity for Compressed
      Pattern Matching.- Improved Multi-unit Auction Clearing Algorithms with Interval
      (Multiple-Choice) Knapsack Problems.- Session 6B: Graphs.- A Simple Message
      Passing Algorithm for Graph Partitioning Problems.- Minimal Interval Completion
      Through Graph Exploration.- Balanced Cut Approximation in Random Geometric Graphs.-
      Improved Algorithms for the Minmax-Regret 1-Center Problem.- Session 7A: Approximation
      Algorithms.- On Approximating the Maximum Simple Sharing Problem.- Approximation
      Scheme for Lowest Outdegree Orientation and Graph Density Measures.- Improved
      Approximation Algorithms for Maximum Resource Bin Packing and Lazy Bin Covering
      Problems.- Session 7B: Graphs.- Partitioning the Nodes of a Graph to Minimize
      the Sum of Subgraph Radii.- Efficient Prufer-Like Coding and Counting Labelled
      Hypertrees.- Intuitive Algorithms and t-Vertex Cover.- Session 8A: Combinatorial
      Optimization and Quantum Computing.- Politician''s Firefighting.- Runtime Analysis
      of a Simple Ant Colony Optimization Algorithm.- Lower Bounds on the Deterministic
      and Quantum Communication Complexities of Hamming-Distance Problems.- Resources
      Required for Preparing Graph States.- Session 8B: Online Algorithms.- Online
      Multi-path Routing in a Maze.- On the On-Line k-Truck Problem with Benefit Maximization.-
      Energy-Efficient Broadcast Scheduling for Speed-Controlled Transmission Channels.-
      Online Packet Admission and Oblivious Routing in Sensor Networks.- Session 9A:
      Computational Geometry.- Field Splitting Problems in Intensity-Modulated Radiation
      Therapy.- Shape Rectangularization Problems in Intensity-Modulated Radiation
      Therapy.- A New Approximation Algorithm for Multidimensional Rectangle Tiling.-
      Tessellation of Quadratic Elements.- Session 9B: Distributed Computing and Cryptography.-
      Effective Elections for Anonymous Mobile Agents.- Gathering Asynchronous Oblivious
      Mobile Robots in a Ring.- Provably Secure Steganography and the Complexity of
      Sampling.", "venue": "", "year": 2006, "referenceCount": 0, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Mathematics"], "s2FieldsOfStudy": [{"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      null, "publicationDate": null, "journal": {"name": "", "volume": ""}, "citationStyles":
      {"bibtex": "@Inproceedings{\u54f2\u592b2006AlgorithmsAC,\n author = {\u6d45\u91ce
      \u54f2\u592b},\n title = {Algorithms and computation : 17th International Symposium,
      ISAAC 2006, Kolkata, India, December 18-20, 2006 : proceedings},\n year = {2006}\n}\n"},
      "authors": [{"authorId": "2097149575", "name": "\u6d45\u91ce \u54f2\u592b"}]},
      {"paperId": "d3a6b52333b168e91021dae4a0e260e3f5ba64da", "externalIds": {"MAG":
      "1560672642", "DOI": "10.5772/7973", "CorpusId": 60748664}, "corpusId": 60748664,
      "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/d3a6b52333b168e91021dae4a0e260e3f5ba64da",
      "title": "Antennas of RFID Tags", "abstract": "Radio Frequency Identification
      (RFID) is a rapidly developing technology which uses RF signals for automatic
      identification of objects. RFID system generally consists of three components:
      1) A small electronic data carrying device called a transponder or tag that
      is attached to the item to be identified, 2) A reader that communicates with
      the tag using radio frequency signals, 3) A host data processing system that
      contains the information of the identified item and distributes the information
      between other remote data processing systems. A typical passive RFID tag consists
      of an antenna and RFID chip. RFID tags can be active (with battery) or passive
      (without battery). In particular, passive UHF (860 ~ 960) MHz tags represent
      a near optimal combination of cost and performance (Hunt et al., 2007). Generally,
      omni directionality for the tag antenna is preferred to ensure the identification
      from all directions. The structure of the tag antenna should also be low cost,
      small in size, have good impedance matching and insensitive to the attached
      objects to keep performance consistent (Curty et al., 2007). A passive RFID
      system operates in the following way: RFID reader transmits a modulated RF signal
      to the RFID tag consisting of an antenna and an integrated circuit chip. The
      chip receives power from the antenna and responds by varying its input impedance
      and thus modulating the backscattered signal. Modulation type often used in
      RFID is amplitude shift keying (ASK) where the chip impedance switches between
      two states: one is matched to the antenna (chip collects power in that state)
      and another one is strongly mismatched. The most important RFID system performance
      characteristic is tag range \u2013 the maximum distance at which RFID reader
      can either read or write information to the tag. Tag range is defined with respect
      to a certain read/write rate (percentage of successful reads/writes) which varies
      with a distance and depends on RFID reader characteristics and propagation environment
      (Nikitin & Rao, 2006). In this chapter, the operation theory of the RFID system
      is described. The antenna in RFID system is discussed, and the designing considerations
      of the antennas for RFID applications are presented. Also the design, simulation
      and implementation of some commonly used antennas in the RFID system are presented
      and investigated. IE3D electromagnetic simulator based on Method of Moment (MoM)
      is used to design some of these antennas. Source: Radio Frequency Identification
      Fundamentals and Applications, Design Methods and Solutions, Book edited by:
      Cristina Turcu, ISBN 978-953-7619-72-5, pp. 324, February 2010, INTECH, Croatia,
      downloaded from SCIYO.COM", "venue": "", "year": 2010, "referenceCount": 15,
      "citationCount": 3, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf":
      null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Engineering", "source":
      "s2-fos-model"}, {"category": "Physics", "source": "s2-fos-model"}], "publicationTypes":
      null, "publicationDate": "2010-02-01", "journal": {"name": "", "volume": ""},
      "citationStyles": {"bibtex": "@Inproceedings{Salama2010AntennasOR,\n author
      = {A. Salama},\n title = {Antennas of RFID Tags},\n year = {2010}\n}\n"}, "authors":
      [{"authorId": "2065059667", "name": "A. Salama"}]}, {"paperId": "16ce934a5234c64df0e88823b84788f746099a12",
      "externalIds": {"MAG": "2162506849", "CorpusId": 11267530}, "corpusId": 11267530,
      "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/16ce934a5234c64df0e88823b84788f746099a12",
      "title": "Algorithms and lower bounds in the streaming and sparse recovery models",
      "abstract": "In the data stream computation model, input data is given to us
      sequentially (the data stream), and our goal is to compute or approximate some
      function or statistic on that data using a sublinear (in both the length of
      the stream and the size of the universe of items that can appear in the stream)
      amount of space; in particular, we can store neither the entire stream nor a
      counter for each possible item we might see. \nIn the sparse recovery model
      (also known as compressed sensing), input data is a large but sparse vector
      x \u2208 Rn , and our goal is to design an m \u00d7 n matrix \u03a6, where m
      << n, such that for any sufficiently sparse x we can efficiently recover a good
      approximation of x from \u03a6x. \nAlthough at first glance these two models
      may seem quite different, they are in fact intimately related. In the streaming
      model, most statistics of interest are order-invariant, meaning they care only
      about the frequency of each item in the stream and not their position. For these
      problems, the data in the stream can be viewed as an n-dimensional vector x,
      where xi is the number of occurrences of item i. Using this representation,
      one of the high-level tools that have proven most popular has been the linear
      sketch, where for some m \u00d7 n matrix \u03a6, we maintain \u03a6 x (the sketch)
      for the partial vector x as we progress along the stream. The linearity of the
      mapping \u03a6 allows us to efficiently do incremental updates on our sketch,
      and as in its use in sparse recovery, the linear sketch turns out to be surprisingly
      powerful. In this thesis, we try to answer some questions of interest in each
      model, illustrating both the power and the limitations of the linear sketch.
      \nIn Chapter 2, we provide an efficient sketch for estimating the (planar) Earth-Mover
      Distance (EMD) between two multisets of points. The EMD between point sets A,
      B \u2286 R2 of the same size is defined as the minimum cost of a perfect matching
      between them, with each edge contributing a cost equal to its (Euclidean) length.
      As immediate consequences, we give an improved algorithm for estimating EMD
      between point sets given over a stream, and an improved algorithm for the approximate
      nearest neighbor problem under EMD. \nIn Chapter 3, we prove tight lower bounds
      for sparse recovery in the number of rows in the matrix \u03a6 (i.e., the number
      of measurements) in order to achieve any of the three most studied recovery
      guarantees. Specifically, consider a matrix \u03a6 and an algorithm R such that
      for any signal x, R can recover an approximation x\u02c6 from \u03a6 x satisfying
      x-xd p\u2264Cmink-sparse x\u2032 x-x\u2032 q, where (1) p = q = 1 and C = O(1),
      (2) p = q = 2 and C = O(1), or (3) p = 2, q = 1 and C = O( k\u20131/2). We show
      that any such \u03a6 must have at least \u03a9(k log(n/k)) rows. This is known
      to be optimal in cases (1) and (2), and near optimal for (3). \nIn Chapter 4,
      we propose a variant of sparse recovery that incorporates some additional knowledge
      about the signal that allows the above lower bound to be broken. In particular,
      we consider the scenario where, after measurements are taken, we are given a
      set S of size s << n (s is known beforehand) that is supposed to contain most
      of the \"large\" coefficients of x. The goal is then to recover x\u02c6 satisfying
      x-xd p\u2264Cmin k-sparsex\u2032 supppx\u2032p\u2286S x-x\u2032 q. We refer
      to this formulation as the sparse recovery with partial support knowledge problem
      (SRPSK). We focus on the guarantees where p = q = 1 or 2 and C = 1 + e, for
      which we provide lower bounds as well as a method of converting algorithms for
      \"standard\" sparse recovery into ones for SRPSK. We also make use of one of
      the reductions to give an optimal algorithm for SRPSK for the guarantee where
      p = q = 2. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge,
      MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)", "venue": "", "year": 2012,
      "referenceCount": 73, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics"], "s2FieldsOfStudy":
      [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": null, "publicationDate": null, "journal": {"name": "", "volume":
      ""}, "citationStyles": {"bibtex": "@Inproceedings{Indyk2012AlgorithmsAL,\n author
      = {P. Indyk and Khanh Do Ba},\n title = {Algorithms and lower bounds in the
      streaming and sparse recovery models},\n year = {2012}\n}\n"}, "authors": [{"authorId":
      "1688317", "name": "P. Indyk"}, {"authorId": "2836805", "name": "Khanh Do Ba"}]},
      {"paperId": "7fe51f4d4c54686034fe79bc25dabb43343f20b6", "externalIds": {"MAG":
      "1541952385", "CorpusId": 86526427}, "corpusId": 86526427, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/7fe51f4d4c54686034fe79bc25dabb43343f20b6",
      "title": "Combinatorial pattern matching : 11th Annual Symposium, CPM 2000,
      Montreal, Canada, June 21-23, 2000 : proceedings", "abstract": "Invited Lectures.-
      Identifying and Filtering Near-Duplicate Documents.- Machine Learning for Efficient
      Natural-Language Processing.- Browsing around a Digital Library: Today and Tomorrow.-
      Summer School Lectures.- Algorithmic Aspects of Speech Recognition: A Synopsis.-
      Some Results on Flexible-Pattern Discovery.- Contributed Papers.- Explaining
      and Controlling Ambiguity in Dynamic Programming.- A Dynamic Edit Distance Table.-
      Parametric Multiple Sequence Alignment and Phylogeny Construction.- Tsukuba
      BB: A Branch and Bound Algorithm for Local Multiple Sequence Alignment.- A Polynomial
      Time Approximation Scheme for the Closest Substring Problem.- Approximation
      Algorithms for Hamming Clustering Problems.- Approximating the Maximum Isomorphic
      Agreement Subtree Is Hard.- A Faster and Unifying Algorithm for Comparing Trees.-
      Incomplete Directed Perfect Phylogeny.- The Longest Common Subsequence Problem
      for Arc-Annotated Sequences.- Boyer-Moore String Matching over Ziv-Lempel Compressed
      Text.- A Boyer-Moore Type Algorithm for Compressed Pattern Matching.- Approximate
      String Matching over Ziv-Lempel Compressed Text.- Improving Static Compression
      Schemes by Alphabet Extension.- Genome Rearrangement by Reversals and Insertions/Deletions
      of Contiguous Segments.- A Lower Bound for the Breakpoint Phylogeny Problem.-
      Structural Properties and Tractability Results for Linear Synteny.- Shift Error
      Detection in Standardized Exams.- An Upper Bound for Number of Contacts in the
      HP-Model on the Face-Centered-Cubic Lattice (FCC).- The Combinatorial Partitioning
      Method.- Compact Suffix Array.- Linear Bidirectional On-Line Construction of
      Affix Trees.- Using Suffix Trees for Gapped Motif Discovery.- Indexing Text
      with Approximate q-Grams.- Simple Optimal String Matching Algorithm.- Exact
      and Efficient Computation of the Expected Number of Missing and Common Words
      in Random Texts.- Periods and Quasiperiods Characterization.- Finding Maximal
      Quasiperiodicities in Strings.- On the Complexity of Determining the Period
      of a String.", "venue": "", "year": 2000, "referenceCount": 0, "citationCount":
      2, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      null, "publicationDate": null, "journal": {"name": "", "volume": ""}, "citationStyles":
      {"bibtex": "@Inproceedings{Giancarlo2000CombinatorialPM,\n author = {R. Giancarlo
      and D. Sankoff},\n title = {Combinatorial pattern matching : 11th Annual Symposium,
      CPM 2000, Montreal, Canada, June 21-23, 2000 : proceedings},\n year = {2000}\n}\n"},
      "authors": [{"authorId": "3275133", "name": "R. Giancarlo"}, {"authorId": "1693256",
      "name": "D. Sankoff"}]}, {"paperId": "7291c5af547bce92a17db023566e7a16008a4708",
      "externalIds": {"MAG": "2079469303", "DOI": "10.1111/j.1444-0938.2008.00303.x",
      "CorpusId": 21434269, "PubMed": "18761474"}, "corpusId": 21434269, "publicationVenue":
      {"id": "d804318e-9fd7-477c-a8f1-2ad683fba90a", "name": "Clinical and experimental
      optometry", "type": "journal", "alternate_names": ["Clinical and Experimental
      Optometry", "Clin Exp Optom", "Clin exp optom"], "issn": "0816-4622", "url":
      "https://onlinelibrary.wiley.com/journal/14440938"}, "url": "https://www.semanticscholar.org/paper/7291c5af547bce92a17db023566e7a16008a4708",
      "title": "Is BCVA an invention of ophthalmology?", "abstract": "After 15 years
      as editor of Clinical and Experimental Optometry, I have become accustomed to
      many of the idiosyncrasies of our authors. Use of \u2018utilise\u2019 instead
      of \u2018use\u2019, \u2018in order to\u2019 instead of \u2018to\u2019, \u2018at
      this point in time\u2019 instead of \u2018now\u2019, \u2018over this time period\u2019
      instead of \u2018over this period\u2019, \u2018the result was a significant
      one\u2019 instead of \u2018the result was significant\u2019 et cetera. Authors
      who have published in Clinical and Experimental Optometry in recent years will
      be aware that I frequently invoke my rights as an editor to edit, with the aim
      of simplifying the writing style. Visual acuity is the most commonly measured
      function by all ophthalmic practitioners. It is the cornerstone of refraction
      and the most important visual function for assessing the progression of an ocular
      disease or the success of therapy. When I became editor of Clinical and Experimental
      Optometry in 1993, it was rare to find the term \u2018best corrected visual
      acuity\u2019 or \u2018BCVA\u2019 in a proffered manuscript. Now, it is common
      and may occur in 10 to 15 per cent of submitted papers. When referring to the
      optimal spatial resolution of the eye, authors who are optometrists use the
      term \u2018visual acuity\u2019 or \u2018VA\u2019, while those who are ophthalmologists
      or medical practitioners (many of whom may be ophthalmologists) almost invariably
      refer to the \u2018best corrected visual acuity\u2019 or \u2018BCVA\u2019. This
      is consistent with the fact that 15.9 per cent of the 150 authors who published
      in Clinical and Experimental Optometry in 2005 and 2006 were medically qualified
      and of these, more than half were recognisable as ophthalmologists.1 There appears
      to be some confusion in the use of the term \u2018visual acuity\u2019 and it
      may be useful to emulate the enigmatic and slightly mad Professor Julius Sumner
      Miller and ask \u2018Why is it so?\u2019 In March 2008, I searched for these
      terms in the PubMed database (www. ncbi.nlm.nih.gov) with the following results:
      \u2018visual acuity\u2019, 51,031 publications; VA, 49,060; \u2018best corrected
      visual acuity\u2019, 2,785 and BCVA, 844 publications. Because these numbers
      are so large, it was beyond my patience to view all of the entries but I did
      analyse the 844 BCVA entries. Most (83.4 per cent) were published in journals
      with ophthalmology (57.8 per cent) or surgery or medicine (25.6 per cent) in
      the title. A few (16.1 per cent) were in journals with titles not relating to
      a profession, such as, Cornea, Retina, Eye et cetera, while only four (0.5 per
      cent) were in optometric journals. It is also interesting that the oldest paper
      listed in PubMed when searching for \u2018visual acuity\u2019 was published
      in 1902. In contrast, the first publication using the term \u2018best corrected
      visual acuity\u2019 was published in 1976 and for BCVA, 1995. It appears that
      the term \u2018best corrected visual acuity\u2019 and its acronym BCVA are very
      recent inventions that have arisen within the medical profession. The policy
      of Clinical and Experimental Optometry for the use of these terms\u2014at least
      while I am Editor\u2014is that \u2018visual acuity\u2019 refers to the maximum
      resolution of the eye and it is redundant or tautological to use the extended
      term \u2018best corrected visual acuity\u2019 or BCVA. When present, these are
      replaced by the more appropriate terms. When the capacity of the eye is measured
      under less than optimal conditions, it should be referred to as \u2018unaided
      vision\u2019 or \u2018vision without correction\u2019; however, the use of distance
      visual acuity, near acuity and peripheral acuity are, of course, acceptable.
      This is consistent with the third edition of Borish\u2019s textbook,3 the \u2018bible\u2019
      for most schools of optometry in the 1970s and 1980s, which states \u2018when
      taken without a correction, it is recorded as vision; when taken with a correction,
      as the visual acuity.\u2019 If we search for a definition of visual acuity,
      there appears to be no preferred option. Two recent medical dictionaries define
      visual acuity as the \u2018ability to discriminate visually between forms\u2019
      and \u2018a measure of resolving power\u2019. While neither of these definitions
      indicates whether a refractive correction should be worn, the wording implies
      the maximum capacity of the eye, which is independent of refractive error. C
      L I N I C A L A N D E X P E R I M E N T A L", "venue": "Clinical and experimental
      optometry", "year": 2008, "referenceCount": 21, "citationCount": 8, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Medicine"],
      "s2FieldsOfStudy": [{"category": "Medicine", "source": "external"}, {"category":
      "Medicine", "source": "s2-fos-model"}], "publicationTypes": ["Editorial"], "publicationDate":
      "2008-09-01", "journal": {"name": "Clinical and Experimental Optometry", "volume":
      "91"}, "citationStyles": {"bibtex": "@Article{Collin2008IsBA,\n author = {H.
      Collin},\n booktitle = {Clinical and experimental optometry},\n journal = {Clinical
      and Experimental Optometry},\n title = {Is BCVA an invention of ophthalmology?},\n
      volume = {91},\n year = {2008}\n}\n"}, "authors": [{"authorId": "145681323",
      "name": "H. Collin"}]}, {"paperId": "fb00af631372c04a2b3b2c7cfc6cebc323b6241f",
      "externalIds": {"MAG": "1580029614", "CorpusId": 118574899}, "corpusId": 118574899,
      "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/fb00af631372c04a2b3b2c7cfc6cebc323b6241f",
      "title": "Algorithms -- ESA 2003 : 11th Annual European Symposium, Budapest,
      Hungary, September 16-19, 2003 : proceedings", "abstract": "Invited Lectures.-
      Sublinear Computing.- Authenticated Data Structures.- Approximation Algorithms
      and Network Games.- Contributed Papers: Design and Analysis Track.- I/O-Efficient
      Structures for Orthogonal Range-Max and Stabbing-Max Queries.- Line System Design
      and a Generalized Coloring Problem.- Lagrangian Relaxation for the k-Median
      Problem: New Insights and Continuity Properties.- Scheduling for Flow-Time with
      Admission Control.- On Approximating a Geometric Prize-Collecting Traveling
      Salesman Problem with Time Windows.- Semi-clairvoyant Scheduling.- Algorithms
      for Graph Rigidity and Scene Analysis.- Optimal Dynamic Video-on-Demand Using
      Adaptive Broadcasting.- Multi-player and Multi-round Auctions with Severely
      Bounded Communication.- Network Lifetime and Power Assignment in ad hoc Wireless
      Networks.- Disjoint Unit Spheres admit at Most Two Line Transversals.- An Optimal
      Algorithm for the Maximum-Density Segment Problem.- Estimating Dominance Norms
      of Multiple Data Streams.- Smoothed Motion Complexity.- Kinetic Dictionaries:
      How to Shoot a Moving Target.- Deterministic Rendezvous in Graphs.- Fast Integer
      Programming in Fixed Dimension.- Correlation Clustering - Minimizing Disagreements
      on Arbitrary Weighted Graphs.- Dominating Sets and Local Treewidth.- Approximating
      Energy Efficient Paths in Wireless Multi-hop Networks.- Bandwidth Maximization
      in Multicasting.- Optimal Distance Labeling for Interval and Circular-Arc Graphs.-
      Improved Approximation of the Stable Marriage Problem.- Fast Algorithms for
      Computing the Smallest k-Enclosing Disc.- The Minimum Generalized Vertex Cover
      Problem.- An Approximation Algorithm for MAX-2-SAT with Cardinality Constraint.-
      On-Demand Broadcasting Under Deadline.- Improved Bounds for Finger Search on
      a RAM.- The Voronoi Diagram of Planar Convex Objects.- Buffer Overflows of Merging
      Streams.- Improved Competitive Guarantees for QoS Buffering.- On Generalized
      Gossiping and Broadcasting.- Approximating the Achromatic Number Problem on
      Bipartite Graphs.- Adversary Immune Leader Election in ad hoc Radio Networks.-
      Universal Facility Location.- A Method for Creating Near-Optimal Instances of
      a Certified Write-All Algorithm.- I/O-Efficient Undirected Shortest Paths.-
      On the Complexity of Approximating TSP with Neighborhoods and Related Problems.-
      A Lower Bound for Cake Cutting.- Ray Shooting and Stone Throwing.- Parameterized
      Tractability of Edge-Disjoint Paths on Directed Acyclic Graphs.- Binary Space
      Partition for Orthogonal Fat Rectangles.- Sequencing by Hybridization in Few
      Rounds.- Efficient Algorithms for the Ring Loading Problem with Demand Splitting.-
      Seventeen Lines and One-Hundred-and-One Points.- Jacobi Curves: Computing the
      Exact Topology of Arrangements of Non-singular Algebraic Curves.- Contributed
      Papers: Engineering and Application Track.- Streaming Geometric Optimization
      Using Graphics Hardware.- An Efficient Implementation of a Quasi-polynomial
      Algorithm for Generating Hypergraph Transversals.- Experiments on Graph Clustering
      Algorithms.- More Reliable Protein NMR Peak Assignment via Improved 2-Interval
      Scheduling.- The Minimum Shift Design Problem: Theory and Practice.- Loglog
      Counting of Large Cardinalities.- Packing a Trunk.- Fast Smallest-Enclosing-Ball
      Computation in High Dimensions.- Automated Generation of Search Tree Algorithms
      for Graph Modification Problems.- Boolean Operations on 3D Selective Nef Complexes:
      Data Structure, Algorithms, and Implementation.- Fleet Assignment with Connection
      Dependent Ground Times.- A Practical Minimum Spanning Tree Algorithm Using the
      Cycle Property.- The Fractional Prize-Collecting Steiner Tree Problem on Trees.-
      Algorithms and Experiments for the Webgraph.- Finding Short Integral Cycle Bases
      for Cyclic Timetabling.- Slack Optimization of Timing-Critical Nets.- Multisampling:
      A New Approach to Uniform Sampling and Approximate Counting.- Multicommodity
      Flow Approximation Used for Exact Graph Partitioning.- A Linear Time Heuristic
      for the Branch-Decomposition of Planar Graphs.- Geometric Speed-Up Techniques
      for Finding Shortest Paths in Large Sparse Graphs.", "venue": "", "year": 2003,
      "referenceCount": 0, "citationCount": 3, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics"], "s2FieldsOfStudy":
      [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": null, "publicationDate": null, "journal": {"name": "", "volume":
      ""}, "citationStyles": {"bibtex": "@Inproceedings{Battista2003AlgorithmsE,\n
      author = {G. Battista and Uri Zwick},\n title = {Algorithms -- ESA 2003 : 11th
      Annual European Symposium, Budapest, Hungary, September 16-19, 2003 : proceedings},\n
      year = {2003}\n}\n"}, "authors": [{"authorId": "4507538", "name": "G. Battista"},
      {"authorId": "1750794", "name": "Uri Zwick"}]}, {"paperId": "221a1d6939218d3f05d1038289edd2789c80d280",
      "externalIds": {"MAG": "3035413965", "CorpusId": 196049791}, "corpusId": 196049791,
      "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/221a1d6939218d3f05d1038289edd2789c80d280",
      "title": "Development of a cryocooler to provide zero boil-off of a cryogenic
      propellant tank.", "abstract": "Lockheed Martin has been developing advanced
      technology to provide cooling of a cryogenic propellant tank in order to achieve
      zero boil-off during orbital storage periods. Present systems for long duration
      flights show large amounts of propellant loss due to parasitic heat loads. A
      singlestage Pulse Tube cryocooler has been integrated with a cryogenic methane
      tank. The cryocooler provides a flow loop of cold gas that circulates in the
      storage tank and is used to absorb the parasitic heat load, thus allowing the
      tank to remain non-vented. The cryocooler is located at a distance from the
      tank, thus requiring a remote cooling loop. The remote cooling loop uses the
      same working gas as the pulse tube. This flow loop is driven by the same compressor
      used to provide the pressure wave to the pulse tube cold head, an approach that
      adds very little complexity to the overall system. The flow loop utilizes steady
      unidirectional (DC) flow to provide cooling at temperatures near 110 K at the
      remote cooling location. All cooling is provided by the pulse tube cooler, so
      that the remote cooling mechanism is forced convection. This paper describes
      the results from a flow loop developed and tested on a 635-liter cryogenic methane
      tank as a technology demonstrator. The flow loop, driven by a pulse tube cooler,
      delivered cold helium gas to and from the remote location to remove the parasitic
      heat load on the storage tank. INTRODUCTION Numerous future propulsion systems
      will utilize cryogenic propellants to improve performance. While the specific
      impulse is greatly increased over storable propellants, long duration missions
      can result in large amounts of propellant boil-off due to parasitic heat loads
      from the warm environment into the cold propellant tanks. Numerous studies have
      been conducted pointing out the overall system benefits from reduction of or
      elimination of this boil-off by refrigeration means. Since mechanical cryocoolers
      have now been established as high reliability systems, they represent a viable
      means to eliminate or reduce this boil-off. There are numerous approaches to
      employ cryocoolers for reduced boil-off. The optimum approach is system specific.
      These techniques include direct contact of the cryocooler cold tip with the
      tank wall, employment of a circulation loop (this paper) to distribute the cooling
      over large surface areas or multiple tanks, or the employment of various JouleThomson
      approaches. 583 Cryocoolers 14, edited by S.D. Miller and R.G. Ross, Jr. \u00a9\u00b6International
      Cryocooler Conference, Inc., Boulder, CO, 2007 In these approaches, a key consideration
      is to eliminate or reduce the temperature gradients in the propellant due to
      stratification, which increases tank pressure and can lead to pump cavitation.
      One technique to achieve this is to distribute the cooling over large areas\u2014for
      example, over the propellant tank wall or internal heat exchangers to provide
      cooling at the optimum location. This system is described in this paper.", "venue":
      "", "year": 2006, "referenceCount": 4, "citationCount": 4, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Environmental
      Science"], "s2FieldsOfStudy": [{"category": "Environmental Science", "source":
      "external"}, {"category": "Engineering", "source": "s2-fos-model"}, {"category":
      "Physics", "source": "s2-fos-model"}, {"category": "Environmental Science",
      "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": "2006-06-14",
      "journal": {"name": "", "volume": ""}, "citationStyles": {"bibtex": "@Inproceedings{Frank2006DevelopmentOA,\n
      author = {D. Frank and E. Roth and J. Olson},\n title = {Development of a cryocooler
      to provide zero boil-off of a cryogenic propellant tank.},\n year = {2006}\n}\n"},
      "authors": [{"authorId": "97901043", "name": "D. Frank"}, {"authorId": "91907480",
      "name": "E. Roth"}, {"authorId": "2220822", "name": "J. Olson"}]}, {"paperId":
      "0fa09de159b41c8b67c99ff21fdf1212370cd372", "externalIds": {"CorpusId": 196590573},
      "corpusId": 196590573, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/0fa09de159b41c8b67c99ff21fdf1212370cd372",
      "title": "Title : Monitoring the observation impact with Taiwan Central Weather
      Bureau operational analysis / forecast system", "abstract": "Title: Impact of
      upper-air and near-surface observations on short-range forecasts from an hourly
      assimilation cycle (RUC and Rapid Refresh) Authors: Stan Benjamin, Haidao Lin,
      Steve Weygandt, Susan Sahm, David Dowell NOAA Earth System Research Laboratory,
      Boulder, CO The hourly updated model/assimilation cycles in the United States,
      the Rapid Update Cycle (run operationally at NCEP through Jan 2011) and its
      GSI/WRF-based successor, the Rapid Refresh, both provide a unique perspective
      for examining observation impact on very short-range (1-18h) forecasts. One
      initial study has been carried to examine relative impact of aircraft, profiler,
      rawinsonde, VAD wind, GPS-precipitable water, surface-METAR, and mesonet (non-METAR)
      data. In this OSE study (Benjamin et al., Monthly Weather Review, 2010), it
      was found that aircraft observations had the strongest impact on short-range
      forecasts, followed by rawinsonde, and then followed by GPS-PW and surface observations.
      The impact of surface observations was much larger than originally anticipated
      due to augmentation of near-surface data via pseudoinnovations in the boundary
      layer. More recent regional OSE results using 1-h intermittent assimilation
      will be presented at the Workshop using the new Rapid Refresh (to be implemented
      at NCEP in January 2012 replacing the RUC). This paper will be accompanied by
      a study specifically on overall impact from radar reflectivity and radial wind
      assimilation in the same hourly assimilation RUC and Rapid Refresh assimilation
      systems. Regional aspects of a European upper-air network redesign study: results
      obtained with the ALADIN limited-area model at the Hungarian Meteorological
      Service Andr\u00e1s Hor\u00e1nyi, Edit Adamcsek and Gergely B\u00f6l\u00f6ni
      (horanyi.a@met.hu, adamcsek.e@met.hu, boloni.g@met.hu) The main objective of
      the presented study was to provide input for the definition of a European-wide
      network of ground-based upper-air observing systems with special emphasis on
      regional aspects as provided by regional limited-area models. A former study
      (conducted by EUCOS: EUMETNET Composite Observing System programme) indicated
      that the radiosonde and aircraft observations play important role with respect
      to the satellite observations for regional numerical weather prediction. The
      recent work was concentrating on the possible refinement of the upper-air measurement
      network with special emphasis on the radiosonde and aircraft data as regards
      their optimal spatial and temporal distribution. For that purpose, six different
      observing system scenarios have been specified, varying from a full operational-like
      data usage (control scenario) to a baseline scenario, which is characterised
      by radical decrease of the number of radiosonde and aircraft profiles. The intermediate
      scenarios are focusing on the different thinning distances for the radiosonde
      and aircraft data, implying a stepwise degradation of their quantity in terms
      of spatial resolution. The Observing System Experiments (OSEs) based on the
      abovementioned scenarios were performed by the global NWP centre ECMWF and some
      National Meteorological Services (NMS) running limitedarea models. In Hungary
      the ALADIN/HU model was applied in its hydrostatic version with 8 km horizontal
      and 49 levels vertical resolution covering a large part of Europe. Concerning
      the data assimilation setup, an upper-air three-dimensional variational data
      assimilation (3d-var) and an optimal interpolation (OI) surface assimilation
      scheme have been used with 6-hours cycling frequency. The assimilated data consisted
      of surface, radiosonde, aircraft, windprofiler and satellite (Atmospheric Motion
      Vectors and ATOVS/AMSU and MHS) measurements. For the impact studies 00 UTC
      and 06 UTC forecast runs were performed with 54 and 48 hours integration times,
      respectively. Most of the observation denial experiments led to a degradeation
      in the forecast skill with respect to the control scenario, especially up to
      +18 hours. An exception is a scenario when 00 UTC radiosonde observations were
      kept unchanged and only 06, 12 and 18 UTC radiosondes were thinned. This fact
      indicates that in case of optimisation of the European observational network
      one can consider a partial reduction in the 06, 12 and 18 UTC radiosonde ascents
      (probably thanks to the growing availability of the aircraft profiles) but not
      those at 00 UTC. Regional impact studies performed in the COSMO community Alexander
      Cress, Klaus Stephan, Christoph Schraff, Hans-Juergen Bitzer Deutscher Wetterdienst,
      63004 Offenbach, Germany", "venue": "", "year": 2011, "referenceCount": 0, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category": "Environmental Science",
      "source": "s2-fos-model"}], "publicationTypes": ["Review"], "publicationDate":
      null, "journal": null, "citationStyles": {"bibtex": "@Inproceedings{Zhang2011TitleM,\n
      author = {Xin Zhang and Xiangyu Huang},\n title = {Title : Monitoring the observation
      impact with Taiwan Central Weather Bureau operational analysis / forecast system},\n
      year = {2011}\n}\n"}, "authors": [{"authorId": "2149172583", "name": "Xin Zhang"},
      {"authorId": "9111063", "name": "Xiangyu Huang"}]}, {"paperId": "0a39963267a2c817ca40b2dcddf8e8d01ee1ae15",
      "externalIds": {"MAG": "1540917933", "CorpusId": 118220546}, "corpusId": 118220546,
      "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/0a39963267a2c817ca40b2dcddf8e8d01ee1ae15",
      "title": "Algorithms - ESA 2002 : 10th Annual European Symposium, Rome, Italy,
      September 17-21, 2002 : proceedings", "abstract": "Invited Lectures.- Solving
      Traveling Salesman Problems.- Computing Shapes from Point Cloud Data.- Mechanism
      Design for Fun and Profit.- On Distance Oracles and Routing in Graphs.- Contributed
      Papers.- Kinetic Medians and kd-Trees.- Range Searching in Categorical Data:
      Colored Range Searching on Grid.- Near-Linear Time Approximation Algorithms
      for Curve Simplification.- Translating a Planar Object to Maximize Point Containment.-
      Approximation Algorithms for k-Line Center.- New Heuristics and Lower Bounds
      for the Min-Max k-Chinese Postman Problem.- SCIL - Symbolic Constraints in Integer
      Linear Programming.- Implementing I/O-efficient Data Structures Using TPIE.-
      On the k-Splittable Flow Problem.- Partial Alphabetic Trees.- Classical and
      Contemporary Shortest Path Problems in Road Networks: Implementation and Experimental
      Analysis of the TRANSIMS Router.- Scanning and Traversing: Maintaining Data
      for Traversals in a Memory Hierarchy.- Two Simplified Algorithms for Maintaining
      Order in a List.- Efficient Tree Layout in a Multilevel Memory Hierarchy.- A
      Computational Basis for Conic Arcs and Boolean Operations on Conic Polygons.-
      TSP with Neighborhoods of Varying Size.- 1.375-Approximation Algorithm for Sorting
      by Reversals.- Radio Labeling with Pre-assigned Frequencies.- Branch-and-Bound
      Algorithms for the Test Cover Problem.- Constructing Plane Spanners of Bounded
      Degree and Low Weight.- Eager st-Ordering.- Three-Dimensional Layers of Maxima.-
      Optimal Terrain Construction Problems and Applications in Intensity-Modulated
      Radiation Therapy.- Geometric Algorithms for Density-Based Data Clustering.-
      Balanced-Replication Algorithms for Distribution Trees.- Butterflies and Peer-to-Peer
      Networks.- Estimating Rarity and Similarity over Data Stream Windows.- Efficient
      Constructions of Generalized Superimposed Codes with Applications to Group Testing
      and Conflict Resolution in Multiple Access Channels.- Frequency Estimation of
      Internet Packet Streams with Limited Space.- Truthful and Competitive Double
      Auctions.- Optimal Graph Exploration without Good Maps.- Approximating the Medial
      Axis from the Voronoi Diagram with a Convergence Guarantee.- Non-independent
      Randomized Rounding and an Application to Digital Halftoning.- Computing Homotopic
      Shortest Paths Efficiently.- An Algorithm for Dualization in Products of Lattices
      and Its Applications.- Determining Similarity of Conformational Polymorphs.-
      Minimizing the Maximum Starting Time On-line.- Vector Assignment Problems: A
      General Framework.- Speeding Up the Incremental Construction of the Union of
      Geometric Objects in Practice.- Simple and Fast: Improving a Branch-And-Bound
      Algorithm for Maximum Clique.- Online Companion Caching.- Deterministic Communication
      in Radio Networks with Large Labels.- A Primal Approach to the Stable Set Problem.-
      Wide-Sense Nonblocking WDM Cross-Connects.- Efficient Implementation of a Minimal
      Triangulation Algorithm.- Scheduling Malleable Parallel Tasks: An Asymptotic
      Fully Polynomial-Time Approximation Scheme.- The Probabilistic Analysis of a
      Greedy Satisfiability Algorithm.- Dynamic Additively Weighted Voronoi Diagrams
      in 2D.- Time-Expanded Graphs for Flow-Dependent Transit Times.- Partially-Ordered
      Knapsack and Applications to Scheduling.- A Software Library for Elliptic Curve
      Cryptography.- Real-Time Dispatching of Guided and Unguided Automobile Service
      Units with Soft Time Windows.- Randomized Approximation Algorithms for Query
      Optimization Problems on Two Processors.- Covering Things with Things.- On-Line
      Dial-a-Ride Problems under a Restricted Information Model.- Approximation Algorithm
      for the Maximum Leaf Spanning Tree Problem for Cubic Graphs.- Engineering a
      Lightweight Suffix Array Construction Algorithm.- Complexity of Compatible Decompositions
      of Eulerian Graphs and Their Transformations.- External-Memory Breadth-First
      Search with Sublinear I/O.- Frequency Channel Assignment on Planar Networks.-
      Design and Implementation of Efficient Data Types for Static Graphs.- An Exact
      Algorithm for the Uniformly-Oriented Steiner Tree Problem.- A Fast, Accurate
      and Simple Method for Pricing European-Asian and Saving-Asian Options.- Sorting
      13 Elements Requires 34 Comparisons.- Extending Reduction Techniques for the
      Steiner Tree Problem.- A Comparison of Multicast Pull Models.- Online Scheduling
      for Sorting Buffers.- Finding the Sink Takes Some Time.- Lagrangian Cardinality
      Cuts and Variable Fixing for Capacitated Network Design.- Minimizing Makespan
      and Preemption Costs on a System of Uniform Machines.- Minimizing the Total
      Completion Time On-line on a Single Machine, Using Restarts.- High-Level Filtering
      for Arrangements of Conic Arcs.- An Approximation Scheme for Cake Division with
      a Linear Number of Cuts.- A Simple Linear Time Algorithm for Finding Even Triangulations
      of 2-Connected Bipartite Plane Graphs.", "venue": "", "year": 2002, "referenceCount":
      0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": null, "publicationDate": null, "journal": {"name": "", "volume":
      ""}, "citationStyles": {"bibtex": "@Inproceedings{M\u00f6hring2002AlgorithmsE,\n
      author = {R. M\u00f6hring and R. Raman},\n title = {Algorithms - ESA 2002 :
      10th Annual European Symposium, Rome, Italy, September 17-21, 2002 : proceedings},\n
      year = {2002}\n}\n"}, "authors": [{"authorId": "1803133", "name": "R. M\u00f6hring"},
      {"authorId": "1685583", "name": "R. Raman"}]}, {"paperId": "ca88d273b823eb2795d479e912a3c1b77ed52200",
      "externalIds": {"MAG": "1573399792", "CorpusId": 61966926}, "corpusId": 61966926,
      "publicationVenue": {"id": "01259446-be8e-4510-a20c-cf0cb92f2a75", "name": "International
      Symposium on Algorithms and Computation", "type": "conference", "alternate_names":
      ["Int Symp Algorithm Comput", "ISAAC"], "url": "http://www.wikicfp.com/cfp/program?id=1668"},
      "url": "https://www.semanticscholar.org/paper/ca88d273b823eb2795d479e912a3c1b77ed52200",
      "title": "Algorithms and computation : 20th International Symposium, ISAAC 2009,
      Honolulu, Hawaii, USA, December 16-18, 2009 : proceedings", "abstract": "Bubblesort
      and Juggling Sequences.- A Proof of the Molecular Conjecture.- Exact Algorithms
      for Dominating Clique Problems.- Enumerating Stereoisomers of Tree Structured
      Molecules Using Dynamic Programming.- Exact Algorithms for the Bottleneck Steiner
      Tree Problem.- Exact Algorithms for Set Multicover and Multiset Multicover Problems.-
      Practical Discrete Unit Disk Cover Using an Exact Line-Separable Algorithm.-
      Divide-and-Conquer Algorithms for Partitioning Hypergraphs and Submodular Systems.-
      On Protein Structure Alignment under Distance Constraint.- A Structural Lemma
      in 2-Dimensional Packing, and Its Implications on Approximability.- Max-Coloring
      Paths: Tight Bounds and Extensions.- Frechet Distance Problems in Weighted Regions.-
      The Complexity of Solving Stochastic Games on Graphs.- Computational Complexity
      of Cast Puzzles.- New Bounds on the Average Distance from the Fermat-Weber Center
      of a Planar Convex Body.- Reconstructing Numbers from Pairwise Function Values.-
      Hilbert''s Thirteenth Problem and Circuit Complexity.- Interval Stabbing Problems
      in Small Integer Ranges.- Online Sorted Range Reporting.- Data Structures for
      Approximate Orthogonal Range Counting.- Dynamic 3-Sided Planar Range Queries
      with Expected Doubly Logarithmic Time.- Untangled Monotonic Chains and Adaptive
      Range Search.- Geodesic Spanners on Polyhedral Surfaces.- Approximating Points
      by a Piecewise Linear Function: I.- Approximating Points by a Piecewise Linear
      Function: II. Dealing with Outliers.- Computing the Map of Geometric Minimal
      Cuts.- On the Camera Placement Problem.- Graph Orientations with Set Connectivity
      Requirements.- A Linear Vertex Kernel for Maximum Internal Spanning Tree.- Geometric
      Minimum Diameter Minimum Cost Spanning Tree Problem.- On Shortest Disjoint Paths
      in Planar Graphs.- An Optimal Labeling for Node Connectivity.- SOFA: Strategyproof
      Online Frequency Allocation for Multihop Wireless Networks.- 1-Bounded Space
      Algorithms for 2-Dimensional Bin Packing.- On the Advice Complexity of Online
      Problems.- Online Knapsack Problems with Limited Cuts.- Online Paging for Flash
      Memory Devices.- Shifting Strategy for Geometric Graphs without Geometry.- Approximation
      Algorithms for Variable Voltage Processors: Min Energy, Max Throughput and Online
      Heuristics.- Approximation Algorithms for Min-Max Path Cover Problems with Service
      Handling Time.- Minimum Covering with Travel Cost.- Route-Enabling Graph Orientation
      Problems.- Complexity of Approximating the Vertex Centroid of a Polyhedron.-
      Popular Matchings with Variable Job Capacities.- On the Tightness of the Buhrman-Cleve-Wigderson
      Simulation.- Bounds on Contention Management Algorithms.- Algorithmic Folding
      Complexity.- Min-Energy Scheduling for Aligned Jobs in Accelerate Model.- Posi-modular
      Systems with Modulotone Requirements under Permutation Constraints.- Generalized
      Reduction to Compute Toric Ideals.- Linear and Sublinear Time Algorithms for
      Basis of Abelian Groups.- Good Programming in Transactional Memory.- Induced
      Packing of Odd Cycles in a Planar Graph.- On the Infinitesimal Rigidity of Bar-and-Slider
      Frameworks.- Exploration of Periodically Varying Graphs.- Parameterized Complexity
      of Arc-Weighted Directed Steiner Problems.- Worst Case Analysis for Pickup and
      Delivery Problems with Consecutive Pickups and Deliveries.- Minimum Cycle Bases
      of Weighted Outerplanar Graphs.- Bandwidth on AT-Free Graphs.- Editing Graphs
      into Disjoint Unions of Dense Clusters.- A Certifying Algorithm for 3-Colorability
      of P 5-Free Graphs.- Parameterizing Cut Sets in a Graph by the Number of Their
      Components.- Inapproximability of Maximal Strip Recovery.- The Complexity of
      Perfect Matching Problems on Dense Hypergraphs.- On Lower Bounds for Constant
      Width Arithmetic Circuits.- Spending Is Not Easier Than Trading: On the Computational
      Equivalence of Fisher and Arrow-Debreu Equilibria.- The Identity Correspondence
      Problem and Its Applications.- Fast Distributed Approximation Algorithm for
      the Maximum Matching Problem in Bounded Arboricity Graphs.- An Improved Approximation
      Algorithm for the Traveling Tournament Problem.- The Fault-Tolerant Facility
      Allocation Problem.- Tighter Approximation Bounds for Minimum CDS in Wireless
      Ad Hoc Networks.- Maximal Strip Recovery Problem with Gaps: Hardness and Approximation
      Algorithms.- The Directed Hausdorff Distance between Imprecise Point Sets.-
      Computing Multidimensional Persistence.- Locating an Obnoxious Line among Planar
      Objects.- Finding Fullerene Patches in Polynomial Time.- Convex Drawings of
      Internally Triconnected Plane Graphs on O(n 2) Grids.- A Self-stabilizing and
      Local Delaunay Graph Construction.- Succinct Greedy Geometric Routing in the
      Euclidean Plane.- Electric Routing and Concurrent Flow Cutting.- A Polynomial-Time
      Algorithm for the Universally Quickest Transshipment Problem in a Certain Class
      of Dynamic Networks with Uniform Path-Lengths.- Strong Robustness of Randomized
      Rumor Spreading Protocols.- Data Structures for Range Median Queries.- Deletion
      without Rebalancing in Multiway Search Trees.- Counting in the Presence of Memory
      Faults.- A Simple, Fast, and Compact Static Dictionary.- Reconstructing Polygons
      from Scanner Data.- Computing Large Matchings in Planar Graphs with Fixed Minimum
      Degree.- Crossing-Free Acyclic Hamiltonian Path Completion for Planar st-Digraphs.-
      Covering a Graph with a Constrained Forest (Extended Abstract).- Tri-Edge-Connectivity
      Augmentation for Planar Straight Line Graphs.- Upward Star-Shaped Polyhedral
      Graphs.- Conditional Hardness of Approximating Satisfiable Max 3CSP-q.- The
      Roles of Advice to One-Tape Linear-Time Turing Machines and Finite Automata
      (Extended Abstract).- Of Choices, Failures and Asynchrony: The Many Faces of
      Set Agreement.- Step-Assembly with a Constant Number of Tile Types.- Lower Bounds
      on Fast Searching.- Approximation Algorithms for the Firefighter Problem: Cuts
      over Time and Submodularity.- Constant-Factor Approximations of Branch-Decomposition
      and Largest Grid Minor of Planar Graphs in O(n 1?+?? ) Time.- PTAS for k-Tour
      Cover Problem on the Plane for Moderately Large Values of k.- Optimal Randomized
      Algorithm for the Density Selection Problem.- New Results on Simple Stochastic
      Games.- Worst-Case and Smoothed Analysis of k-Means Clustering with Bregman
      Divergences.- Succinct Index for Dynamic Dictionary Matching.- Range Non-overlapping
      Indexing.- Querying Two Boundary Points for Shortest Paths in a Polygonal Domain.-
      Pattern Matching for 321-Avoiding Permutations.- Folding a Better Checkerboard.-
      Finding All Approximate Gapped Palindromes.- General Pseudo-random Generators
      from Weaker Models of Computation.- Random Generation and Enumeration of Bipartite
      Permutation Graphs.- A Combinatorial Algorithm for Horn Programs.- Online Maximum
      Directed Cut.- Maintaining Nets and Net Trees under Incremental Motion.- Distributed
      Scheduling of Parallel Hybrid Computations.- I/O-Efficient Contour Tree Simplification.-
      Algorithms for Computing the Maximum Weight Region Decomposable into Elementary
      Shapes.- I/O and Space-Efficient Path Traversal in Planar Graphs.- Improved
      Algorithms for Finding Consistent Superstrings Based on a New Graph Model.-
      Two-Vertex Connectivity Augmentations for Graphs with a Partition Constraint
      (Extended Abstract).- Computing a Smallest Multi-labeled Phylogenetic Tree from
      Rooted Triplets.- On Partitioning a Graph into Two Connected Subgraphs.", "venue":
      "International Symposium on Algorithms and Computation", "year": 2009, "referenceCount":
      0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Mathematics"], "s2FieldsOfStudy":
      [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": null, "publicationDate": null, "journal": null, "citationStyles":
      {"bibtex": "@Inproceedings{Dong2009AlgorithmsAC,\n author = {Yingfei Dong and
      D. Du and O. Ibarra},\n booktitle = {International Symposium on Algorithms and
      Computation},\n title = {Algorithms and computation : 20th International Symposium,
      ISAAC 2009, Honolulu, Hawaii, USA, December 16-18, 2009 : proceedings},\n year
      = {2009}\n}\n"}, "authors": [{"authorId": "2115905227", "name": "Yingfei Dong"},
      {"authorId": "145902418", "name": "D. Du"}, {"authorId": "1712312", "name":
      "O. Ibarra"}]}, {"paperId": "3b15ffc6a72379e4db16018d0a412f142b47d70a", "externalIds":
      {"MAG": "1550721562", "CorpusId": 28611035}, "corpusId": 28611035, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/3b15ffc6a72379e4db16018d0a412f142b47d70a",
      "title": "Algorithms and Complexity: 6th Italian Conference, CIAC 2006, Rome,
      Italy, May 29-31, 2006, Proceedings", "abstract": "Invited Talks.- Reliable
      and Efficient Geometric Computing.- Beware of the Model: Reflections on Algorithmic
      Research.- On Search Problems in Complexity Theory and in Logic (Abstract).-
      Session 1.- Covering a Set of Points with a Minimum Number of Lines.- Approximation
      Algorithms for Capacitated Rectangle Stabbing.- In-Place Randomized Slope Selection.-
      Session 2.- Quadratic Programming and Combinatorial Minimum Weight Product Problems.-
      Counting All Solutions of Minimum Weight Exact Satisfiability.- Clause Shortening
      Combined with Pruning Yields a New Upper Bound for Deterministic SAT Algorithms.-
      Session 3.- Network Discovery and Verification with Distance Queries.- Deciding
      the FIFO Stability of Networks in Polynomial Time.- Heterogenous Networks Can
      Be Unstable at Arbitrarily Low Injection Rates.- Session 4.- Provisioning a
      Virtual Private Network Under the Presence of Non-communicating Groups.- Gathering
      Algorithms on Paths Under Interference Constraints.- On the Hardness of Range
      Assignment Problems.- Session 5.- Black Hole Search in Asynchronous Rings Using
      Tokens.- On Broadcast Scheduling with Limited Energy.- A Near Optimal Scheduler
      for On-Demand Data Broadcasts.- Session 6.- Fair Cost-Sharing Methods for Scheduling
      Jobs on Parallel Machines.- Tighter Approximation Bounds for LPT Scheduling
      in Two Special Cases.- Inapproximability Results for Orthogonal Rectangle Packing
      Problems with Rotations.- Session 7.- Approximate Hierarchical Facility Location
      and Applications to the Shallow Steiner Tree and Range Assignment Problems.-
      An Approximation Algorithm for a Bottleneck Traveling Salesman Problem.- On
      the Minimum Common Integer Partition Problem.- Session 8.- Matching Subsequences
      in Trees.- Distance Approximating Trees: Complexity and Algorithms.- How to
      Pack Directed Acyclic Graphs into Small Blocks.- Session 9.- On-Line Coloring
      of H-Free Bipartite Graphs.- Distributed Approximation Algorithms for Planar
      Graphs.- A New NC-Algorithm for Finding a Perfect Matching in d-Regular Bipartite
      Graphs When d Is Small.- Session 10.- Fixed-Parameter Tractability Results for
      Feedback Set Problems in Tournaments.- Parameterized Algorithms for Hitting
      Set: The Weighted Case.- Fixed-Parameter Tractable Generalizations of Cluster
      Editing.- Session 11.- The Linear Arrangement Problem Parameterized Above Guaranteed
      Value.- Universal Relations and #P-Completeness.- Locally 2-Dimensional Sperner
      Problems Complete for the Polynomial Parity Argument Classes.", "venue": "",
      "year": 2006, "referenceCount": 0, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics"],
      "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source":
      "s2-fos-model"}], "publicationTypes": null, "publicationDate": "2006-07-06",
      "journal": {"name": "", "volume": ""}, "citationStyles": {"bibtex": "@Inproceedings{Italiano2006AlgorithmsAC,\n
      author = {G. Italiano and T. Calamoneri and Irene Finocchi},\n title = {Algorithms
      and Complexity: 6th Italian Conference, CIAC 2006, Rome, Italy, May 29-31, 2006,
      Proceedings},\n year = {2006}\n}\n"}, "authors": [{"authorId": "1688493", "name":
      "G. Italiano"}, {"authorId": "1698687", "name": "T. Calamoneri"}, {"authorId":
      "1680706", "name": "Irene Finocchi"}]}, {"paperId": "f7678214cb29fe20b9505af4a6ea8bfd60d432c6",
      "externalIds": {"DBLP": "journals/tkde/LoukidesPS23", "DOI": "10.1109/TKDE.2022.3231780",
      "CorpusId": 255974699}, "corpusId": 255974699, "publicationVenue": {"id": "c6840156-ee10-4d78-8832-7f8909811576",
      "name": "IEEE Transactions on Knowledge and Data Engineering", "type": "journal",
      "alternate_names": ["IEEE Trans Knowl Data Eng"], "issn": "1041-4347", "url":
      "https://www.computer.org/web/tkde", "alternate_urls": ["http://ieeexplore.ieee.org/servlet/opac?punumber=69"]},
      "url": "https://www.semanticscholar.org/paper/f7678214cb29fe20b9505af4a6ea8bfd60d432c6",
      "title": "Bidirectional String Anchors for Improved Text Indexing and Top-$K$
      Similarity Search", "abstract": "The minimizers sampling mechanism is a popular
      mechanism for string sampling. However, minimizers sampling mechanisms lack
      good guarantees on the expected size of their samples for different combinations
      of their input parameters. Furthermore, indexes constructed over minimizers
      samples lack good worst-case guarantees for on-line pattern searches. In response,
      we propose bidirectional string anchors (bd-anchors), a new string sampling
      mechanism. Given an integer <inline-formula><tex-math notation=\"LaTeX\">$\\ell$</tex-math><alternatives><mml:math><mml:mi>\u2113</mml:mi></mml:math><inline-graphic
      xlink:href=\"loukides-ieq2-3231780.gif\"/></alternatives></inline-formula>,
      our mechanism selects the lexicographically smallest rotation in every length-<inline-formula><tex-math
      notation=\"LaTeX\">$\\ell$</tex-math><alternatives><mml:math><mml:mi>\u2113</mml:mi></mml:math><inline-graphic
      xlink:href=\"loukides-ieq3-3231780.gif\"/></alternatives></inline-formula> fragment.
      We show that, like minimizers samples, bd-anchors samples are approximately
      uniform, locally consistent, and computable in linear time. Furthermore, our
      experiments demonstrate that the bd-anchors sample sizes decrease proportionally
      to <inline-formula><tex-math notation=\"LaTeX\">$\\ell$</tex-math><alternatives><mml:math><mml:mi>\u2113</mml:mi></mml:math><inline-graphic
      xlink:href=\"loukides-ieq4-3231780.gif\"/></alternatives></inline-formula>;
      and that these sizes are <italic>competitive to or smaller than</italic> the
      minimizers sample sizes. We theoretically justify these results by analyzing
      the expected size of bd-anchors samples. We also prove that computing a total
      order on the input alphabet which minimizes the bd-anchors sample size is NP-hard.
      We next highlight the benefits of bd-anchors in two important applications:
      text indexing and top-<inline-formula><tex-math notation=\"LaTeX\">$K$</tex-math><alternatives><mml:math><mml:mi>K</mml:mi></mml:math><inline-graphic
      xlink:href=\"loukides-ieq5-3231780.gif\"/></alternatives></inline-formula> similarity
      search. For the first application, we develop an index for performing on-line
      pattern searches in near-optimal time, and show experimentally that a simple
      implementation of our index is <italic>consistently faster</italic> for on-line
      pattern searches than an analogous implementation of a minimizers-based index;
      we also show that it is <italic>substantially</italic> faster than two classic
      text indexes. For the second application, we develop a heuristic for top-<inline-formula><tex-math
      notation=\"LaTeX\">$K$</tex-math><alternatives><mml:math><mml:mi>K</mml:mi></mml:math><inline-graphic
      xlink:href=\"loukides-ieq6-3231780.gif\"/></alternatives></inline-formula> similarity
      search under edit distance, and show experimentally that it is generally as
      <italic>accurate</italic> as the state-of-the-art tool for the same purpose
      but <italic>more than one order of magnitude faster</italic>.", "venue": "IEEE
      Transactions on Knowledge and Data Engineering", "year": 2023, "referenceCount":
      100, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": true,
      "openAccessPdf": {"url": "https://ir.cwi.nl/pub/32902/32902.pdf", "status":
      "GREEN"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-11-01", "journal": {"name": "IEEE Transactions on Knowledge and Data Engineering",
      "pages": "11093-11111", "volume": "35"}, "citationStyles": {"bibtex": "@Article{Loukides2023BidirectionalSA,\n
      author = {G. Loukides and S. Pissis and Michelle Sweering},\n booktitle = {IEEE
      Transactions on Knowledge and Data Engineering},\n journal = {IEEE Transactions
      on Knowledge and Data Engineering},\n pages = {11093-11111},\n title = {Bidirectional
      String Anchors for Improved Text Indexing and Top-$K$ Similarity Search},\n
      volume = {35},\n year = {2023}\n}\n"}, "authors": [{"authorId": "1726972", "name":
      "G. Loukides"}, {"authorId": "1722688", "name": "S. Pissis"}, {"authorId": "89309270",
      "name": "Michelle Sweering"}]}, {"paperId": "5e389e0ed5f9db8d12b0c1e82ff3940012c7a20d",
      "externalIds": {"DBLP": "conf/icalp/ChanWX21", "ArXiv": "2102.06181", "DOI":
      "10.4230/LIPIcs.ICALP.2021.47", "CorpusId": 231879759}, "corpusId": 231879759,
      "publicationVenue": {"id": "d024be26-06b0-4afe-8fa3-a297e04fe604", "name": "International
      Colloquium on Automata, Languages and Programming", "type": "conference", "alternate_names":
      ["Int Conf Arab Lang Process", "International Conference on Arabic Language
      Processing", "Int Colloq Autom Lang Program", "ICALP"], "url": "http://www.eatcs.org/"},
      "url": "https://www.semanticscholar.org/paper/5e389e0ed5f9db8d12b0c1e82ff3940012c7a20d",
      "title": "Algorithms, Reductions and Equivalences for Small Weight Variants
      of All-Pairs Shortest Paths", "abstract": "All-Pairs Shortest Paths (APSP) is
      one of the most well studied problems in graph algorithms. This paper studies
      several variants of APSP in unweighted graphs or graphs with small integer weights.
      APSP with small integer weights in undirected graphs [Seidel\u201995, Galil
      and Margalit\u201997] has an \u00d5(n) time algorithm, where \u03c9 < 2.373
      is the matrix multiplication exponent. APSP in directed graphs with small weights
      however, has a much slower running time that would be \u03a9(n) even if \u03c9
      = 2 [Zwick\u201902]. To understand this n bottleneck, we build a web of reductions
      around directed unweighted APSP. We show that it is fine-grained equivalent
      to computing a rectangular Min-Plus product for matrices with integer entries;
      the dimensions and entry size of the matrices depend on the value of \u03c9.
      As a consequence, we establish an equivalence between APSP in directed unweighted
      graphs, APSP in directed graphs with small (\u00d5(1)) integer weights, All-Pairs
      Longest Paths in DAGs with small weights, cRed-APSP in undirected graphs with
      small weights, for any c \u2265 2 (computing all-pairs shortest path distances
      among paths that use at most c red edges), #\u2264cAPSP in directed graphs with
      small weights (counting the number of shortest paths for each vertex pair, up
      to c), and approximate APSP with additive error c in directed graphs with small
      weights, for c \u2264 \u00d5(1). We also provide fine-grained reductions from
      directed unweighted APSP to All-Pairs Shortest Lightest Paths (APSLP) in undirected
      graphs with {0, 1} weights and #mod cAPSP in directed unweighted graphs (computing
      counts mod c), thus showing that unless the current algorithms for APSP in directed
      unweighted graphs can be improved substantially, these problems need at least
      \u03a9(n) time. We complement our hardness results with new algorithms. We improve
      the known algorithms for APSLP in directed graphs with small integer weights
      (previously studied by Zwick [STOC\u201999]) and for approximate APSP with sublinear
      additive error in directed unweighted graphs (previously studied by Roditty
      and Shapira [ICALP\u201908]). Our algorithm for approximate APSP with sublinear
      additive error is optimal, when viewed as a reduction to Min-Plus product. We
      also give new algorithms for variants of #APSP (such as #\u2264UAPSP and #mod
      UAPSP for U \u2264 n\u00d5) in unweighted graphs, as well as a near-optimal
      \u00d5(n)-time algorithm for the original #APSP problem in unweighted graphs
      (when counts may be exponentially large). This also implies an \u00d5(n)-time
      algorithm for Betweenness Centrality, improving on the previous \u00d5(n) running
      time for the problem. Our techniques also lead to a simpler alternative to Shoshan
      and Zwick\u2019s algorithm [FOCS\u201999] for the original APSP problem in undirected
      graphs with small integer weights.", "venue": "International Colloquium on Automata,
      Languages and Programming", "year": 2021, "referenceCount": 36, "citationCount":
      9, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Mathematics", "source": "s2-fos-model"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle", "Conference"], "publicationDate": "2021-02-11", "journal":
      {"name": "ArXiv", "volume": "abs/2102.06181"}, "citationStyles": {"bibtex":
      "@Article{Chan2021AlgorithmsRA,\n author = {Timothy M. Chan and V. V. Williams
      and Yinzhan Xu},\n booktitle = {International Colloquium on Automata, Languages
      and Programming},\n journal = {ArXiv},\n title = {Algorithms, Reductions and
      Equivalences for Small Weight Variants of All-Pairs Shortest Paths},\n volume
      = {abs/2102.06181},\n year = {2021}\n}\n"}, "authors": [{"authorId": "31555479",
      "name": "Timothy M. Chan"}, {"authorId": "2275118", "name": "V. V. Williams"},
      {"authorId": "10032840", "name": "Yinzhan Xu"}]}, {"paperId": "02c09135d877fadc5429c8c94a1ea55dc79b6a48",
      "externalIds": {"DBLP": "conf/esa/LoukidesP21", "DOI": "10.4230/LIPIcs.ESA.2021.64",
      "CorpusId": 237366297}, "corpusId": 237366297, "publicationVenue": {"id": "da625a67-4bac-4737-81b6-af5459021b72",
      "name": "Embedded Systems and Applications", "type": "conference", "alternate_names":
      ["ESA", "European Symposium on Algorithms", "Embed Syst Appl", "Eur Symp Algorithm"],
      "url": "http://esa-symposium.org/"}, "url": "https://www.semanticscholar.org/paper/02c09135d877fadc5429c8c94a1ea55dc79b6a48",
      "title": "Bidirectional String Anchors: A New String Sampling Mechanism", "abstract":
      "The minimizers sampling mechanism is a popular mechanism for string sampling
      introduced independently by Schleimer et al. [SIGMOD 2003] and by Roberts et
      al. [ Bioinf. 2004]. Given two positive integers w and k , it selects the lexicographically
      smallest length-k substring in every fragment of w consecutive length-k substrings
      (in every sliding window of length w + k \u2212 1). Minimizers samples are approximately
      uniform, locally consistent, and computable in linear time. Although they do
      not have good worst-case guarantees on their size, they are often small in practice.
      They thus have been successfully employed in several string processing applications.
      Two main disadvantages of minimizers sampling mechanisms are: first, they also
      do not have good guarantees on the expected size of their samples for every
      combination of w and k ; and, second, indexes that are constructed over their
      samples do not have good worst-case guarantees for on-line pattern searches.
      To alleviate these disadvantages, we introduce bidirectional string anchors
      (bd-anchors), a new string sampling mechanism. Given a positive integer \u2113
      , our mechanism selects the lexicographically smallest rotation in every length-\u2113
      fragment (in every sliding window of length \u2113 ). We show that bd-anchors
      samples are also approximately uniform, locally consistent, and computable in
      linear time. In addition, our experiments using several datasets demonstrate
      that the bd-anchors sample sizes decrease proportionally to \u2113 ; and that
      these sizes are competitive to or smaller than the minimizers sample sizes using
      the analogous sampling parameters. We provide theoretical justification for
      these results by analyzing the expected size of bd-anchors samples. We also
      show that by using any bd-anchors sample, we can construct, in near-linear time,
      an index which requires linear (extra) space in the size of the sample and answers
      on-line pattern searches in near-optimal time. We further show, using several
      datasets, that a simple implementation of our index is consistently faster for
      on-line pattern searches than an analogous implementation of a minimizers-based
      index [Grabowski and Raniszewski, Softw. Pract. Exp. 2017]. Finally, we highlight
      the applicability of bd-anchors by developing an efficient and effective heuristic
      for top-K similarity search under edit distance. We show, using synthetic datasets,
      that our heuristic is more accurate and more than one order of magnitude faster
      in top-K similarity searches than the state-of-the-art tool for the same purpose
      [Zhang and Zhang, KDD 2020].", "venue": "Embedded Systems and Applications",
      "year": 2021, "referenceCount": 70, "citationCount": 7, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://hal.inria.fr/hal-03395425/document",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
      "Conference"], "publicationDate": null, "journal": {"pages": "64:1-64:21"},
      "citationStyles": {"bibtex": "@Article{Loukides2021BidirectionalSA,\n author
      = {G. Loukides and S. Pissis},\n booktitle = {Embedded Systems and Applications},\n
      pages = {64:1-64:21},\n title = {Bidirectional String Anchors: A New String
      Sampling Mechanism},\n year = {2021}\n}\n"}, "authors": [{"authorId": "1726972",
      "name": "G. Loukides"}, {"authorId": "1722688", "name": "S. Pissis"}]}, {"paperId":
      "5aeb1558abead222d1e36bd17db0507a323db017", "externalIds": {"MAG": "2225766585",
      "CorpusId": 19396426}, "corpusId": 19396426, "publicationVenue": null, "url":
      "https://www.semanticscholar.org/paper/5aeb1558abead222d1e36bd17db0507a323db017",
      "title": "Nearest neighbor search : the old, the new, and the impossible", "abstract":
      "Over the last decade, an immense amount of data has become available. From
      collections of photos, to genetic data, and to network tra c statistics, modern
      technologies and cheap storage have made it possible to accumulate huge datasets.
      But how can we e ectively use all this data? The ever growing sizes of the datasets
      make it imperative to design new algorithms capable of sifting through this
      data with extreme e ciency. A fundamental computational primitive for dealing
      with massive dataset is the Nearest Neighbor (NN) problem. In the NN problem,
      the goal is to preprocess a set of objects, so that later, given a query object,
      one can nd e ciently the data object most similar to the query. This problem
      has a broad set of applications in data processing and analysis. For instance,
      it forms the basis of a widely used classi cation method in machine learning:
      to give a label for a new object, nd the most similar labeled object and copy
      its label. Other applications include information retrieval, searching image
      databases, nding duplicate les and web pages, vector quantization, and many
      others. To represent the objects and the similarity measures, one often uses
      geometric notions. For example, a black-and-white image may be modeled by a
      high-dimensional vector, with one coordinate per pixel, whereas the similarity
      measure may be the standard Euclidean distance between the resulting vectors.
      Many other, more elaborate ways of representing objects by high-dimensional
      feature vectors have been studied. In this thesis, we study the NN problem,
      as well as other related problems that occur frequently when dealing with the
      massive datasets. Our contribution is two-fold: we signi cantly improve the
      algorithms within the classical approaches to NN, as well as propose new approaches
      where the classical ones fail. We focus on several key distances and similarity
      measures, including the Euclidean distance, string edit distance and the Earth-Mover
      Distance (a popular method for comparing images). We also give a number of impossibility
      results, pointing out the limits of the NN algorithms. The high-level structure
      of our thesis is summarized as follows. New algorithms via the classical approaches.
      We give a new algorithm for the approximate NN problem in the d-dimensional
      Euclidean space. For an approximation factor c > 1, our algorithm achieves dn\u03c1
      query time and dn1+\u03c1 space for \u03c1 = 1/c2+o(1). This greatly improves
      on the previous algorithms that achieved \u03c1 that was only slightly smaller
      than 1/c. The same technique also yields an algorithm with dnO(\u03c1) query
      time and space near-linear in n. Furthermore, our algorithm is near-optimal
      in the class of hashing algorithms. Failure of the classical approaches for
      some hard distances. We give an evidence that the classical approaches to NN
      under certain hard distances, such as the string edit", "venue": "", "year":
      2009, "referenceCount": 166, "citationCount": 114, "influentialCitationCount":
      12, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      null, "publicationDate": null, "journal": {"name": "", "volume": ""}, "citationStyles":
      {"bibtex": "@Inproceedings{Andoni2009NearestNS,\n author = {Alexandr Andoni},\n
      title = {Nearest neighbor search : the old, the new, and the impossible},\n
      year = {2009}\n}\n"}, "authors": [{"authorId": "1738395", "name": "Alexandr
      Andoni"}]}, {"paperId": "3ebce51559a6312e0171488f8550d2557c676bb2", "externalIds":
      {"MAG": "2059879909", "DBLP": "journals/bmcbi/VaronW12", "PubMedCentral": "3605350",
      "DOI": "10.1186/1471-2105-13-293", "CorpusId": 5377611, "PubMed": "23140486"},
      "corpusId": 5377611, "publicationVenue": {"id": "be3f884c-b44a-496a-a593-1cad3f89d254",
      "name": "BMC Bioinformatics", "type": "journal", "alternate_names": ["BMC Bioinform"],
      "issn": "1471-2105", "url": "http://www.biomedcentral.com/bmcbioinformatics",
      "alternate_urls": ["http://www.pubmedcentral.nih.gov/tocrender.fcgi?journal=13",
      "http://www.biomedcentral.com/bmcbioinformatics/"]}, "url": "https://www.semanticscholar.org/paper/3ebce51559a6312e0171488f8550d2557c676bb2",
      "title": "The tree alignment problem", "abstract": null, "venue": "BMC Bioinformatics",
      "year": 2012, "referenceCount": 50, "citationCount": 31, "influentialCitationCount":
      3, "isOpenAccess": true, "openAccessPdf": {"url": "https://bmcbioinformatics.biomedcentral.com/counter/pdf/10.1186/1471-2105-13-293",
      "status": "GOLD"}, "fieldsOfStudy": ["Biology", "Medicine", "Computer Science"],
      "s2FieldsOfStudy": [{"category": "Biology", "source": "external"}, {"category":
      "Medicine", "source": "external"}, {"category": "Computer Science", "source":
      "external"}, {"category": "Biology", "source": "s2-fos-model"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2012-11-09", "journal": {"name": "BMC Bioinformatics", "pages":
      "293 - 293", "volume": "13"}, "citationStyles": {"bibtex": "@Article{Var\u00f3n2012TheTA,\n
      author = {Andr\u00e9s Var\u00f3n and W. Wheeler},\n booktitle = {BMC Bioinformatics},\n
      journal = {BMC Bioinformatics},\n pages = {293 - 293},\n title = {The tree alignment
      problem},\n volume = {13},\n year = {2012}\n}\n"}, "authors": [{"authorId":
      "145267293", "name": "Andr\u00e9s Var\u00f3n"}, {"authorId": "40384475", "name":
      "W. Wheeler"}]}, {"paperId": "6cac5ead3eb4c9fc69f8b97fca50494e3fe501d6", "externalIds":
      {"CorpusId": 265887929}, "corpusId": 265887929, "publicationVenue": null, "url":
      "https://www.semanticscholar.org/paper/6cac5ead3eb4c9fc69f8b97fca50494e3fe501d6",
      "title": "Journal of Double Star Observations V5, No4", "abstract": "This paper
      reports Speckle Interferometry measurements of double stars made during 2017,
      using the Kuhn 22-inch telescope of the Orange County Astronomers, a ZWO ASI
      290MM CMOS camera, and four interference filters. Observations are reported
      for 71 systems. Targeted separations ranged from 0.3\" to 3.0\", but wider components
      of several multiple systems were also measured. Astrometric data reduction utilized
      the REDUC and Speckle Tool Box programs, and bispectrum analysis was also done
      for all stars. Equipment, data acquisition, astrometric and photometric data
      reduction and analyses are described. Results for several stars are discussed
      in detail. Figure 1. Above: The OCA Kuhn 22\" Telescope in its roll-off roof
      observatory. Left: Close-up of speckle instrumentation. Below, left to right:
      Flip mirror with illuminated reticle eyepiece, ZWO manual filter wheel, 2x Barlow
      (silver), and ZWO camera (red). The laptop computer is on a wheeled table below,
      connected by the USB3.0 cable carrying 5V power to the camera and images to
      the laptop. Vol. 15 No. 2 April 1, 2019 Page 274 Journal of Double Star Observations
      Speckle Interferometry with the OCA Kuhn 22\" Telescope II and a rolling shutter.
      This un-cooled camera was chosen because the back-illuminated design, new technology
      for CMOS cameras, gives improved sensitivity in the near-IR spectral region;
      because the read noise is very low (~1erms depending on gain); and because this
      high-tech unit is available for only about $400US. It has a high-speed USB3.0
      interface (more than 30 fps full frame), providing 12-bit images. The Quantum
      Efficiency (QE) is believed to be about 70% peak at 600 nm, and still 24% at
      900nm. Because of the small pixels, less magnification is required to reach
      the optimum speckle image scale \u2013 about 7 to 8 pixels across the Airy disk
      diameter (Rowe, 2016) \u2013 a good compromise between more pixel sampling and
      less light available per pixel. Therefore, a simple 2x Barlow is used on the
      Kuhn 22\", providing f/16, a plate scale of about 0.066 arc-sec/ pixel, and
      about 8.8 pixels across the Airy disk at 650nm wavelength. The speckle field
      is small about 2.2''x1.2'' but is adequate for close double stars, and large
      enough for easy centering with an illuminated reticle eyepiece. Filters A ZWO
      manual filter wheel was used, housing the three 11\u20444-inch filters already
      in hand; a longer wavelength IR-pass filter (IR807) was added to make use of
      the better near-IR QE of the back-illuminated sensor, for observations of very
      red stars (Serot et al, 2018). Table 1 gives the characteristics of the four
      interference filters used for the observations reported here. These filters
      are not members of any photometric standard series, but they are economical,
      durable, and cover the detectable wavelength range of the camera well. For the
      two long-pass filters in Table 1, asterisks indicate convolved characteristics:
      i.e., filter transmission times QE of the CMOS detector. The \u201c50% Band
      Pass\u201d column for these two filters is 50% cut-on transmission on the short
      side, but it is assumed to be 1 micron on the long side because detection is
      determined by the Silicon detector sensitivity limit (~1\u03bc) rather than
      filter transmission. Target Selection and Observation Double star targets were
      chosen by searching the Washington Double Star (WDS) Catalog, primarily using
      the search tool WDS1.2 (Rowe, 2017). Input parameters include ranges for RA
      and Dec, primary star magnitude, magnitude difference and separation. This program
      also gives a list of possible reference stars within 3 degrees of the target;
      the list may be sorted by distance or magnitude. These are very important, timesaving
      features for the user, making it easy to select a suitable reference star, which
      should be as close to the target star as possible in terms of location, magnitude
      and color (spectral type). A reference star was usually observed immediately
      after every double star. The target search parameters generally employed were:
      \u2022 0.3\" < Separation < 3.0\". \u2022 Primary star brighter than magnitude
      11. \u2022 Declination between +68 and -2 (i.e.,observatory latitude ~33 +/35).
      Special consideration was given to binary stars which already have orbital solutions,
      in the hope of providing additional speckle measurements for refining the orbits.
      For some stars, especially those with orbits, detailed information was found
      at the Italian website Stelle-Doppie (Sordiglioni, 2016), including SAO number,
      orbital period, and current orbit ephemerides for Separation (\uf072) and Position
      Angle (\uf071). A \u201cmaster\u201d Target List was built as an EXCEL workbook,
      covering the entire RA range in spreadsheets of 2 hours each. The WDS orbit
      plots were also copied and hyper-linked into the spreadsheets for quick reference.
      For each observing run, a copy of the workbook was made, to serve as the observing
      log by entering observation date, sequence numbers, filters and notes into the
      spreadsheets in real time. A sequence of 1000 frames was acquired for most Filter
      Manufacturer Name 50% Band Pass (nm) Center Wavelength (nm) Width (nm) Peak
      Transition G Baader G (LRGB Series) 495 575 534 80 96% R Baader R (LRGB Series)
      585 690 636 105 98% IR742 Astronomik ProPlanet 742 736 \u2013 * 844 * 260 *
      56% * IR807 Astronomik ProPlanet 807 800 \u2013 * 885 * 200 * 44% * Table 1.
      Filter characteristics. These interference filters typically have a sharp rise
      and fall of about 10 nm width, and a high, nearly constant transmission plateau
      (95+%). The \u201cIR742\u201d and \u201cIR807\u201d filters are long-pass IR
      transmission filters. Vol. 15 No. 2 April 1, 2019 Page 275 Journal of Double
      Star Observations Speckle Interferometry with the OCA Kuhn 22\" Telescope II
      double and reference stars; more than one sequence was recorded for some doubles
      having a faint secondary star, with the intention to improve S/N. Stars were
      generally observed at zenith angles less than about 35 degrees, because an atmospheric
      dispersion corrector was not used; it has been found that for larger zenith
      angles atmospheric dispersion \u201csmearing\u201d becomes noticeable for the
      moderate-width filters of Table 1, possibly degrading separation and position
      angle accuracy. Acquisition and Analysis Software All data acquisition, processing
      and analysis was performed on a laptop computer with Intel i7 quad processors,
      running Windows 10. FireCapture 2.6 (Edelmann, 2015) software was used for all
      data acquisition. This very versatile program, designed primarily for planetary
      imaging, can be used with many types of astronomy cameras, easily handles fast
      USB3.0 data speeds from the camera, and can store raw data frames as FITS files,
      a convenient format for Speckle data processing in both REDUC (Losse, 2015)
      and Speckle Tool Box (STB) software (Rowe & Genet, 2015). The Drift Calibration
      method (Wasson, 2018) was used to calibrate each night\u2019s data for Plate
      Scale and Camera Orientation on the sky. Multiple drifts were made throughout
      the night typically several drifts on each of several bright reference stars;
      the average of all drift results was used to reduce all the speckle data for
      that night. Each drift sequence was first edited in REDUC to delete frames where
      the star was absent from the field, not moving, or overlapped the edge. A convenient
      Drift Calibration tool is part of the STB data reduction program (Harshaw, Rowe
      and Genet, 2017). Plate scale was about 0.0662 arc-sec/pixel. Standard deviation
      of plate scale calibrations for the 6 nights of observation ranged from 0.00022
      to 0.00044\u201d/pixel. Standard deviation of the camera orientation on the
      sky ranged from 0.13 to 0.37 degree. STB version 1.13 software (Rowe, Genet,
      Wasson, 2019) was employed for all speckle data analysis. It includes tools
      for both normal speckle AC and triple correlation BSA. The first step of processing
      was assembly of each sequence of double or reference star images into FITS cube
      format. STB has a simple-touse tool to create the FITS cubes, which centers
      each frame on the star and, if desired, crops all frames to a smaller size,
      to speed up processing time and reduce file storage space. The original speckle
      frames were a 512x512 pixel region of interest (ROI) near the center of the
      larger camera field of view, allowing plenty of room for approximate centering
      and movement from seeing and telescope tracking errors. In creating the FITS
      cubes, the field was cropped to 128x128 pixels (or 256x256 for wide doubles),
      but the original frames are not altered. Dark frames were generally not recorded
      or used in AC or BSA processing. Of course, if dark frames were to be used,
      they must be taken with exactly the same camera ROI as the speckle frames, and
      the master dark must be subtracted from all original speckle frames before creating
      a FITS cube with smaller cropped frames. This is because these smaller images
      are randomly positioned to follow the star movements and center it, losing registry
      with both original and dark frames. Normal speckle AC processing, including
      deconvolution with a reference star, was first performed for all the double
      stars; results were written to a .csv (spreadsheet) file \u2013 another convenient
      STB feature. The latest WDS observation or orbit ephemerides was used to select
      the correct \uf071 quadrant from the two peaks given by the AC solution. The
      same set of double and reference star FITS cubes were then used for BSA in STB1.13,
      and these results were copied into the AC spreadsheet for comparison. Bispectrum
      Analysis Bispectrum analysis \u2013 also known as triplecorrelation \u2013 is
      an extension of the AC speckle analysis technique; \u03c1, \u03b8 and \u0394magnitude
      of double stars down to near the diffraction limit can be measured. BSA has
      been used by professional astronomers for some time (Horch, et al, 1999). STB1.13
      became available to amateur speckle observers in 2017 for experimental testing
      (Serot, et al, 2018), and is expected to be available by request from the author
      in 2019. Two inherent mathematical limitations arise from AC processing: (1)
      the 180\u00b0 unc", "venue": "", "year": 2018, "referenceCount": 8, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category": "Physics", "source":
      "s2-fos-model"}], "publicationTypes": null, "publicationDate": null, "journal":
      null, "citationStyles": {"bibtex": "@Inproceedings{Wasson2018JournalOD,\n author
      = {Rick Wasson and Murrieta},\n title = {Journal of Double Star Observations
      V5, No4},\n year = {2018}\n}\n"}, "authors": [{"authorId": "2270888471", "name":
      "Rick Wasson"}, {"authorId": "2271780735", "name": "Murrieta"}]}, {"paperId":
      "9bb28b8f94daef420de5acfe5799acf29d79ad97", "externalIds": {"MAG": "2797229299",
      "DOI": "10.1213/ANE.0000000000002923", "CorpusId": 80083407}, "corpusId": 80083407,
      "publicationVenue": {"id": "10106566-d267-4be8-b7be-3c716007639f", "name": "Anesthesia
      and Analgesia", "type": "journal", "alternate_names": ["Anesthesia Analg", "Anesthesia
      & Analgesia", "Anesthesia  Analg"], "issn": "0003-2999", "url": "http://gateway.ovid.com/ovidweb.cgi?AN=00000539-000000000-00000&D=ovft&MODE=ovid&PAGE=toc&T=JS",
      "alternate_urls": ["http://www.anesthesia-analgesia.org/"]}, "url": "https://www.semanticscholar.org/paper/9bb28b8f94daef420de5acfe5799acf29d79ad97",
      "title": "Textbook of Rapid Response Systems", "abstract": "2142 www.anesthesia-analgesia.org
      June 2018 \u2022 Volume 126 \u2022 Number 6 DOI: 10.1213/ANE.0000000000002923
      T he second edition of Textbook of Rapid Response Systems: Concept and Implementation,
      written and edited by internationally renowned experts in the field, is the
      latest iteration of this indispensable guide to implementing and improving the
      delivery of rapid response systems (RRSs). RRSs have grown considerably in the
      last 2 decades and have become a robust strategy both to improve patient safety
      and to change the culture in the delivery of health care. This book offers practical
      guidance to clinicians, administrators, and policymakers in the delivery of
      a RRS. Textbook of Rapid Response Systems is divided up into 3 parts covering
      a comprehensive range of topics. The theme of the first part is RRSs and patient
      safety. Several chapters are dedicated to making the case for RRSs. There are
      also helpful tools introduced such as the Learning From Defects tool, a type
      of root cause analysis that helps to standardize actions and identify opportunities
      for organizational learning. The track and trigger systems currently in use
      lack clinical context and often fail to capture the dynamic nature of patient
      deterioration. Appreciating this limitation is important in understanding the
      variation in RRS success, as described in chapter 9, \u201cMultiple Parameter
      Track and Trigger Systems.\u201d \u201cCauses of Failure to Rescue,\u201d chapter
      10, describes the potential complex system interactions between the patient
      and practitioner. Factors that may potentially contribute to failures in rescuing
      deteriorating patients are discussed in detail, and the variable effectiveness
      of RRSs is explored further in chapter 11. The first part concludes with chapter
      12, \u201cMaking the Business Case for a Rapid Response System.\u201d The business
      case and the financial plan to support the RRS have to be made both for its
      creation as well as for continued support of the system. The authors suggest
      that adopting the lean management model may be feasible in the near term but
      that the more optimum model requires that consideration be made for ongoing
      training education and governance. A methodology for cost\u2013benefit analysis
      is also provided. The second part is thematically organized around creating
      a RRS. The context in which RRSs are established is important to their success.
      The system should be specific to the case mix and should include relevant personnel,
      guided by frequent auditing and modification. Perhaps the biggest challenge
      to implementing a successful RRS is the cultural change of a new system. The
      key question for administrators and hospital leadership is understanding how
      to implement a RRS that is both locally sensitive and data driven. Successful
      activation of the RRS requires empowering bedside nurses to take responsibility
      for activating the system while supported by senior clinicians. The reasons
      for failures in system activation vary between hospitals, and regular education
      and feedback are required to calibrate the ideal activation rate.1 A carefully
      calibrated system should aim to avoid activation fatigue. The optimal constitution
      of the RRS is likely to be context specific. Nurse-led teams require the support
      of senior leadership to be successful. Many interventions do not require specific
      physician input, and nurse-led teams improve patient safety by improving communication,
      adherence to clinical pathways, and education and training. There are other
      low-frequency, high-risk patient categories including the pediatric, septic,
      obstetric, tracheostomy, and difficult airway patients who require special skills
      and equipment. To maintain an effective RRS, staff should be suitably trained
      in equipment, medications, and other required resources. Emergency equipment
      should be standardized across the hospital. The RRS is resource intensive but
      also provides a source for organizational learning. The third part focuses on
      evaluating the current effectiveness of RRSs and future challenges. The activation
      of an RRS relies on observations that are relatively infrequently performed.
      The effect of continuous monitoring and automation of the recognition of the
      deteriorating patient remain in the distance, and there are several areas of
      uncertainty. Continuous monitoring offers the potential of preventing patient
      harm, though there is little real-world evidence to support its efficacy currently.
      The recognition of the dying patient, the ethical dilemma of interventions with
      a low probability of achieving the patient\u2019s goals, and the recognition
      of what constitutes a \u201cgood death\u201d remains a complex skill. Communicating
      a terminal prognosis, eliciting patient preferences, supporting families, and
      delivering a safe death are essential to minimizing distress to patients, families,
      and staff.2 The RRS is an important part of continuing the culture of caring
      for patients even when they are dying. Textbook of Rapid Response Systems: Concepts
      and Implementation, Second Edition is a focused and concise update to the best
      evidence and expert opinion on the implementation and evaluation of the service.
      This book will serve as an accessible and effective reference guide for those
      clinicians and administrators wanting to fine-tune their existing RRSs as well
      as for those health systems contemplating starting the service.", "venue": "Anesthesia
      and Analgesia", "year": 2018, "referenceCount": 2, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": null, "fieldsOfStudy": ["Medicine"],
      "s2FieldsOfStudy": [{"category": "Medicine", "source": "external"}, {"category":
      "Medicine", "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate":
      "2018-06-01", "journal": {"name": "Anesthesia & Analgesia"}, "citationStyles":
      {"bibtex": "@Article{Maharaj2018TextbookOR,\n author = {R. Maharaj},\n booktitle
      = {Anesthesia and Analgesia},\n journal = {Anesthesia & Analgesia},\n title
      = {Textbook of Rapid Response Systems},\n year = {2018}\n}\n"}, "authors": [{"authorId":
      "6278492", "name": "R. Maharaj"}]}, {"paperId": "d1aa65a2b642ed06200d8569ab08691c2be72a09",
      "externalIds": {"MAG": "2341570704", "DOI": "10.1007/978-3-662-47672-7", "CorpusId":
      10976408}, "corpusId": 10976408, "publicationVenue": {"id": "2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
      "name": "Lecture Notes in Computer Science", "type": "journal", "alternate_names":
      ["LNCS", "Transactions on Computational Systems Biology", "Trans Comput Syst
      Biology", "Lect Note Comput Sci"], "issn": "0302-9743", "alternate_issns": ["1861-2059",
      "1861-2075", "1866-4733"], "url": "http://www.springer.com/lncs", "alternate_urls":
      ["http://www.springer.com/sgw/cda/frontpage/0,11855,1-164-2-73659-0,00.html",
      "https://link.springer.com/bookseries/558", "http://link.springer.com/search?query=\"Transactions+on+Computational+Systems+Biology\""]},
      "url": "https://www.semanticscholar.org/paper/d1aa65a2b642ed06200d8569ab08691c2be72a09",
      "title": "Automata, Languages, and Programming", "abstract": null, "venue":
      "Lecture Notes in Computer Science", "year": 2015, "referenceCount": 0, "citationCount":
      2, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Mathematics"], "s2FieldsOfStudy": [{"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      null, "publicationDate": null, "journal": {"name": "Lecture Notes in Computer
      Science", "volume": "9134"}, "citationStyles": {"bibtex": "@Article{Halld\u00f3rsson2015AutomataLA,\n
      author = {M. Halld\u00f3rsson and K. Iwama and N. Kobayashi and B. Speckmann},\n
      booktitle = {Lecture Notes in Computer Science},\n journal = {Lecture Notes
      in Computer Science},\n title = {Automata, Languages, and Programming},\n volume
      = {9134},\n year = {2015}\n}\n"}, "authors": [{"authorId": "1717015", "name":
      "M. Halld\u00f3rsson"}, {"authorId": "144144899", "name": "K. Iwama"}, {"authorId":
      "144333021", "name": "N. Kobayashi"}, {"authorId": "1699605", "name": "B. Speckmann"}]},
      {"paperId": "4c1dcad4ea992c82b88ab22e309e496c315025ee", "externalIds": {"MAG":
      "608341459", "CorpusId": 122415557}, "corpusId": 122415557, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/4c1dcad4ea992c82b88ab22e309e496c315025ee",
      "title": "Algorithms and Computation: 24th International Symposium, ISAAC 2013,
      Hong Kong, China, December 16-18, 2013, Proceedings", "abstract": "Invited Talk
      Paper.- Market Approach to Social Ads: The MyLikes Example and Related Problems.-
      Session 1A: Computational Geometry I.- Geodesic-Preserving Polygon Simplification.-
      Space-Efficient and Data-Sensitive Polygon Reconstruction Algorithms from Visibility
      Angle Information.- On the Edge Crossing Properties of Euclidean Minimum Weight
      Laman Graphs.- Structure and Computation of Straight Skeletons in 3-Space.-
      Session 1B: Pattern Matching.- Pattern Matching with Non Overlapping Reversals
      - Approximation and On-line Algorithms.- Single and Multiple Consecutive Permutation
      Motif Search.- Beating O(nm) in Approximate LZW-Compressed Pattern Matching.-
      Less Space: Indexing for Queries with Wildcards.- Session 2A: Computational
      Complexity I.- On Determining Deep Holes of Generalized Reed-Solomon Codes.-
      Isomorphism on Subgraph-Closed Graph Classes: A Complexity Dichotomy and Intermediate
      Graph Classes.- Determinantal Complexities and Field Extensions.- Session 2B:
      Internet and Social Network Algorithms I.- Algorithms to Measure Diversity and
      Clustering in Social Networks through Dot Product Graphs.- Sublinear-Time Algorithms
      for Monomer-Dimer Systems on Bounded Degree Graphs.- The Complexity of Finding
      a Large Subgraph under Anonymity Constraints.- Session 3A: Graph Theory and
      Algorithms I.- On the Number of Edges of Fan-Crossing Free Graphs.- Cops and
      Robbers on Intersection Graphs.- SEFE with No Mapping via Large Induced Outerplane
      Graphs in Plane Graph.- Hardness and Algorithms for Variants of Line Graphs
      of Directed Graphs.- Session 3B: Scheduling Algorithms.- Performance Guarantees
      for Scheduling Algorithms under Perturbed Machine Speeds.- Better Bounds for
      Online k-Frame Throughput Maximization in Network Switches.- The Solvable Cases
      of a Scheduling Algorithm.- Session 4A: Computational Complexity II.- Exact
      Sublinear Binomial Sampling.- Trivial, Tractable, Hard. A Not So Sudden Complexity
      Jump in Neighborhood Restricted CNF Formulas.- Dynamic Point Labeling is Strongly
      PSPACE-Complete.- Unsatisfiable CNF Formulas Contain Many Conflicts.- Session
      4B: Computational Geometry II.- Pursuit Evasion on Polyhedral Surfaces.- Algorithms
      for Tolerated Tverberg Partitions.- Abstract Voronoi Diagrams with Disconnected
      Regions.- Terrain Visibility with Multiple Viewpoints.- Session 5A: Graph Theory
      and Algorithms II.- Exact Algorithms for Maximum Independent Set.- On the Enumeration
      and Counting of Minimal Dominating sets in Interval and Permutation Graphs.-
      Testing Mutual Duality of Planar Graph .- Session 5B: Fixed-Parameter Tractable
      Algorithms.- Effective and Efficient Data Reduction for the Subset Interconnection
      Design Problem.- Myhill-Nerode Methods for Hypergraphs.- Augmenting Graphs to
      Minimize the Diameter.- Session 6A: Algorithms and Data Structures I.- Top-k
      Document Retrieval in Compact Space and Near-Optimal Time.- Faster, Space-Efficient
      Selection Algorithms in Read-Only Memory for Integers.- Trajectory-Based Dynamic
      Map Labeling.- Session 6B: Internet and Social Network.- Algorithms II.- Asynchronous
      Rumor Spreading on Random Graphs.- Unit Cost Buyback Problem.- Faster Rumor
      Spreading with Multiple Calls.- Session 7A: Algorithmic Game Theory.- Approximating
      the Value of a Concurrent Reachability Game in the Polynomial Time Hierarchy.-
      Computing a Walrasian Equilibrium in Iterative Auctions with Multiple Differentiated
      Items.- New Results on the Online Pricing Problem.- Session 7B: Algorithms and
      Data Structures II.- RAM-Efficient External Memory Sorting.- Succinct Data Structures
      for Representing Equivalence Classes.- Sliding Bloom Filters.- Session 8A: Graph
      Theory and Algorithms III.- Vertex-Weighted Matching in Two-Directional Orthogonal
      Ray Graphs.- Bounded Representations of Interval and Proper Interval Graphs.-
      Detecting and Counting Small Pattern Graphs.- An O*Invited Talk Paper.- Market
      Approach to Social Ads: The MyLikes Example and Related Problems.- Session 1A:
      Computational Geometry I.- Geodesic-Preserving Polygon Simplification.- Space-Efficient
      and Data-Sensitive Polygon Reconstruction Algorithms from Visibility Angle Information.-
      On the Edge Crossing Properties of Euclidean Minimum Weight Laman Graphs.- Structure
      and Computation of Straight Skeletons in 3-Space.- Session 1B: Pattern Matching.-
      Pattern Matching with Non Overlapping Reversals - Approximation and On-line
      Algorithms.- Single and Multiple Consecutive Permutation Motif Search.- Beating
      O(nm) in Approximate LZW-Compressed Pattern Matching.- Less Space: Indexing
      for Queries with Wildcards.- Session 2A: Computational Complexity I.- On Determining
      Deep Holes of Generalized Reed-Solomon Codes.- Isomorphism on Subgraph-Closed
      Graph Classes: A Complexity Dichotomy and Intermediate Graph Classes.- Determinantal
      Complexities and Field Extensions.- Session 2B: Internet and Social Network
      Algorithms I.- Algorithms to Measure Diversity and Clustering in Social Networks
      through Dot Product Graphs.- Sublinear-Time Algorithms for Monomer-Dimer Systems
      on Bounded Degree Graphs.- The Complexity of Finding a Large Subgraph under
      Anonymity Constraints.- Session 3A: Graph Theory and Algorithms I.- On the Number
      of Edges of Fan-Crossing Free Graphs.- Cops and Robbers on Intersection Graphs.-
      SEFE with No Mapping via Large Induced Outerplane Graphs in Plane Graph.- Hardness
      and Algorithms for Variants of Line Graphs of Directed Graphs.- Session 3B:
      Scheduling Algorithms.- Performance Guarantees for Scheduling Algorithms under
      Perturbed Machine Speeds.- Better Bounds for Online k-Frame Throughput Maximization
      in Network Switches.- The Solvable Cases of a Scheduling Algorithm.- Session
      4A: Computational Complexity II.- Exact Sublinear Binomial Sampling.- Trivial,
      Tractable, Hard. A Not So Sudden Complexity Jump in Neighborhood Restricted
      CNF Formulas.- Dynamic Point Labeling is Strongly PSPACE-Complete.- Unsatisfiable
      CNF Formulas Contain Many Conflicts.- Session 4B: Computational Geometry II.-
      Pursuit Evasion on Polyhedral Surfaces.- Algorithms for Tolerated Tverberg Partitions.-
      Abstract Voronoi Diagrams with Disconnected Regions.- Terrain Visibility with
      Multiple Viewpoints.- Session 5A: Graph Theory and Algorithms II.- Exact Algorithms
      for Maximum Independent Set.- On the Enumeration and Counting of Minimal Dominating
      sets in Interval and Permutation Graphs.- Testing Mutual Duality of Planar Graph
      .- Session 5B: Fixed-Parameter Tractable Algorithms.- Effective and Efficient
      Data Reduction for the Subset Interconnection Design Problem.- Myhill-Nerode
      Methods for Hypergraphs.- Augmenting Graphs to Minimize the Diameter.- Session
      6A: Algorithms and Data Structures I.- Top-k Document Retrieval in Compact Space
      and Near-Optimal Time.- Faster, Space-Efficient Selection Algorithms in Read-Only
      Memory for Integers.- Trajectory-Based Dynamic Map Labeling.- Session 6B: Internet
      and Social Network.- Algorithms II.- Asynchronous Rumor Spreading on Random
      Graphs.- Unit Cost Buyback Problem.- Faster Rumor Spreading with Multiple Calls.-
      Session 7A: Algorithmic Game Theory.- Approximating the Value of a Concurrent
      Reachability Game in the Polynomial Time Hierarchy.- Computing a Walrasian Equilibrium
      in Iterative Auctions with Multiple Differentiated Items.- New Results on the
      Online Pricing Problem.- Session 7B: Algorithms and Data Structures II.- RAM-Efficient
      External Memory Sorting.- Succinct Data Structures for Representing Equivalence
      Classes.- Sliding Bloom Filters.- Session 8A: Graph Theory and Algorithms III.-
      Vertex-Weighted Matching in Two-Directional Orthogonal Ray Graphs.- Bounded
      Representations of Interval and Proper Interval Graphs.- Detecting and Counting
      Small Pattern Graphs.- An O(1.1939n) Time Algorithm for Minimum Weighted Dominating
      Induced Matching.- Session 8B: Approximation Algorithms I.- New Inapproximability
      Bounds for TSP.- Smoothed Analysis of the 2-Opt Heuristic for the TSP: Polynomial
      Bounds for Gaussian Noise.- Tight Approximation Bounds for Connectivity with
      a Color-Spanning Set.- The Train Delivery Problem Revisited.- Session 9A: Computational
      Geometry III.- The Distance 4-Sector of Two Points Is Unique.- The Number of
      Different Unfoldings of Polyhedra.- Computing the Smallest Color-Spanning Axis-Parallel
      Square.- Session 9B: Approximation Algorithms II.- Euclidean Traveling Salesman
      Tours through Stochastic Neighborhoods.- Detecting and Characterizing Small
      Dense Bipartite-Like Subgraphs by the Bipartiteness Ratio Measure.- Approximate
      Cech Complex in Low and High Dimensions.- Session 10A: Computational Complexity
      III.- Model Counting for Formulas of Bounded Clique- Width.- Computing Plurality
      Points and Condorcet Points in Euclidean Space.- Computing Minimum Tile Sets
      to Self-assemble Color Patterns.- Session 10B: Network Algorithms.- A Probabilistic
      Analysis of Kademlia Networks.- Approximating the Generalized Minimum Manhattan
      Network Problem.- Minmax Regret 1-Facility Location on Uncertain Path Networks.",
      "venue": "", "year": 2013, "referenceCount": 0, "citationCount": 2, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": null,
      "journal": {"name": "Lecture Notes in Computer Science", "volume": ""}, "citationStyles":
      {"bibtex": "@Article{Cai2013AlgorithmsAC,\n author = {L. Cai and Siu-Wing Cheng
      and T. Lam},\n journal = {Lecture Notes in Computer Science},\n title = {Algorithms
      and Computation: 24th International Symposium, ISAAC 2013, Hong Kong, China,
      December 16-18, 2013, Proceedings},\n year = {2013}\n}\n"}, "authors": [{"authorId":
      "38880588", "name": "L. Cai"}, {"authorId": "1699777", "name": "Siu-Wing Cheng"},
      {"authorId": "1719754", "name": "T. Lam"}]}, {"paperId": "fa6a06c984dd1dbf86aa1f734dcbb592bd3dea9d",
      "externalIds": {"CorpusId": 54688495}, "corpusId": 54688495, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/fa6a06c984dd1dbf86aa1f734dcbb592bd3dea9d",
      "title": "Title Advancing practical usage of microtechnology : a study of the
      functional consequences of dielectrophoresis on neural stem cells", "abstract":
      "The integration of microscale engineering, microfluidics, and AC electrokinetics
      such as dielectrophoresis has generated novel microsystems that enable quantitative
      analysis of cellular phenotype, function, and physiology. These systems are
      increasingly being used to assess diverse cell types, such as stem cells, so
      it becomes critical to thoroughly evaluate whether the systems themselves impact
      cell function. For example, engineered microsystems have been utilized to investigate
      neural stem/progenitor cells (NSPCs), which are of interest due to their potential
      to treat CNS disease and injury. Analysis by dielectrophoresis (DEP) microsystems
      determined that unlabeled NSPCs with distinct fate potential have previously
      unrecognized distinguishing electrophysiological characteristics, suggesting
      that NSPCs could be isolated by DEP microsystems without the use of cell type
      specific labels. To gauge the potential impact of DEP sorting on NSPCs, we investigated
      whether electric field exposure of varying times affected survival, proliferation,
      or fate potential of NSPCs in suspension. We found short-term DEP exposure (1
      min or less) had no effect on NSPC survival, proliferation, or fate potential
      revealed by differentiation. Moreover, NSPC proliferation (measured by DNA synthesis
      and cell cycle kinetics) and fate potential were not altered by any length of
      DEP exposure (up to 30 min). However, lengthy exposure (> 5 min) to frequencies
      near the crossover frequency (50\u2013100 kHz) led to decreased survival of
      NSPCs (maximum ~30% cell loss after 30 min). Based on experimental observations
      and mathematical simulations of cells in suspension, we find that frequencies
      near the crossover frequency generate an induced transmembrane potential that
      results in cell swelling and rupture. This is in contrast to the case for adherent
      cells since negative DEP frequencies lower than the crossover frequency generate
      the highest induced transmembrane potential and damage for these cells. We clarify
      contrasting effects of DEP on adherent and suspended cells, which are related
      to the cell position within the electric field and the strength of the electric
      field at specific distances from the electrodes. Modeling of electrode configurations
      predicts optimal designs to induce cell movement by DEP while limiting the induced
      transmembrane potential. We find DEP electric fields are not harmful to stem
      cells in suspension at short exposure times, thus providing a basis for developing
      DEP-based applications for stem cells. *Corresponding Authors: Jente Lu, Department
      of Biomedical Engineering, University of California at Irvine, 3020 Gross Hall,
      845 Health Sciences Road, Irvine, California 92697, Tel: (949) 824-0245, jentel@uci.edu.
      Lisa A. Flanagan, Ph.D., Department of Neurology, Sue & Bill Gross Stem Cell
      Research Center, University of California Irvine, 3030 Gross Hall, 845 Health
      Sciences Road, Irvine, California 92697-1705, Tel: (949) 824-5786, lflanaga@uci.edu.
      NIH Public Access Author Manuscript Integr Biol (Camb). Author manuscript; available
      in PMC 2013 October 28. Published in final edited form as: Integr Biol (Camb).
      2012 October ; 4(10): . doi:10.1039/c2ib20171b. N IH PA Athor M anscript N IH
      PA Athor M anscript N IH PA Athor M anscript", "venue": "", "year": 2013, "referenceCount":
      43, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category":
      "Engineering", "source": "s2-fos-model"}, {"category": "Biology", "source":
      "s2-fos-model"}], "publicationTypes": null, "publicationDate": null, "journal":
      null, "citationStyles": {"bibtex": "@Inproceedings{Barrios2013TitleAP,\n author
      = {Chesca A. Barrios and Amanda R. Dickson and J. Nourse and P. Abraham and
      Lee and L. Flanagan},\n title = {Title Advancing practical usage of microtechnology
      : a study of the functional consequences of dielectrophoresis on neural stem
      cells},\n year = {2013}\n}\n"}, "authors": [{"authorId": "31704072", "name":
      "Chesca A. Barrios"}, {"authorId": "2073685626", "name": "Amanda R. Dickson"},
      {"authorId": "34838888", "name": "J. Nourse"}, {"authorId": "144787730", "name":
      "P. Abraham"}, {"authorId": "2053254093", "name": "Lee"}, {"authorId": "3008066",
      "name": "L. Flanagan"}]}, {"paperId": "cb639cb1bd35e9ccd1556ed35fab0a1e2fc9d17a",
      "externalIds": {"DOI": "10.1186/1471-2105-13-293", "CorpusId": 255795358}, "corpusId":
      255795358, "publicationVenue": {"id": "be3f884c-b44a-496a-a593-1cad3f89d254",
      "name": "BMC Bioinformatics", "type": "journal", "alternate_names": ["BMC Bioinform"],
      "issn": "1471-2105", "url": "http://www.biomedcentral.com/bmcbioinformatics",
      "alternate_urls": ["http://www.pubmedcentral.nih.gov/tocrender.fcgi?journal=13",
      "http://www.biomedcentral.com/bmcbioinformatics/"]}, "url": "https://www.semanticscholar.org/paper/cb639cb1bd35e9ccd1556ed35fab0a1e2fc9d17a",
      "title": "The tree alignment problem", "abstract": null, "venue": "BMC Bioinformatics",
      "year": 2012, "referenceCount": 0, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://bmcbioinformatics.biomedcentral.com/counter/pdf/10.1186/1471-2105-13-293",
      "status": "GOLD"}, "fieldsOfStudy": null, "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Biology", "source": "s2-fos-model"}],
      "publicationTypes": null, "publicationDate": "2012-11-09", "journal": {"name":
      "BMC Bioinformatics", "volume": "13"}, "citationStyles": {"bibtex": "@Article{Var\u00f3n2012TheTA,\n
      author = {Andr\u00e9s Var\u00f3n and W. Wheeler},\n booktitle = {BMC Bioinformatics},\n
      journal = {BMC Bioinformatics},\n title = {The tree alignment problem},\n volume
      = {13},\n year = {2012}\n}\n"}, "authors": [{"authorId": "145267293", "name":
      "Andr\u00e9s Var\u00f3n"}, {"authorId": "40384475", "name": "W. Wheeler"}]},
      {"paperId": "b29fdd09c23cf4819e9eb9c849774bda1b20169f", "externalIds": {"MAG":
      "2762710077", "CorpusId": 15828382}, "corpusId": 15828382, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/b29fdd09c23cf4819e9eb9c849774bda1b20169f",
      "title": "Integration of stereophotogrammetry and triangulation-based laser
      scanning system for precise mapping of craniofacial morphology", "abstract":
      "The paper describes the first Malaysian Craniofacial soft tissue 3D imaging
      system which was developed based on the integration of stereophotogrammetry
      and triangulation-based laser scanning system. The main purposes of developing
      the imaging system are to provide a non-contact method for craniofacial anthropometric
      measurement and fast and radiation free 3D modelling of craniofacial soft tissue.
      The stereophotogrammetric system consists of high resolution digital cameras
      setup as three stereo cameras placed at the left, front and right sides of the
      patient. The system was also add-up with another extra two digital cameras setup
      in convergent mode at bottom left and bottom right of the patient. The combination
      of all the cameras allowed for the accuracy improvement of craniofacial anthropometry
      through a novel technique called \u201cnatural features technique\u201d. In
      the natural features technique, the images acquired from the camera system were
      used to digitize the natural features on the human face. Photogrammetric triangulation
      method was used to calculate the 3D coordinates of the features. The cameras
      was highly synchronized (0.2miliseconds) using a new external shutter controller.
      The stereophotogrammetric system was designed to be operated in battery system
      for mobile data capturing purposes. Apart from the camera system, the developed
      stereophotogrammetric system was completely designed with the object space control
      frame. The new patient\u2019s chair and photogrammetric control frame has been
      designed and developed. The object distance is 700mm. Special-built camera calibration
      device was designed and developed to calibrate each camera individually. The
      camera was placed at the camera platform to capture eight convergent images
      of the 3D test field. The self calibration bundle adjustment process was carried
      out using Australis software to calculate the calibration parameters. The developed
      stereophotogrammetric system was integrated with the triangulation-based laser
      scanning system. Two eye-safe Minolta VI-910 laser scanners was setup at right
      and left side of the patient and near to the stereophotogrammetric system with
      object distance of 1000mm. For the purposes of scanning the craniofacial morphology,
      the scanners was setup with middle lens (focal length = 14mm) and fine mode
      resolution with one scan mode. The scanners scanned one after another with 19
      seconds scan period (complete scan). With the optimum setup, two scan images
      was acquired which covered the craniofacial area (from right ear to left ear
      and the hair line to bottom part of the chin). The texture data of the craniofacial
      area was also captured. Both scanners were calibrated using calibrated object.
      In the data collection session, the patient sited on the chair with the head
      placed at the middle of the control frame. The complete system was firstly tested
      using mannequin to determine the accuracy and precision. Both stereo images
      and scans data was processes separately. The DVP digital stereophotogrammetric
      workstation was used to carry out the photogrammetric orientation of the stereo
      images. The vectorization module was used to measure the 3D coordinates of the
      craniofacial landmarks. The laser scan datasets involved with few data processing
      steps which included the registration process, merging process, editing process,
      smoothing process and texturing process. The processing tasks were carried out
      using the RapidForm 2004 software. At final stage, the craniofacial landmarks
      measured from stereophotogrammetric system were registered onto the 3D model
      developed from the laser scanners. The research also involved with the development
      of the craniofacial database system which used to store the captured datasets.
      The results show that both stereophotogrammetry and laser scanning system was
      an effective system to be used in craniofacial mapping. Both systems provide
      high accuracy non-contact measurement method. The accuracy of the craniofacial
      landmark measurement is 0.2mm with one standard deviation, while the accuracy
      of the 3D model is 0.3mm with one standard deviation.", "venue": "", "year":
      2008, "referenceCount": 10, "citationCount": 8, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Engineering", "source": "s2-fos-model"}, {"category": "Medicine",
      "source": "s2-fos-model"}], "publicationTypes": null, "publicationDate": null,
      "journal": {"name": "", "volume": ""}, "citationStyles": {"bibtex": "@Inproceedings{Majid2008IntegrationOS,\n
      author = {Z. Majid and H. Setan and A. Chong},\n title = {Integration of stereophotogrammetry
      and triangulation-based laser scanning system for precise mapping of craniofacial
      morphology},\n year = {2008}\n}\n"}, "authors": [{"authorId": "2406011", "name":
      "Z. Majid"}, {"authorId": "47658883", "name": "H. Setan"}, {"authorId": "1917369",
      "name": "A. Chong"}]}, {"paperId": "fd24999b70949a4c123224a8c14999211cdfceb6",
      "externalIds": {"CorpusId": 53935514}, "corpusId": 53935514, "publicationVenue":
      null, "url": "https://www.semanticscholar.org/paper/fd24999b70949a4c123224a8c14999211cdfceb6",
      "title": "Image analysis : 16th Scandinavian Conference, SCIA 2009, Oslo, Norway,
      June 15-18 : proceedings", "abstract": "Human Motion and Action Analysis.- Instant
      Action Recognition.- Using Hierarchical Models for 3D Human Body-Part Tracking.-
      Analyzing Gait Using a Time-of-Flight Camera.- Primitive Based Action Representation
      and Recognition.- Object and Pattern Recognition.- Recognition of Protruding
      Objects in Highly Structured Surroundings by Structural Inference.- A Binarization
      Algorithm Based on Shade-Planes for Road Marking Recognition.- Rotation Invariant
      Image Description with Local Binary Pattern Histogram Fourier Features.- Weighted
      DFT Based Blur Invariants for Pattern Recognition.- Color Imaging and Quality.-
      The Effect of Motion Blur and Signal Noise on Image Quality in Low Light Imaging.-
      A Hybrid Image Quality Measure for Automatic Image Quality Assessment.- Framework
      for Applying Full Reference Digital Image Quality Measures to Printed Images.-
      Colour Gamut Mapping as a Constrained Variational Problem.- Multispectral Color
      Science.- Geometric Multispectral Camera Calibration.- A Color Management Process
      for Real Time Color Reconstruction of Multispectral Images.- Precise Analysis
      of Spectral Reflectance Properties of Cosmetic Foundation.- Extending Diabetic
      Retinopathy Imaging from Color to Spectra.- Medical and Biomedical Applications.-
      Fast Prototype Based Noise Reduction.- Towards Automated TEM for Virus Diagnostics:
      Segmentation of Grid Squares and Detection of Regions of Interest.- Unsupervised
      Assessment of Subcutaneous and Visceral Fat by MRI.- Image and Pattern Analysis
      in Astrophysics and Astronomy.- Decomposition and Classification of Spectral
      Lines in Astronomical Radio Data Cubes.- Segmentation, Tracking and Characterization
      of Solar Features from EIT Solar Corona Images.- Galaxy Decomposition in Multispectral
      Images Using Markov Chain Monte Carlo Algorithms.- Face Recognition and Tracking.-
      Head Pose Estimation from Passive Stereo Images.- Multi-band Gradient Component
      Pattern (MGCP): A New Statistical Feature for Face Recognition.- Weight-Based
      Facial Expression Recognition from Near-Infrared Video Sequences.- Stereo Tracking
      of Faces for Driver Observation.- Computer Vision.- Camera Resectioning from
      a Box.- Appearance Based Extraction of Planar Structure in Monocular SLAM.-
      A New Triangulation-Based Method for Disparity Estimation in Image Sequences.-
      Sputnik Tracker: Having a Companion Improves Robustness of the Tracker.- Poster
      Session 1.- A Convex Approach to Low Rank Matrix Approximation with Missing
      Data.- Multi-frequency Phase Unwrapping from Noisy Data: Adaptive Local Maximum
      Likelihood Approach.- A New Hybrid DCT and Contourlet Transform Based JPEG Image
      Steganalysis Technique.- Improved Statistical Techniques for Multi-part Face
      Detection and Recognition.- Face Recognition under Variant Illumination Using
      PCA and Wavelets.- On the Spatial Distribution of Local Non-parametric Facial
      Shape Descriptors.- Informative Laplacian Projection.- Segmentation of Highly
      Lignified Zones in Wood Fiber Cross-Sections.- Dense and Deformable Motion Segmentation
      for Wide Baseline Images.- A Two-Phase Segmentation of Cell Nuclei Using Fast
      Level Set-Like Algorithms.- A Fast Optimization Method for Level Set Segmentation.-
      Segmentation of Touching Cell Nuclei Using a Two-Stage Graph Cut Model.- Parallel
      Volume Image Segmentation with Watershed Transformation.- Fast-Robust PCA.-
      Efficient K-Means VLSI Architecture for Vector Quantization.- Joint Random Sample
      Consensus and Multiple Motion Models for Robust Video Tracking.- Extending GKLT
      Tracking-Feature Tracking for Controlled Environments with Integrated Uncertainty
      Estimation.- Image Based Quantitative Mosaic Evaluation with Artificial Video.-
      Improving Automatic Video Retrieval with Semantic Concept Detection.- Content-Aware
      Video Editing in the Temporal Domain.- High Definition Wearable Video Communication.-
      Regularisation of 3D Signed Distance Fields.- An Evolutionary Approach for Object-Based
      Image Reconstruction Using Learnt Priors.- Disambiguation of Fingerprint Ridge
      Flow Direction-Two Approaches.- Similarity Matches of Gene Expression Data Based
      on Wavelet Transform.- Poster Session 2.- Simple Comparison of Spectral Color
      Reproduction Workflows.- Kernel Based Subspace Projection of Near Infrared Hyperspectral
      Images of Maize Kernels.- The Number of Linearly Independent Vectors in Spectral
      Databases.- A Clustering Based Method for Edge Detection in Hyperspectral Images.-
      Contrast Enhancing Colour to Grey.- On the Use of Gaze Information and Saliency
      Maps for Measuring Perceptual Contrast.- A Method to Analyze Preferred MTF for
      Printing Medium Including Paper.- Efficient Denoising of Images with Smooth
      Geometry.- Kernel Entropy Component Analysis Pre-images for Pattern Denoising.-
      Combining Local Feature Histograms of Different Granularities.- Extraction of
      Windows in Facade Using Kernel on Graph of Contours.- Multi-view and Multi-scale
      Recognition of Symmetric Patterns.- Automatic Quantification of Fluorescence
      from Clustered Targets in Microscope Images.- Bayesian Classification of Image
      Structures.- Globally Optimal Least Squares Solutions for Quasiconvex 1D Vision
      Problems.- Spatio-temporal Super-Resolution Using Depth Map.- A Comparison of
      Iterative 2D-3D Pose Estimation Methods for Real-Time Applications.- A Comparison
      of Feature Detectors with Passive and Task-Based Visual Saliency.- Grouping
      of Semantically Similar Image Positions.- Recovering Affine Deformations of
      Fuzzy Shapes.- Shape and Texture Based Classification of Fish Species.- Improved
      Quantification of Bone Remodelling by Utilizing Fuzzy Based Segmentation.- Fusion
      of Multiple Expert Annotations and Overall Score Selection for Medical Image
      Diagnosis.- Quantification of Bone Remodeling in SR?CT Images of Implants.",
      "venue": "", "year": 2009, "referenceCount": 0, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      null, "publicationDate": null, "journal": {"name": "", "volume": ""}, "citationStyles":
      {"bibtex": "@Inproceedings{None,\n title = {Image analysis : 16th Scandinavian
      Conference, SCIA 2009, Oslo, Norway, June 15-18 : proceedings},\n year = {2009}\n}\n"},
      "authors": []}, {"paperId": "20e67ebc39c355bde0edf95bd2c2510364c6db58", "externalIds":
      {"DBLP": "journals/tcbb/MandoiuPSZ09", "DOI": "10.1109/TCBB.2009.45", "CorpusId":
      44839714}, "corpusId": 44839714, "publicationVenue": null, "url": "https://www.semanticscholar.org/paper/20e67ebc39c355bde0edf95bd2c2510364c6db58",
      "title": "Guest Editors'' Introduction to the Special Section on Bioinformatics
      Research and Applications", "abstract": "THIS special section includes a selection
      of papers presented at the Fourth International Symposium on Bioinformatics
      Research and Application (ISBRA), which was held at Georgia State University
      in Atlanta, Georgia, on 6-9 May 2008. The ISBRA symposium provides a forum for
      the exchange of ideas and results among researchers, developers, and practitioners
      working on all aspects of bioinformatics and computational biology and their
      applications. In 2008, 94 papers were submitted in response to the call for
      papers, out of which 35 papers appeared in the ISBRA proceedings published as
      volume 4983 of Springer Verlag\u2019s Lecture Notes in Bioinformatics series.
      A small number of authors were invited to submit extended versions of their
      symposium papers to this special section. Following a rigorous review process,
      five papers were selected for publication. The selected papers cover a broad
      range of bioinformatics topics, including multiple local sequence alignment
      methods, computational prediction of siRNA silencing efficacy, gene network
      models, microarray data analysis and inference, and reconstruction and analysis
      of phylogenetic trees. The first paper by Treangen et al. presents a novel approach
      to identify interspersed repeats in genome sequences. Existing methods perform
      pairwise local sequence alignments to identify homologues, but these methods
      are not scalable and have limited accuracy. The method proposed in the paper
      uses a clever combination of a gapped extension heuristic and an efficient filtration
      technique to achieve greater accuracy in the identification of interspersed
      repeats. The proposed method is implemented and made available for download.
      In the second paper, Qiu and Lane adapt the Support Vector Regression approach
      by considering multiple kernel functions to effectively predict siRNA silencing
      efficacy. Computational prediction of the initiator siRNA molecules can be of
      tremendous assistance to the scientist in the screening process before using
      them in biological experiments. The authors formulate the multiple kernel learning
      function into a quadratically constrained quadratic programming problem, provide
      several heuristics, and empirically establish the superiority of their approach
      over current methods in accuracy, model complexity, and computational speed.
      In the third paper, Park et al. employ gene network models in a novel manner
      to analyze microarray data to infer cancer progression. This approach considerably
      improves the estimates of evolutionary distance between tumors over methods
      that employ only gene expression profiles. They also present three variants
      of the gene network model approach: one that uses optimized best-fit networks,
      the second that uses sampling to infer high confidence subnetworks, and the
      third that uses modular networks inferred from clusters of similarly expressed
      genes. The three variants show excellent results on lung cancer and breast cancer
      microarray data. The last two papers are devoted to advanced methods for the
      reconstruction and analysis of phylogenetic trees. The paper by Zhu et al. proposes
      a new way to define and analyze gene clusters and gene order. They show that
      the bandwidth parameter of a graph is tightly connected with the proposed parameterized
      definition of gene clusters and affects the number, size, and extent of preservation
      of identified clusters along phylogenetic trees. The latter property is computed
      using a new dynamic programming algorithm. The advantages of the proposed analysis
      methods are illustrated by application to a set of genomes drawn from the Yeast
      Gene Order Browser. The paper by Bansal et al. is devoted to the problem of
      inferring a species supertree by reconciling gene trees, including those constructed
      for large families of duplicated genes, based on the duplication optimality
      criterion. The resulting optimization problem (commonly referred to as the gene-duplication
      problem) is NP-hard and practical solutions are frequently based on local search
      heuristics. In each step, these heuristics must find a phylogenetic tree that
      is optimal under the duplication optimality criterion in the neighborhood of
      the current tree, i.e., the set of trees that can be obtained from it by applying
      a variety of tree edit operations. The authors propose near-linear time algorithms
      for searching optimal trees within neighborhoods defined by the k-NNI (Nearest
      Neighbor Interchange) tree edit operation for k 2 f1; 2; 3g. They validate their
      algorithms using sets of large randomly generated gene trees. We would like
      to thank the Program Committee members and external reviewers for volunteering
      their 178 IEEE/ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS,
      VOL. 6, NO. 2, APRIL-JUNE 2009", "venue": "TCBB", "year": 2009, "referenceCount":
      0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Biology",
      "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle", "Review"], "publicationDate": null, "journal":
      {"name": "IEEE ACM Trans. Comput. Biol. Bioinform.", "pages": "178-179", "volume":
      "6"}, "citationStyles": {"bibtex": "@Article{M\u0103ndoiu2009GuestEI,\n author
      = {I. M\u0103ndoiu and Yi Pan and Rajshekhar Sunderraman and A. Zelikovsky},\n
      booktitle = {TCBB},\n journal = {IEEE ACM Trans. Comput. Biol. Bioinform.},\n
      pages = {178-179},\n title = {Guest Editors'' Introduction to the Special Section
      on Bioinformatics Research and Applications},\n volume = {6},\n year = {2009}\n}\n"},
      "authors": [{"authorId": "1743075", "name": "I. M\u0103ndoiu"}, {"authorId":
      "2115430219", "name": "Yi Pan"}, {"authorId": "1756672", "name": "Rajshekhar
      Sunderraman"}, {"authorId": "1720195", "name": "A. Zelikovsky"}]}, {"paperId":
      "202e833b9332fa5ec86d30fedc883701ba75b6d3", "externalIds": {"MAG": "2970643113",
      "CorpusId": 203215075}, "corpusId": 203215075, "publicationVenue": null, "url":
      "https://www.semanticscholar.org/paper/202e833b9332fa5ec86d30fedc883701ba75b6d3",
      "title": "Image analysis : 16th Scandinavian Conference, SCIA 2009, Oslo, Norway,
      June 15-18 : proceedings", "abstract": "Human Motion and Action Analysis.- Instant
      Action Recognition.- Using Hierarchical Models for 3D Human Body-Part Tracking.-
      Analyzing Gait Using a Time-of-Flight Camera.- Primitive Based Action Representation
      and Recognition.- Object and Pattern Recognition.- Recognition of Protruding
      Objects in Highly Structured Surroundings by Structural Inference.- A Binarization
      Algorithm Based on Shade-Planes for Road Marking Recognition.- Rotation Invariant
      Image Description with Local Binary Pattern Histogram Fourier Features.- Weighted
      DFT Based Blur Invariants for Pattern Recognition.- Color Imaging and Quality.-
      The Effect of Motion Blur and Signal Noise on Image Quality in Low Light Imaging.-
      A Hybrid Image Quality Measure for Automatic Image Quality Assessment.- Framework
      for Applying Full Reference Digital Image Quality Measures to Printed Images.-
      Colour Gamut Mapping as a Constrained Variational Problem.- Multispectral Color
      Science.- Geometric Multispectral Camera Calibration.- A Color Management Process
      for Real Time Color Reconstruction of Multispectral Images.- Precise Analysis
      of Spectral Reflectance Properties of Cosmetic Foundation.- Extending Diabetic
      Retinopathy Imaging from Color to Spectra.- Medical and Biomedical Applications.-
      Fast Prototype Based Noise Reduction.- Towards Automated TEM for Virus Diagnostics:
      Segmentation of Grid Squares and Detection of Regions of Interest.- Unsupervised
      Assessment of Subcutaneous and Visceral Fat by MRI.- Image and Pattern Analysis
      in Astrophysics and Astronomy.- Decomposition and Classification of Spectral
      Lines in Astronomical Radio Data Cubes.- Segmentation, Tracking and Characterization
      of Solar Features from EIT Solar Corona Images.- Galaxy Decomposition in Multispectral
      Images Using Markov Chain Monte Carlo Algorithms.- Face Recognition and Tracking.-
      Head Pose Estimation from Passive Stereo Images.- Multi-band Gradient Component
      Pattern (MGCP): A New Statistical Feature for Face Recognition.- Weight-Based
      Facial Expression Recognition from Near-Infrared Video Sequences.- Stereo Tracking
      of Faces for Driver Observation.- Computer Vision.- Camera Resectioning from
      a Box.- Appearance Based Extraction of Planar Structure in Monocular SLAM.-
      A New Triangulation-Based Method for Disparity Estimation in Image Sequences.-
      Sputnik Tracker: Having a Companion Improves Robustness of the Tracker.- Poster
      Session 1.- A Convex Approach to Low Rank Matrix Approximation with Missing
      Data.- Multi-frequency Phase Unwrapping from Noisy Data: Adaptive Local Maximum
      Likelihood Approach.- A New Hybrid DCT and Contourlet Transform Based JPEG Image
      Steganalysis Technique.- Improved Statistical Techniques for Multi-part Face
      Detection and Recognition.- Face Recognition under Variant Illumination Using
      PCA and Wavelets.- On the Spatial Distribution of Local Non-parametric Facial
      Shape Descriptors.- Informative Laplacian Projection.- Segmentation of Highly
      Lignified Zones in Wood Fiber Cross-Sections.- Dense and Deformable Motion Segmentation
      for Wide Baseline Images.- A Two-Phase Segmentation of Cell Nuclei Using Fast
      Level Set-Like Algorithms.- A Fast Optimization Method for Level Set Segmentation.-
      Segmentation of Touching Cell Nuclei Using a Two-Stage Graph Cut Model.- Parallel
      Volume Image Segmentation with Watershed Transformation.- Fast-Robust PCA.-
      Efficient K-Means VLSI Architecture for Vector Quantization.- Joint Random Sample
      Consensus and Multiple Motion Models for Robust Video Tracking.- Extending GKLT
      Tracking-Feature Tracking for Controlled Environments with Integrated Uncertainty
      Estimation.- Image Based Quantitative Mosaic Evaluation with Artificial Video.-
      Improving Automatic Video Retrieval with Semantic Concept Detection.- Content-Aware
      Video Editing in the Temporal Domain.- High Definition Wearable Video Communication.-
      Regularisation of 3D Signed Distance Fields.- An Evolutionary Approach for Object-Based
      Image Reconstruction Using Learnt Priors.- Disambiguation of Fingerprint Ridge
      Flow Direction-Two Approaches.- Similarity Matches of Gene Expression Data Based
      on Wavelet Transform.- Poster Session 2.- Simple Comparison of Spectral Color
      Reproduction Workflows.- Kernel Based Subspace Projection of Near Infrared Hyperspectral
      Images of Maize Kernels.- The Number of Linearly Independent Vectors in Spectral
      Databases.- A Clustering Based Method for Edge Detection in Hyperspectral Images.-
      Contrast Enhancing Colour to Grey.- On the Use of Gaze Information and Saliency
      Maps for Measuring Perceptual Contrast.- A Method to Analyze Preferred MTF for
      Printing Medium Including Paper.- Efficient Denoising of Images with Smooth
      Geometry.- Kernel Entropy Component Analysis Pre-images for Pattern Denoising.-
      Combining Local Feature Histograms of Different Granularities.- Extraction of
      Windows in Facade Using Kernel on Graph of Contours.- Multi-view and Multi-scale
      Recognition of Symmetric Patterns.- Automatic Quantification of Fluorescence
      from Clustered Targets in Microscope Images.- Bayesian Classification of Image
      Structures.- Globally Optimal Least Squares Solutions for Quasiconvex 1D Vision
      Problems.- Spatio-temporal Super-Resolution Using Depth Map.- A Comparison of
      Iterative 2D-3D Pose Estimation Methods for Real-Time Applications.- A Comparison
      of Feature Detectors with Passive and Task-Based Visual Saliency.- Grouping
      of Semantically Similar Image Positions.- Recovering Affine Deformations of
      Fuzzy Shapes.- Shape and Texture Based Classification of Fish Species.- Improved
      Quantification of Bone Remodelling by Utilizing Fuzzy Based Segmentation.- Fusion
      of Multiple Expert Annotations and Overall Score Selection for Medical Image
      Diagnosis.- Quantification of Bone Remodeling in SR?CT Images of Implants.",
      "venue": "", "year": 2009, "referenceCount": 0, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"}],
      "publicationTypes": null, "publicationDate": null, "journal": {"name": "", "volume":
      ""}, "citationStyles": {"bibtex": "@Inproceedings{Salberg2009ImageA,\n author
      = {A. Salberg and J. Hardeberg and R. Jenssen},\n title = {Image analysis :
      16th Scandinavian Conference, SCIA 2009, Oslo, Norway, June 15-18 : proceedings},\n
      year = {2009}\n}\n"}, "authors": [{"authorId": "48068407", "name": "A. Salberg"},
      {"authorId": "1993363", "name": "J. Hardeberg"}, {"authorId": "1747567", "name":
      "R. Jenssen"}]}, {"paperId": "1d690c95be7d91570f813ad1ca7944cb759ae974", "externalIds":
      {"MAG": "1571621449", "DBLP": "conf/icoin/2006", "DOI": "10.1007/11919568",
      "CorpusId": 20622003}, "corpusId": 20622003, "publicationVenue": {"id": "0e129215-7c25-46c9-b04b-a0e9faabf021",
      "name": "International Conference on Information Networking", "type": "conference",
      "alternate_names": ["Int Conf Inf Netw", "ICOIN"], "url": "http://www.icoin.org/"},
      "url": "https://www.semanticscholar.org/paper/1d690c95be7d91570f813ad1ca7944cb759ae974",
      "title": "Information Networking, Advances in Data Communications and Wireless
      Networks, International Conference, ICOIN 2006, Sendai, Japan, January 16-19,
      2006, Revised Selected Papers", "abstract": null, "venue": "International Conference
      on Information Networking", "year": 2006, "referenceCount": 0, "citationCount":
      2, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://link.springer.com/content/pdf/bfm:978-3-540-48564-3/1?pdf=chapter%20toc",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Engineering", "source": "s2-fos-model"}],
      "publicationTypes": null, "publicationDate": null, "journal": {"volume": "3961"},
      "citationStyles": {"bibtex": "@Inproceedings{Chong2006InformationNA,\n author
      = {I. Chong and K. Kawahara},\n booktitle = {International Conference on Information
      Networking},\n title = {Information Networking, Advances in Data Communications
      and Wireless Networks, International Conference, ICOIN 2006, Sendai, Japan,
      January 16-19, 2006, Revised Selected Papers},\n volume = {3961},\n year = {2006}\n}\n"},
      "authors": [{"authorId": "3344348", "name": "I. Chong"}, {"authorId": "2039559",
      "name": "K. Kawahara"}]}]}

      '
    headers:
      Access-Control-Allow-Origin:
      - '*'
      Connection:
      - keep-alive
      Content-Length:
      - '325289'
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Dec 2023 21:48:38 GMT
      Via:
      - 1.1 6fe8e2d5db6a80353eb675f61c249810.cloudfront.net (CloudFront)
      X-Amz-Cf-Id:
      - KlznBbMLWsvTo0W4jy4gCf0109087n8P4m41aZDK-Fo3R64SaNyAzA==
      X-Amz-Cf-Pop:
      - GRU3-P4
      X-Cache:
      - Miss from cloudfront
      x-amz-apigw-id:
      - Qn1EZHNEvHcEoKA=
      x-amzn-Remapped-Connection:
      - keep-alive
      x-amzn-Remapped-Content-Length:
      - '325289'
      x-amzn-Remapped-Date:
      - Wed, 27 Dec 2023 21:48:38 GMT
      x-amzn-Remapped-Server:
      - gunicorn
      x-amzn-RequestId:
      - b0a4074e-6ad4-4cd0-a408-190fdf2f8c16
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - api.semanticscholar.org
      user-agent:
      - python-httpx/0.25.2
    method: GET
    uri: https://api.semanticscholar.org/graph/v1/paper/search?query=sublinear%20near%20optimal%20edit%20distance&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=100&limit=100
  response:
    content: '{"error":"Requested data for this limit and/or offset is not available"}

      '
    headers:
      Access-Control-Allow-Origin:
      - '*'
      Connection:
      - keep-alive
      Content-Length:
      - '73'
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Dec 2023 21:48:39 GMT
      Via:
      - 1.1 d25a1132f04e5b0e596d295b437a27be.cloudfront.net (CloudFront)
      X-Amz-Cf-Id:
      - PZqmf-65TyT6baaTXRjcPcVVp-ISvu5m29INI0Cqa0tvHvkK4UIoog==
      X-Amz-Cf-Pop:
      - GRU3-P4
      X-Cache:
      - Error from cloudfront
      x-amz-apigw-id:
      - Qn1EwGW2vHcEHoA=
      x-amzn-Remapped-Connection:
      - keep-alive
      x-amzn-Remapped-Content-Length:
      - '73'
      x-amzn-Remapped-Date:
      - Wed, 27 Dec 2023 21:48:39 GMT
      x-amzn-Remapped-Server:
      - gunicorn
      x-amzn-RequestId:
      - 1ed4bd47-66ef-43c3-8b81-b4dc71b98849
    http_version: HTTP/1.1
    status_code: 400
version: 1
