interactions:
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - api.semanticscholar.org
      user-agent:
      - python-httpx/0.25.2
    method: GET
    uri: https://api.semanticscholar.org/graph/v1/paper/search?query=turing&venue=ArXiv&fields=abstract,authors,citationCount,citationStyles,corpusId,externalIds,fieldsOfStudy,influentialCitationCount,isOpenAccess,journal,openAccessPdf,paperId,publicationDate,publicationTypes,publicationVenue,referenceCount,s2FieldsOfStudy,title,url,venue,year&offset=0&limit=100
  response:
    content: '{"total": 794, "offset": 0, "next": 100, "data": [{"paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19",
      "externalIds": {"ArXiv": "2201.11990", "DBLP": "journals/corr/abs-2201-11990",
      "CorpusId": 246411325}, "corpusId": 246411325, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/7cbc2a7843411a1768ab762930707af0a3c33a19",
      "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A
      Large-Scale Generative Language Model", "abstract": "Pretrained general-purpose
      language models can achieve state-of-the-art accuracies in various natural language
      processing domains by adapting to downstream tasks via zero-shot, few-shot and
      fine-tuning techniques. Because of their success, the size of these models has
      increased rapidly, requiring high-performance hardware, software, and algorithmic
      techniques to enable training such large models. As the result of a joint effort
      between Microsoft and NVIDIA, we present details on the training of the largest
      monolithic transformer based language model, Megatron-Turing NLG 530B (MT-NLG),
      with 530 billion parameters. In this paper, we first focus on the infrastructure
      as well as the 3D parallelism methodology used to train this model using DeepSpeed
      and Megatron. Next, we detail the training process, the design of our training
      corpus, and our data curation techniques, which we believe is a key ingredient
      to the success of the model. Finally, we discuss various evaluation results,
      as well as other interesting observations and new properties exhibited by MT-NLG.
      We demonstrate that MT-NLG achieves superior zero-, one-, and few-shot learning
      accuracies on several NLP benchmarks and establishes new state-of-the-art results.
      We believe that our contributions will help further the development of large-scale
      training infrastructures, large-scale language models, and natural language
      generations.", "venue": "arXiv.org", "year": 2022, "referenceCount": 78, "citationCount":
      476, "influentialCitationCount": 34, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2022-01-28", "journal": {"name": "ArXiv", "volume": "abs/2201.11990"}, "citationStyles":
      {"bibtex": "@Article{Smith2022UsingDA,\n author = {Shaden Smith and M. Patwary
      and Brandon Norick and P. LeGresley and Samyam Rajbhandari and J. Casper and
      Zhun Liu and Shrimai Prabhumoye and George Zerveas and V. Korthikanti and Elton
      Zhang and Rewon Child and Reza Yazdani Aminabadi and J. Bernauer and Xia Song
      and M. Shoeybi and Yuxiong He and Michael Houston and Saurabh Tiwary and Bryan
      Catanzaro},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Using
      DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative
      Language Model},\n volume = {abs/2201.11990},\n year = {2022}\n}\n"}, "authors":
      [{"authorId": "2110486618", "name": "Shaden Smith"}, {"authorId": "66870756",
      "name": "M. Patwary"}, {"authorId": "2172095", "name": "Brandon Norick"}, {"authorId":
      "3081566", "name": "P. LeGresley"}, {"authorId": "32817044", "name": "Samyam
      Rajbhandari"}, {"authorId": "48991386", "name": "J. Casper"}, {"authorId": "49293070",
      "name": "Zhun Liu"}, {"authorId": "9358910", "name": "Shrimai Prabhumoye"},
      {"authorId": "30647302", "name": "George Zerveas"}, {"authorId": "3111334",
      "name": "V. Korthikanti"}, {"authorId": "2151686157", "name": "Elton Zhang"},
      {"authorId": "48422824", "name": "Rewon Child"}, {"authorId": "3394222", "name":
      "Reza Yazdani Aminabadi"}, {"authorId": "2745589", "name": "J. Bernauer"}, {"authorId":
      "50706785", "name": "Xia Song"}, {"authorId": "1911755", "name": "M. Shoeybi"},
      {"authorId": "2145020341", "name": "Yuxiong He"}, {"authorId": "122523478",
      "name": "Michael Houston"}, {"authorId": "40070335", "name": "Saurabh Tiwary"},
      {"authorId": "2301680", "name": "Bryan Catanzaro"}]}, {"paperId": "c3823aacea60bc1f2cabb9283144690a3d015db5",
      "externalIds": {"MAG": "2167839676", "DBLP": "journals/corr/GravesWD14", "ArXiv":
      "1410.5401", "CorpusId": 15299054}, "corpusId": 15299054, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/c3823aacea60bc1f2cabb9283144690a3d015db5",
      "title": "Neural Turing Machines", "abstract": "We extend the capabilities of
      neural networks by coupling them to external memory resources, which they can
      interact with by attentional processes. The combined system is analogous to
      a Turing Machine or Von Neumann architecture but is differentiable end-toend,
      allowing it to be efficiently trained with gradient descent. Preliminary results
      demonstrate that Neural Turing Machines can infer simple algorithms such as
      copying, sorting, and associative recall from input and output examples.", "venue":
      "arXiv.org", "year": 2014, "referenceCount": 41, "citationCount": 2051, "influentialCitationCount":
      223, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2014-10-20", "journal": {"name": "ArXiv", "volume": "abs/1410.5401"}, "citationStyles":
      {"bibtex": "@Article{Graves2014NeuralTM,\n author = {Alex Graves and Greg Wayne
      and Ivo Danihelka},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title
      = {Neural Turing Machines},\n volume = {abs/1410.5401},\n year = {2014}\n}\n"},
      "authors": [{"authorId": "1753223", "name": "Alex Graves"}, {"authorId": "89504302",
      "name": "Greg Wayne"}, {"authorId": "1841008", "name": "Ivo Danihelka"}]}, {"paperId":
      "836e7a4e2e290910d967e904b0930ddb104071a5", "externalIds": {"DBLP": "journals/corr/abs-2208-06279",
      "ArXiv": "2208.06279", "DOI": "10.48550/arXiv.2208.06279", "CorpusId": 251554593},
      "corpusId": 251554593, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/836e7a4e2e290910d967e904b0930ddb104071a5",
      "title": "Developmental Network Two, Its Optimality, and Emergent Turing Machines",
      "abstract": "OF THE DISCLOSURE This invention includes a new type of neural
      network that is able to automatically and incrementally generate an internal
      hierarchy without a need to handcraft a static hierarchy of network areas and
      a static number of levels and the static number of neurons in each network area
      or level. This capability is achieved by enabling each neuron to have its own
      dynamic inhibitory zone using neuron-specific inhibitory connections.", "venue":
      "arXiv.org", "year": 2022, "referenceCount": 48, "citationCount": 10, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "http://arxiv.org/pdf/2208.06279",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2022-08-04", "journal": {"name": "ArXiv", "volume": "abs/2208.06279"},
      "citationStyles": {"bibtex": "@Article{Weng2022DevelopmentalNT,\n author = {J.
      Weng and Zejia Zheng and Xiang Wu},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Developmental Network Two, Its Optimality, and Emergent Turing Machines},\n
      volume = {abs/2208.06279},\n year = {2022}\n}\n"}, "authors": [{"authorId":
      "145926447", "name": "J. Weng"}, {"authorId": "2010802", "name": "Zejia Zheng"},
      {"authorId": "2108404228", "name": "Xiang Wu"}]}, {"paperId": "2a7e86f6af062445196dbc505d6422637e0d1fbd",
      "externalIds": {"DBLP": "journals/corr/abs-2201-04678", "ArXiv": "2201.04678",
      "CorpusId": 245906284}, "corpusId": 245906284, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/2a7e86f6af062445196dbc505d6422637e0d1fbd",
      "title": "Polynomial Turing Compressions for Some Graph Problems Parameterized
      by Modular-Width", "abstract": "A polynomial Turing compression (PTC) for a
      parameterized problem $L$ is a polynomial time Turing machine that has access
      to an oracle for a problem $L''$ such that a polynomial in the input parameter
      bounds each query. Meanwhile, a polynomial (many-one) compression (PC) can be
      regarded as a restricted variant of PTC where the machine can query the oracle
      exactly once and must output the same answer as the oracle. Bodlaender et al.
      (ICALP 2008) and Fortnow and Santhanam (STOC 2008) initiated an impressive hardness
      theory for PC under the assumption coNP $\\not\\subseteq$ NP/poly. Since PTC
      is a generalization of PC, we define $\\mathcal{C}$ as the set of all problems
      that have PTCs but have no PCs under the assumption coNP $\\not\\subseteq$ NP/poly.
      Based on the hardness theory for PC, Fernau et al. (STACS 2009) found the first
      problem Leaf Out-tree($k$) in $\\mathcal{C}$. However, very little is known
      about $\\mathcal{C}$, as only a dozen problems were shown to belong to the complexity
      class in the last ten years. Several problems are open, for example, whether
      CNF-SAT($n$) and $k$-path are in $\\mathcal{C}$, and novel ideas are required
      to better understand the fundamental differences between PTCs and PCs. In this
      paper, we enrich our knowledge about $\\mathcal{C}$ by showing that several
      problems parameterized by modular-width ($mw$) belong to $\\mathcal{C}$. More
      specifically, exploiting the properties of the well-studied structural graph
      parameter $mw$, we demonstrate 17 problems parameterized by $mw$ are in $\\mathcal{C}$,
      such as Chromatic Number($mw$) and Hamiltonian Cycle($mw$). In addition, we
      develop a general recipe to prove the existence of PTCs for a large class of
      problems, including our 17 problems.", "venue": "arXiv.org", "year": 2022, "referenceCount":
      51, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2022-01-12", "journal":
      {"name": "ArXiv", "volume": "abs/2201.04678"}, "citationStyles": {"bibtex":
      "@Article{Luo2022PolynomialTC,\n author = {Weidong Luo},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {Polynomial Turing Compressions for Some Graph
      Problems Parameterized by Modular-Width},\n volume = {abs/2201.04678},\n year
      = {2022}\n}\n"}, "authors": [{"authorId": "49756279", "name": "Weidong Luo"}]},
      {"paperId": "7849726f7176d93b770221f1d9e76129d95af6e2", "externalIds": {"DBLP":
      "journals/corr/abs-2204-00563", "DOI": "10.48550/arXiv.2204.00563", "CorpusId":
      247922712}, "corpusId": 247922712, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/7849726f7176d93b770221f1d9e76129d95af6e2",
      "title": "Arithmetic logical Irreversibility and the Turing''s Halt Problem",
      "abstract": ": A different explanation to the halting problem in Turing''s machine
      because of the phenomenon of arithmetic logical irreversibility and memory erasure
      that introduce computing uncertainty or improbability into the machine and therefore
      make it impossible to predict how the calculation or computation will develop.
      Characteristics of arithmetic logical irreversibility, Landauer principle and
      memory erasure. Definition of the concept of arithmetic logical entropy as a
      measure of uncertainty and indicator of loss 1 of information. Turing machine
      as a series of computational states that can be transformed through the \u03bb
      calculus and the Turing/Church thesis into a series of arithmetic 2 logical
      operations equivalent to this machine and then applying different interpretations
      of the Shannon measure of information on this series of computational arithmetic
      logical operations may be defined the measure of computer uncertainty or improbability.
      The indecision in the halting problem of the Turing machine because of computational
      uncertainty that is expressed as lack of information to determine how computing
      will develop. Based on these facts 3 it can be shown that there is a local computational
      determinism that is determined by immediate computing conditions, but there
      is a global indeterminism over the entire series of computational operations
      jointed. This also leads us to a different explanation of Turing''s oracle machine
      as such that it introduces external information into the computational performance
      to control computational uncertainty and thus decide the outcome of the computation.
      The Shannon''s interpretations for the measure of the information show that
      indecision over the halting conditions of a Turing machine through an algorithm
      is a consequence of uncertainty and lack of", "venue": "arXiv.org", "year":
      2022, "referenceCount": 19, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "http://arxiv.org/pdf/2204.00563",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal":
      {"name": "ArXiv", "volume": "abs/2204.00563"}, "citationStyles": {"bibtex":
      "@Article{Lapin2022ArithmeticLI,\n author = {Ya. S. Lapin and C. Bennet and
      R. Landauer and G. Chaitin},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Arithmetic logical Irreversibility and the Turing''s Halt Problem},\n
      volume = {abs/2204.00563},\n year = {2022}\n}\n"}, "authors": [{"authorId":
      "93077307", "name": "Ya. S. Lapin"}, {"authorId": "2265974437", "name": "C.
      Bennet"}, {"authorId": "2265984761", "name": "R. Landauer"}, {"authorId": "2265899066",
      "name": "G. Chaitin"}]}, {"paperId": "1382cd1a16b001cbb5a298d4458b788c2f0a6ffa",
      "externalIds": {"ArXiv": "2211.13087", "DBLP": "journals/corr/abs-2211-13087",
      "DOI": "10.48550/arXiv.2211.13087", "CorpusId": 253801749}, "corpusId": 253801749,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/1382cd1a16b001cbb5a298d4458b788c2f0a6ffa",
      "title": "Human or Machine? Turing Tests for Vision and Language", "abstract":
      "As AI algorithms increasingly participate in daily activities that used to
      be the sole province of humans, we are inevitably called upon to consider how
      much machines are really like us. To address this question, we turn to the Turing
      test and systematically benchmark current AIs in their abilities to imitate
      humans. We establish a methodology to evaluate humans versus machines in Turing-like
      tests and systematically evaluate a representative set of selected domains,
      parameters, and variables. The experiments involved testing 769 human agents,
      24 state-of-the-art AI agents, 896 human judges, and 8 AI judges, in 21,570
      Turing tests across 6 tasks encompassing vision and language modalities. Surprisingly,
      the results reveal that current AIs are not far from being able to impersonate
      human judges across different ages, genders, and educational levels", "venue":
      "arXiv.org", "year": 2022, "referenceCount": 78, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/2211.13087",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2022-11-23", "journal": {"name": "ArXiv", "volume": "abs/2211.13087"},
      "citationStyles": {"bibtex": "@Article{Zhang2022HumanOM,\n author = {Mengmi
      Zhang and Giorgia Dellaferrera and Ankur Sikarwar and M. Armend\u00e1riz and
      Noga Mudrik and Prachi Agrawal and Spandan Madan and Andrei Barbu and Haochen
      Yang and T. Kumar and Meghna Sadwani and Stella Dellaferrera and Michele Pizzochero
      and H. Pfister and Gabriel Kreiman},\n booktitle = {arXiv.org},\n journal =
      {ArXiv},\n title = {Human or Machine? Turing Tests for Vision and Language},\n
      volume = {abs/2211.13087},\n year = {2022}\n}\n"}, "authors": [{"authorId":
      "2418491", "name": "Mengmi Zhang"}, {"authorId": "104096295", "name": "Giorgia
      Dellaferrera"}, {"authorId": "2048021896", "name": "Ankur Sikarwar"}, {"authorId":
      "40263427", "name": "M. Armend\u00e1riz"}, {"authorId": "2168467358", "name":
      "Noga Mudrik"}, {"authorId": "2067433241", "name": "Prachi Agrawal"}, {"authorId":
      "7232330", "name": "Spandan Madan"}, {"authorId": "21570451", "name": "Andrei
      Barbu"}, {"authorId": "2118530836", "name": "Haochen Yang"}, {"authorId": "2191899809",
      "name": "T. Kumar"}, {"authorId": "2191899184", "name": "Meghna Sadwani"}, {"authorId":
      "2191899118", "name": "Stella Dellaferrera"}, {"authorId": "2191896327", "name":
      "Michele Pizzochero"}, {"authorId": "40624376", "name": "H. Pfister"}, {"authorId":
      "2066787605", "name": "Gabriel Kreiman"}]}, {"paperId": "bc0210361535562dac14987da8a91c7839533682",
      "externalIds": {"DBLP": "journals/corr/abs-2208-14755", "ArXiv": "2208.14755",
      "DOI": "10.48550/arXiv.2208.14755", "CorpusId": 251953492}, "corpusId": 251953492,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/bc0210361535562dac14987da8a91c7839533682",
      "title": "Python Type Hints are Turing Complete", "abstract": "Grigore showed
      that Java generics are Turing complete by describing a reduction from Turing
      machines to Java subtyping. We apply Grigore''s algorithm to Python type hints
      and deduce that they are Turing complete. In addition, we present an alternative
      reduction in which the Turing machines are simulated in real time, resulting
      in significantly lower compilation times. Our work is accompanied by a Python
      implementation of both reductions that compiles Turing machines into Python
      subtyping machines.", "venue": "arXiv.org", "year": 2022, "referenceCount":
      20, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true,
      "openAccessPdf": {"url": "http://arxiv.org/pdf/2208.14755", "status": "GREEN"},
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2022-08-31", "journal": {"name": "ArXiv",
      "volume": "abs/2208.14755"}, "citationStyles": {"bibtex": "@Article{Roth2022PythonTH,\n
      author = {Ori Roth},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title
      = {Python Type Hints are Turing Complete},\n volume = {abs/2208.14755},\n year
      = {2022}\n}\n"}, "authors": [{"authorId": "38840709", "name": "Ori Roth"}]},
      {"paperId": "37371d64ae7a73f8bad43482dce40fa6485d9d6f", "externalIds": {"ArXiv":
      "2205.03949", "DBLP": "journals/corr/abs-2205-03949", "DOI": "10.48550/arXiv.2205.03949",
      "CorpusId": 248665550}, "corpusId": 248665550, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/37371d64ae7a73f8bad43482dce40fa6485d9d6f",
      "title": "Turing machine interaction problem", "abstract": "\u0410\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u044f.
      The article introduces some ideas for solving special cases of the following
      problem, proposed in a somewhat generalized form by Marcus Hutter in 2000. Given
      two Turing machines A and C, it is required to build a Turing machine B, such
      that after interacting of A and B on a shared tape for a fixed number of iterations,
      the machine C outputs 1 on the communication protocol of A and B. Details in
      the introduction.", "venue": "arXiv.org", "year": 2022, "referenceCount": 7,
      "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf":
      {"url": "https://arxiv.org/pdf/2205.03949", "status": "GREEN"}, "fieldsOfStudy":
      ["Mathematics", "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2022-05-08", "journal": {"name": "ArXiv",
      "volume": "abs/2205.03949"}, "citationStyles": {"bibtex": "@Article{Matdinov2022TuringMI,\n
      author = {M. Matdinov},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title
      = {Turing machine interaction problem},\n volume = {abs/2205.03949},\n year
      = {2022}\n}\n"}, "authors": [{"authorId": "2284734", "name": "M. Matdinov"}]},
      {"paperId": "cc3461f286d57aea512837ed2d88d11f552efb5f", "externalIds": {"DBLP":
      "journals/corr/abs-2212-11834", "ArXiv": "2212.11834", "DOI": "10.48550/arXiv.2212.11834",
      "CorpusId": 254974098}, "corpusId": 254974098, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/cc3461f286d57aea512837ed2d88d11f552efb5f",
      "title": "Real-valued affine automata compute beyond Turing machines", "abstract":
      "We show that bounded-error affine finite automata recognize uncountably many
      (and so some non-Turing recognizable) languages when using real-valued transitions.",
      "venue": "arXiv.org", "year": 2022, "referenceCount": 30, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "http://arxiv.org/pdf/2212.11834", "status": "GREEN"}, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2022-12-22", "journal": {"name": "ArXiv", "volume": "abs/2212.11834"}, "citationStyles":
      {"bibtex": "@Article{Yakary\u0131lmaz2022RealvaluedAA,\n author = {A. Yakary\u0131lmaz},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Real-valued affine
      automata compute beyond Turing machines},\n volume = {abs/2212.11834},\n year
      = {2022}\n}\n"}, "authors": [{"authorId": "1969092", "name": "A. Yakary\u0131lmaz"}]},
      {"paperId": "74d06c6a1c56d7bc819d057623d381edf9346736", "externalIds": {"ArXiv":
      "2207.05700", "DBLP": "journals/corr/abs-2207-05700", "DOI": "10.48550/arXiv.2207.05700",
      "CorpusId": 250450880}, "corpusId": 250450880, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/74d06c6a1c56d7bc819d057623d381edf9346736",
      "title": "Turing Machines cannot simulate the human mind", "abstract": "Can
      a Turing Machine simulate the human mind? If the Church-Turing thesis is assumed
      to be true, then a Turing Machine should be able to simulate the human mind.
      In this paper, I challenge that assumption by providing strong mathematical
      arguments against the Church-Turing thesis. First, I show that there are decision
      problems that are computable for humans, but uncomputable for Turing Machines.
      Next, using a thought experiment I show that a humanoid robot equipped with
      a Turing Machine as the control unit cannot perform all humanly doable physical
      tasks. Finally, I show that a quantum mechanical computing device involving
      sequential quantum wave function collapse can compute sequences that are uncomputable
      for Turing Machines. These results invalidate the Church-Turing thesis and lead
      to the conclusion that the human mind cannot be simulated by a Turing Machine.
      Connecting these results, I argue that quantum effects in the human brain are
      fundamental to the computing abilities of the human mind.", "venue": "arXiv.org",
      "year": 2022, "referenceCount": 26, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "http://arxiv.org/pdf/2207.05700",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Philosophy",
      "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2022-06-18", "journal":
      {"name": "ArXiv", "volume": "abs/2207.05700"}, "citationStyles": {"bibtex":
      "@Article{Muraleedharan2022TuringMC,\n author = {Abhinav Muraleedharan},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {Turing Machines cannot simulate
      the human mind},\n volume = {abs/2207.05700},\n year = {2022}\n}\n"}, "authors":
      [{"authorId": "2175779537", "name": "Abhinav Muraleedharan"}]}, {"paperId":
      "246810f567b3e49164b1ffdedc911d6af0d1b144", "externalIds": {"DBLP": "journals/corr/abs-2206-06419",
      "ArXiv": "2206.06419", "DOI": "10.48550/arXiv.2206.06419", "CorpusId": 249642563},
      "corpusId": 249642563, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/246810f567b3e49164b1ffdedc911d6af0d1b144",
      "title": "A Relative Church-Turing-Deutsch Thesis from Special Relativity and
      Undecidability", "abstract": "Beginning with Turing\u2019s seminal work in 1950,
      arti\ufb01cial intelligence pro-poses that consciousness can be simulated by
      a Turing machine. This implies a potential theory of everything where the universe
      is a simulation on a computer, which begs the question of whether we can prove
      we exist in a simulation. In this work, we construct a relative model of computation
      where a computable local machine is simulated by a global , classical Turing
      machine. We show that the problem of the local machine computing simulation
      properties of its global simulator is undecidable in the same sense as the Halting
      problem. Then, we show that computing the time, space, or error accumulated
      by the global simulator are simulation properties and therefore are undecidable.
      These simulation properties give rise to special relativistic e\ufb00ects in
      the relative model which we use to construct a relative Church-Turing-Deutsch
      thesis where a global, classical Turing machine computes quantum mechanics for
      a local machine with the same constant-time local computational complexity as
      experienced in our universe.", "venue": "arXiv.org", "year": 2022, "referenceCount":
      18, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true,
      "openAccessPdf": {"url": "https://arxiv.org/pdf/2206.06419", "status": "GREEN"},
      "fieldsOfStudy": ["Computer Science", "Physics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Physics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category":
      "Philosophy", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2022-06-13", "journal": {"name": "ArXiv", "volume": "abs/2206.06419"},
      "citationStyles": {"bibtex": "@Article{Wilson2022ARC,\n author = {Blake A. Wilson
      and Ethan Dickey and Vaishnavi Iyer and S. Kais},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {A Relative Church-Turing-Deutsch Thesis from Special
      Relativity and Undecidability},\n volume = {abs/2206.06419},\n year = {2022}\n}\n"},
      "authors": [{"authorId": "2142506804", "name": "Blake A. Wilson"}, {"authorId":
      "2043408800", "name": "Ethan Dickey"}, {"authorId": "2170169648", "name": "Vaishnavi
      Iyer"}, {"authorId": "1699217", "name": "S. Kais"}]}, {"paperId": "335094aecbee9a8fabec0a1aa680ac411c88b596",
      "externalIds": {"DBLP": "journals/corr/abs-2206-14672", "DOI": "10.48550/arXiv.2206.14672",
      "CorpusId": 250113617}, "corpusId": 250113617, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/335094aecbee9a8fabec0a1aa680ac411c88b596",
      "title": "Is it possible not to cheat on the Turing Test: Exploring the potential
      and challenges for true natural language ''understanding'' by computers", "abstract":
      "The increasing sophistication of NLP models has renewed optimism regarding
      machines achieving a full human-like command of natural language. Whilst work
      in NLP/NLU may have made great strides in that direction, the lack of conceptual
      clarity in how \u2018understanding\u2019 is used in this and other disciplines
      have made it difficult to discern how close we actually are. A critical, interdisciplinary
      review of current approaches and remaining challenges is yet to be carried out.
      Beyond linguistic knowledge, this requires considering our species-specific
      capabilities to categorize, memorize, label and communicate our (sufficiently
      similar) embodied and situated experiences. Moreover, gauging the practical
      constraints requires critically analyzing the technical capabilities of current
      models, as well as deeper philosophical reflection on theoretical possibilities
      and limitations. In this paper, I unite all of these perspectives\u2014the philosophical,
      cognitive-linguistic, and technical\u2014to unpack the challenges involved in
      approaching true (human-like) language understanding. By unpacking the theoretical
      assumptions inherent in current approaches, I hope to illustrate how far we
      actually are from achieving this goal, if indeed it is the goal.", "venue":
      "arXiv.org", "year": 2022, "referenceCount": 122, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/2206.14672",
      "status": "GREEN"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Linguistics", "source": "s2-fos-model"},
      {"category": "Philosophy", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle",
      "Review"], "publicationDate": null, "journal": {"name": "ArXiv", "volume": "abs/2206.14672"},
      "citationStyles": {"bibtex": "@Article{Alberts2022IsIP,\n author = {Lize Alberts},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Is it possible not
      to cheat on the Turing Test: Exploring the potential and challenges for true
      natural language ''understanding'' by computers},\n volume = {abs/2206.14672},\n
      year = {2022}\n}\n"}, "authors": [{"authorId": "1415024767", "name": "Lize Alberts"}]},
      {"paperId": "a58f2c90fbeaca660c9ce79f41a587bef20e7698", "externalIds": {"ArXiv":
      "2106.11394", "DBLP": "journals/corr/abs-2106-11394", "CorpusId": 235593224},
      "corpusId": 235593224, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/a58f2c90fbeaca660c9ce79f41a587bef20e7698",
      "title": "A Turing Test for Transparency", "abstract": "A central goal of explainable
      artificial intelligence (XAI) is to improve the trust relationship in human-AI
      interaction. One assumption underlying research in transparent AI systems is
      that explanations help to better assess predictions of machine learning (ML)
      models, for instance by enabling humans to identify wrong predictions more efficiently.
      Recent empirical evidence however shows that explanations can have the opposite
      effect: When presenting explanations of ML predictions humans often tend to
      trust ML predictions even when these are wrong. Experimental evidence suggests
      that this effect can be attributed to how intuitive, or human, an AI or explanation
      appears. This effect challenges the very goal of XAI and implies that responsible
      usage of transparent AI methods has to consider the ability of humans to distinguish
      machine generated from human explanations. Here we propose a quantitative metric
      for XAI methods based on Turing''s imitation game, a Turing Test for Transparency.
      A human interrogator is asked to judge whether an explanation was generated
      by a human or by an XAI method. Explanations of XAI methods that can not be
      detected by humans above chance performance in this binary classification task
      are passing the test. Detecting such explanations is a requirement for assessing
      and calibrating the trust relationship in human-AI interaction. We present experimental
      results on a crowd-sourced text classification task demonstrating that even
      for basic ML models and XAI approaches most participants were not able to differentiate
      human from machine generated explanations. We discuss ethical and practical
      implications of our results for applications of transparent ML.", "venue": "arXiv.org",
      "year": 2021, "referenceCount": 10, "citationCount": 4, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Philosophy",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2021-06-21", "journal": {"name": "ArXiv", "volume": "abs/2106.11394"}, "citationStyles":
      {"bibtex": "@Article{Biessmann2021ATT,\n author = {F. Biessmann and Viktor Treu},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A Turing Test for Transparency},\n
      volume = {abs/2106.11394},\n year = {2021}\n}\n"}, "authors": [{"authorId":
      "2170760", "name": "F. Biessmann"}, {"authorId": "2114421985", "name": "Viktor
      Treu"}]}, {"paperId": "4ab14b6585f85c2121ba5d3900e8c8d00fb80dfe", "externalIds":
      {"DBLP": "journals/corr/abs-2101-10907", "ArXiv": "2101.10907", "CorpusId":
      231709582}, "corpusId": 231709582, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/4ab14b6585f85c2121ba5d3900e8c8d00fb80dfe",
      "title": "Exploring Rulial Space: The Case of Turing Machines", "abstract":
      "As an example of the concept of rulial space, we explore the case of simple
      Turing machines. We construct the rulial multiway graph which represents the
      behavior of all possible Turing machines with a certain class of rules. This
      graph (which is a Cayley graph of a \u201cTuring machine group\u201d) gives
      a map of the space of non\u2010deterministic Turing machines. We investigate
      the subgraph formed by deterministic machines, and explore the relationship
      to the P vs. NP problem. We also consider the implications of features of rulial
      space for physics, including estimating the maximum speed \u03c1 in rulial space,
      relations between rulial black holes and computational reducibility, and interpretations
      of hypercomputation.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      0, "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Physics",
      "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2021-01-22", "journal": {"name": "ArXiv",
      "volume": "abs/2101.10907"}, "citationStyles": {"bibtex": "@Article{Wolfram2021ExploringRS,\n
      author = {S. Wolfram},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title
      = {Exploring Rulial Space: The Case of Turing Machines},\n volume = {abs/2101.10907},\n
      year = {2021}\n}\n"}, "authors": [{"authorId": "143898851", "name": "S. Wolfram"}]},
      {"paperId": "18f7745ee7f7e8849d6d8250ad9d2d5e72661006", "externalIds": {"DBLP":
      "journals/corr/abs-2110-06211", "CorpusId": 239049903}, "corpusId": 239049903,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/18f7745ee7f7e8849d6d8250ad9d2d5e72661006",
      "title": "Diagonalization of Polynomial-Time Turing Machines Via Nondeterministic
      Turing Machine", "abstract": "\u2217 This work is a merger of arXiv:2110.06211
      and arXiv:2112.03677 \u2020 E-mail: The diagonalization technique was invented
      by Georg Cantor to show that there are more real numbers than algebraic numbers,
      and is very important in computer science. In this work, we enumerate all polynomial-time
      deterministic Turing machines and diagonalize over all of them by an universal
      nondeterministic Turing machine. As a result, we obtain that there is a language
      L d not accepted by any polynomial-time deterministic Turing machines but accepted
      by a nondeterministic Turing machine working within O ( n k ) for any k \u2208
      N 1 . By this, we further show that L d \u2208 N P . That is, we present a proof
      that P and N P di\ufb00er.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      39, "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal":
      {"name": "ArXiv", "volume": "abs/2110.06211"}, "citationStyles": {"bibtex":
      "@Article{Lin2021DiagonalizationOP,\n author = {Tianrong Lin},\n booktitle =
      {arXiv.org},\n journal = {ArXiv},\n title = {Diagonalization of Polynomial-Time
      Turing Machines Via Nondeterministic Turing Machine},\n volume = {abs/2110.06211},\n
      year = {2021}\n}\n"}, "authors": [{"authorId": "2325834", "name": "Tianrong
      Lin"}]}, {"paperId": "574cddb0d56fa84708b259dcd2d81473b810e7ad", "externalIds":
      {"DBLP": "journals/corr/abs-2104-08231", "ArXiv": "2104.08231", "CorpusId":
      233289893}, "corpusId": 233289893, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/574cddb0d56fa84708b259dcd2d81473b810e7ad",
      "title": "An Adversarially-Learned Turing Test for Dialog Generation Models",
      "abstract": "The design of better automated dialogue evaluation metrics offers
      the potential of accelerate evaluation research on conversational AI. However,
      existing trainable dialogue evaluation models are generally restricted to classifiers
      trained in a purely supervised manner, which suffer a significant risk from
      adversarial attacking (e.g., a nonsensical response that enjoys a high classification
      score). To alleviate this risk, we propose an adversarial training approach
      to learn a robust model, ATT (Adversarial Turing Test), that discriminates machine-generated
      responses from human-written replies. In contrast to previous perturbation-based
      methods, our discriminator is trained by iteratively generating unrestricted
      and diverse adversarial examples using reinforcement learning. The key benefit
      of this unrestricted adversarial training approach is allowing the discriminator
      to improve robustness in an iterative attack-defense game. Our discriminator
      shows high accuracy on strong attackers including DialoGPT and GPT-3.", "venue":
      "arXiv.org", "year": 2021, "referenceCount": 38, "citationCount": 1, "influentialCitationCount":
      1, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2021-04-16", "journal": {"name": "ArXiv",
      "volume": "abs/2104.08231"}, "citationStyles": {"bibtex": "@Article{Gao2021AnAT,\n
      author = {Xiang Gao and Yizhe Zhang and Michel Galley and Bill Dolan},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {An Adversarially-Learned Turing
      Test for Dialog Generation Models},\n volume = {abs/2104.08231},\n year = {2021}\n}\n"},
      "authors": [{"authorId": "71886367", "name": "Xiang Gao"}, {"authorId": "48378494",
      "name": "Yizhe Zhang"}, {"authorId": "1947267", "name": "Michel Galley"}, {"authorId":
      "66648221", "name": "Bill Dolan"}]}, {"paperId": "a9449bf585120b910cff9e98a7d60d853581a255",
      "externalIds": {"DBLP": "journals/corr/abs-2112-02152", "ArXiv": "2112.02152",
      "CorpusId": 237209912}, "corpusId": 237209912, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/a9449bf585120b910cff9e98a7d60d853581a255",
      "title": "A reliable Turing machine", "abstract": "We consider computations
      of a Turing machine subjected to noise. In every step, the action (the new state
      and the new content of the observed cell, the direction of the head movement)
      can di\ufb00er from that prescribed by the transition function with a small
      probability (independently of previous such events). We construct a universal
      1-tape Turing machine that in such noise with a low enough (constant) noise
      probability bound, performs arbitrarily large computations. For this unavoidably,
      the input needs to be encoded\u2014by a simple code depending on its size. The
      work uses a technique familiar from reliable cellular automata, complemented
      by some new ones.", "venue": "arXiv.org", "year": 2021, "referenceCount": 12,
      "citationCount": 1, "influentialCitationCount": 1, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2021-12-03", "journal":
      {"name": "ArXiv", "volume": "abs/2112.02152"}, "citationStyles": {"bibtex":
      "@Article{\u00c7apuni2021ART,\n author = {Ilir \u00c7apuni and P. G\u00e1cs},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A reliable Turing machine},\n
      volume = {abs/2112.02152},\n year = {2021}\n}\n"}, "authors": [{"authorId":
      "1746115", "name": "Ilir \u00c7apuni"}, {"authorId": "1712160", "name": "P.
      G\u00e1cs"}]}, {"paperId": "4df2147a463d6ed21aeb5bcb7a969da857ce6699", "externalIds":
      {"DBLP": "journals/corr/abs-2101-02203", "ArXiv": "2101.02203", "DOI": "10.32604/jqc.2020.014586",
      "CorpusId": 230800696}, "corpusId": 230800696, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/4df2147a463d6ed21aeb5bcb7a969da857ce6699",
      "title": "Translation of Quantum Circuits into Quantum Turing Machines for Deutsch
      and Deutsch-Jozsa Problems", "abstract": "We want in this article to show the
      usefulness of Quantum Turing Machine (QTM) in a high-level didactic context
      as well as in theoretical studies. We use QTM to show its equivalence with quantum
      circuit model for Deutsch and Deutsch-Jozsa algorithms. Further we introduce
      a strategy of translation from Quantum Circuit to Quantum Turing models by these
      examples. Moreover we illustrate some features of Quantum Computing such as
      superposition from a QTM point of view and starting with few simple examples
      very known in Quantum Circuit form.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      13, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": true,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Physics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Physics",
      "source": "external"}, {"category": "Computer Science", "source": "s2-fos-model"},
      {"category": "Physics", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2021-01-06", "journal": {"name": "ArXiv", "volume": "abs/2101.02203"}, "citationStyles":
      {"bibtex": "@Article{Corrente2021TranslationOQ,\n author = {Giuseppe Corrente},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Translation of Quantum
      Circuits into Quantum Turing Machines for Deutsch and Deutsch-Jozsa Problems},\n
      volume = {abs/2101.02203},\n year = {2021}\n}\n"}, "authors": [{"authorId":
      "35058013", "name": "Giuseppe Corrente"}]}, {"paperId": "bb1fe9432657a641635fa745de9fc0d1f22316ac",
      "externalIds": {"ArXiv": "2110.02279", "DBLP": "journals/corr/abs-2110-02279",
      "CorpusId": 238408146}, "corpusId": 238408146, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/bb1fe9432657a641635fa745de9fc0d1f22316ac",
      "title": "Turing approximations, toric isometric embeddings & manifold convolutions",
      "abstract": "Convolutions are fundamental elements in deep learning architectures.
      Here, we present a theoretical framework for combining extrinsic and intrinsic
      approaches to manifold convolution through isometric embeddings into tori. In
      this way, we define a convolution operator for a manifold of arbitrary topology
      and dimension. We also explain geometric and topological conditions that make
      some local definitions of convolutions which rely on translating filters along
      geodesic paths on a manifold, computationally intractable. A result of Alan
      Turing from 1938 underscores the need for such a toric isometric embedding approach
      to achieve a global definition of convolution on computable, finite metric space
      approximations to a smooth manifold.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      61, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Mathematics"],
      "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2021-10-05", "journal":
      {"name": "ArXiv", "volume": "abs/2110.02279"}, "citationStyles": {"bibtex":
      "@Article{Su''arez-Serrato2021TuringAT,\n author = {P. Su''arez-Serrato},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Turing approximations,
      toric isometric embeddings & manifold convolutions},\n volume = {abs/2110.02279},\n
      year = {2021}\n}\n"}, "authors": [{"authorId": "2066256143", "name": "P. Su''arez-Serrato"}]},
      {"paperId": "b910f67b8c2b2041c266305511e8a65a7c832b55", "externalIds": {"DBLP":
      "journals/corr/abs-2110-06119", "ArXiv": "2110.06119", "CorpusId": 238634713},
      "corpusId": 238634713, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/b910f67b8c2b2041c266305511e8a65a7c832b55",
      "title": "The Turing machine of a harmonic oscillator: from the code to the
      dynamic system", "abstract": "In this work we consider a dynamic system consisting
      of a damped harmonic oscillator and we formalize a Turing Machine whose definition
      in terms of states, alphabet and transition rules, can be considered equivalent
      to that of the oscillator. We prove that the Turing Machine of a FOR loop corresponds
      to that of the oscillator and we ask ourselves if it is possible to obtain the
      dynamic system of the harmonic oscillator as a physical realization of the FOR
      loop. We discuss the relationship between the results found and the science
      of Can and Can\u2019t. We discuss the possibility of an evolution of computer
      science also towards non-computerized specialized machines whose operating principle
      is designed as an automatic process starting from a source code instead of as
      a work of human ingenuity. The approach to the implementation of algorithms
      in dynamic systems instead of universal computers can be particularly interesting
      for the field of both diagnostic and implantable medical devices.", "venue":
      "arXiv.org", "year": 2021, "referenceCount": 10, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Physics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
      "external"}, {"category": "Physics", "source": "external"}, {"category": "Physics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2021-10-01", "journal": {"name": "ArXiv", "volume": "abs/2110.06119"}, "citationStyles":
      {"bibtex": "@Article{Sisini2021TheTM,\n author = {F. Sisini and Valentina Sisini},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {The Turing machine
      of a harmonic oscillator: from the code to the dynamic system},\n volume = {abs/2110.06119},\n
      year = {2021}\n}\n"}, "authors": [{"authorId": "3358162", "name": "F. Sisini"},
      {"authorId": "2132056040", "name": "Valentina Sisini"}]}, {"paperId": "37c37255fcdfea3dc18cb360f3c27643710ae072",
      "externalIds": {"DBLP": "journals/corr/abs-2110-01415", "ArXiv": "2110.01415",
      "CorpusId": 238259586}, "corpusId": 238259586, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/37c37255fcdfea3dc18cb360f3c27643710ae072",
      "title": "Compiling Turing Machines into Storage Modification Machines", "abstract":
      "It is well known that Sch\\\"onhage''s Storage Modification Machines (SMM)
      can simulate Turing Machines (TM) since Sch\\\"onhage''s original proof of the
      Turing completeness of the eponymous machines. We propose a simple transformation
      of TM into SMM, setting the base for a straightforward TM-to-SMM compiler.",
      "venue": "arXiv.org", "year": 2021, "referenceCount": 7, "citationCount": 1,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2021-09-28", "journal": {"name": "ArXiv", "volume": "abs/2110.01415"}, "citationStyles":
      {"bibtex": "@Article{Chauvet2021CompilingTM,\n author = {J. Chauvet},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {Compiling Turing Machines into
      Storage Modification Machines},\n volume = {abs/2110.01415},\n year = {2021}\n}\n"},
      "authors": [{"authorId": "34795986", "name": "J. Chauvet"}]}, {"paperId": "040c88bc1ed507c42d995d45b545ab86205ef1c4",
      "externalIds": {"ArXiv": "2112.03677", "DBLP": "journals/corr/abs-2112-03677",
      "CorpusId": 244920640}, "corpusId": 244920640, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/040c88bc1ed507c42d995d45b545ab86205ef1c4",
      "title": "On Baker-Gill-Solovay Oracle Turing Machines and Relativization Barrier",
      "abstract": "This work analyses the so-called\"Relativization Barrier\"with
      respect to the Baker-Gill-Solovay oracle Turing machine. We show that the {\\em
      diagonalization} technique is a valid mathematical proof technique, but it has
      some prerequisites when referring to the\"relativization barrier.\"", "venue":
      "arXiv.org", "year": 2021, "referenceCount": 22, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2021-12-07", "journal": {"name": "ArXiv", "volume": "abs/2112.03677"}, "citationStyles":
      {"bibtex": "@Article{Lin2021OnBO,\n author = {Tianrong Lin},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {On Baker-Gill-Solovay Oracle Turing Machines and
      Relativization Barrier},\n volume = {abs/2112.03677},\n year = {2021}\n}\n"},
      "authors": [{"authorId": "2325834", "name": "Tianrong Lin"}]}, {"paperId": "cbddbb34da264c489eb307f49143044fae3a785a",
      "externalIds": {"ArXiv": "2110.03279", "DBLP": "journals/corr/abs-2110-03279",
      "CorpusId": 238419398}, "corpusId": 238419398, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/cbddbb34da264c489eb307f49143044fae3a785a",
      "title": "Polynomial Turing Kernels for Clique with an Optimal Number of Queries",
      "abstract": "A polynomial Turing kernel for some parameterized problem P is
      a polynomial-time algorithm that solves P using queries to an oracle of P whose
      sizes are upper-bounded by some polynomial in the parameter. Here the term \u201cpolynomial\u201d
      refers to the bound on the query sizes, as the running time of any kernel is
      required to be polynomial. One of the most important open goals in parameterized
      complexity is to understand the applicability and limitations of polynomial
      Turing Kernels. As any fixed-parameter tractable problem admits a Turing kernel
      of some size, the focus has mostly being on determining which problems admit
      such kernels whose query sizes can be indeed bounded by some polynomial. In
      this paper we take a different approach, and instead focus on the number of
      queries that a Turing kernel uses, assuming it is restricted to using only polynomial
      sized queries. Our study focuses on one the main problems studied in parameterized
      complexity, the Clique problem: Given a graph G and an integer k, determine
      whether there are k pairwise adjacent vertices in G. We show that Clique parameterized
      by several structural parameters exhibits the following phenomena: \u2022 It
      admits polynomial Turing kernels which use a sublinear number of queries, namely
      O(n/ log(n)) queries where n is the total size of the graph and c is any constant.
      This holds even for a very restrictive type of Turing kernels which we call
      OR-kernels. \u2022 It does not admit polynomial Turing kernels which use O(n)
      queries, unless NP \u2286 coNP / poly. For proving the second item above, we
      develop a new framework for bounding the number of queries needed by polynomial
      Turing kernels. This framework is inspired by the standard lower bounds framework
      for Karp kernels, and while it is quite similar, it still requires some novel
      ideas to allow its extension to the Turing setting.", "venue": "arXiv.org",
      "year": 2021, "referenceCount": 27, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "s2-fos-model"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2021-10-07", "journal": {"name": "ArXiv", "volume": "abs/2110.03279"},
      "citationStyles": {"bibtex": "@Article{Fluschnik2021PolynomialTK,\n author =
      {T. Fluschnik and Klaus Heeger and D. Hermelin},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {Polynomial Turing Kernels for Clique with an Optimal
      Number of Queries},\n volume = {abs/2110.03279},\n year = {2021}\n}\n"}, "authors":
      [{"authorId": "1866810", "name": "T. Fluschnik"}, {"authorId": "35676871", "name":
      "Klaus Heeger"}, {"authorId": "1736630", "name": "D. Hermelin"}]}, {"paperId":
      "58f3f0d11ddfd2243d64f9bf1abb761abda2a131", "externalIds": {"DBLP": "journals/corr/abs-2103-14013",
      "ArXiv": "2103.14013", "CorpusId": 232352473}, "corpusId": 232352473, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/58f3f0d11ddfd2243d64f9bf1abb761abda2a131",
      "title": "Set Turing Machines", "abstract": "In this paper we define a notion
      of Turing computability for class functions, i.e., functions that operate on
      arbitrary sets. We generalize the notion of a Turing machine to the set Turing
      machine. Set Turing machines operate on a class size tape. We represent sets
      by placing marks in the cells of the set Turing machine tape. Instead of being
      indexed by N or Z, the tapes cells are indexed by finite sequences of ordinals.
      For a marking of the cells to represent a set, the markings have the structure
      of a tree which mirrors the transitive closure of the set. Our conception depends
      on both the Axiom of Choice and the Axiom of Foundation. Representations of
      sets as marks on the set Turing machine tape exist by the Axiom of Choice. The
      representations are well founded by the Axiom of Foundation. Using the concepts
      of the set Turing machines and the encoding of sets by marks on the set Turing
      machine tape, we define the Turing computable class functions denoted TUR. We
      also define the collection of recursive class functions, REC, a generalization
      of the primitive recursive set functions as defined in [JK]. The class functions
      in REC are analogous to the recursive functions on N. We will prove some elementary
      properties about REC. In the last section we prove our main theorem that TUR
      = REC.", "venue": "arXiv.org", "year": 2021, "referenceCount": 3, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category":
      "Mathematics", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2021-03-25", "journal": {"name": "ArXiv", "volume": "abs/2103.14013"},
      "citationStyles": {"bibtex": "@Article{Melles2021SetTM,\n author = {Garvin Melles},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Set Turing Machines},\n
      volume = {abs/2103.14013},\n year = {2021}\n}\n"}, "authors": [{"authorId":
      "2933043", "name": "Garvin Melles"}]}, {"paperId": "39512882e97addfc5fbc1c733ff8494362041a2c",
      "externalIds": {"DBLP": "journals/corr/abs-2104-07454", "CorpusId": 233241236},
      "corpusId": 233241236, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/39512882e97addfc5fbc1c733ff8494362041a2c",
      "title": "Memory Capacity of Neural Turing Machines with Matrix Representation",
      "abstract": "It is well known that recurrent neural networks (RNNs) faced limitations
      in learning longterm dependencies that have been addressed by memory structures
      in long short-term memory (LSTM) networks. Matrix neural networks feature matrix
      representation which inherently preserves the spatial structure of data and
      has the potential to provide better memory structures when compared to canonical
      neural networks that use vector representation. Neural Turing machines (NTMs)
      are novel RNNs that implement notion of programmable computers with neural network
      controllers to feature algorithms that have copying, sorting, and associative
      recall tasks. In this paper, we study augmentation of memory capacity with matrix
      representation of RNNs and NTMs (MatNTMs). We investigate if matrix representation
      has a better memory capacity than the vector representations in conventional
      neural networks. We use a probabilistic model of the memory capacity using Fisher
      information and investigate how the memory capacity for matrix representation
      networks are limited under various constraints, and in general, without any
      constraints. In the case of memory capacity without any constraints, we found
      that the upper bound on memory capacity to be N for an N\u00d7N state matrix.
      The results from our experiments using synthetic algorithmic tasks show that
      MatNTMs have a better learning capacity when compared to its counterparts.",
      "venue": "arXiv.org", "year": 2021, "referenceCount": 49, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      null, "journal": {"name": "ArXiv", "volume": "abs/2104.07454"}, "citationStyles":
      {"bibtex": "@Article{Renanse2021MemoryCO,\n author = {Animesh Renanse and Rohitash
      Chandra and Alok Sharma},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Memory Capacity of Neural Turing Machines with Matrix Representation},\n
      volume = {abs/2104.07454},\n year = {2021}\n}\n"}, "authors": [{"authorId":
      "2077430207", "name": "Animesh Renanse"}, {"authorId": "38743363", "name": "Rohitash
      Chandra"}, {"authorId": "2109552408", "name": "Alok Sharma"}]}, {"paperId":
      "314e76f1df702702cc2de8661caebab1beb5a32d", "externalIds": {"ArXiv": "2112.13345",
      "DBLP": "journals/corr/abs-2112-13345", "CorpusId": 245502188}, "corpusId":
      245502188, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/314e76f1df702702cc2de8661caebab1beb5a32d",
      "title": "Resource dependent undecidability: computability landscape of distinct
      Turing theories", "abstract": "Can a problem undecidable with classical resources
      be decidable with quantum ones? The answer expected is no; as both being Turing
      theories, they should not solve the Halting problem - a problem unsolvable by
      any Turing machine. Yet, we provide an affirmative answer to the aforesaid question.
      We come up with a novel logical structure to formulate infinitely many such
      problems for any pair of distinct Turing theories, including but not limited
      to the classical and quantum theories. Importantly, a class of other decision
      problems, such as the Halting one, remains unsolvable in all those theories.
      The apparent paradoxical situation gets resolved once it is perceived that the
      reducibility of Halting problem changes with varying resources available for
      computations in different theories. In the end, we propose a multi-agent game
      where winnability of the player having access to only classical resources is
      undecidable while quantum resources provide a perfect winning strategy.", "venue":
      "arXiv.org", "year": 2021, "referenceCount": 39, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Physics", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Physics", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2021-12-26", "journal": {"name": "ArXiv", "volume": "abs/2112.13345"}, "citationStyles":
      {"bibtex": "@Article{Antony2021ResourceDU,\n author = {Airin Antony},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {Resource dependent undecidability:
      computability landscape of distinct Turing theories},\n volume = {abs/2112.13345},\n
      year = {2021}\n}\n"}, "authors": [{"authorId": "2048120813", "name": "Airin
      Antony"}]}, {"paperId": "bca2348d548194beb6134b337ac57d861cc4a3a6", "externalIds":
      {"ArXiv": "2104.05636", "DBLP": "journals/corr/abs-2104-05636", "CorpusId":
      233210618}, "corpusId": 233210618, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/bca2348d548194beb6134b337ac57d861cc4a3a6",
      "title": "What Kind of Person Wins the Turing Award?", "abstract": "Computer
      science has grown rapidly since its inception in the 1950s and the pioneers
      in the field are celebrated annually by the A.M. Turing Award. In this paper,
      we attempt to shed light on the path to influential computer scientists by examining
      the characteristics of the 72 Turing Award laureates. To achieve this goal,
      we build a comprehensive dataset of the Turing Award laureates and analyze their
      characteristics, including their personal information, family background, academic
      background, and industry experience. The FP-Growth algorithm is used for frequent
      feature mining. Logistic regression plot, pie chart, word cloud and map are
      generated accordingly for each of the interesting features to uncover insights
      regarding personal factors that drive influential work in the field of computer
      science. In particular, we show that the Turing Award laureates are most commonly
      white, male, married, United States citizen, and received a PhD degree. Our
      results also show that the age at which the laureate won the award increases
      over the years; most of the Turing Award laureates did not major in computer
      science; birth order is strongly related to the winners'' success; and the number
      of citations is not as important as one would expect.", "venue": "arXiv.org",
      "year": 2021, "referenceCount": 31, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2021-04-04", "journal": {"name": "ArXiv",
      "volume": "abs/2104.05636"}, "citationStyles": {"bibtex": "@Article{Shangguan2021WhatKO,\n
      author = {Zhongkai Shangguan and Zihe Zheng and Jiebo Luo},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {What Kind of Person Wins the Turing Award?},\n
      volume = {abs/2104.05636},\n year = {2021}\n}\n"}, "authors": [{"authorId":
      "1850415250", "name": "Zhongkai Shangguan"}, {"authorId": "2109675164", "name":
      "Zihe Zheng"}, {"authorId": "2116783457", "name": "Jiebo Luo"}]}, {"paperId":
      "1d6b35c73bcdbe0a55de3ce5d9b8a5edf3ca1a58", "externalIds": {"ArXiv": "2112.13205",
      "DBLP": "journals/corr/abs-2112-13205", "CorpusId": 245502640}, "corpusId":
      245502640, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/1d6b35c73bcdbe0a55de3ce5d9b8a5edf3ca1a58",
      "title": "New Computing Model of GNeTM Turing Machine On Solving Even Goldbach
      Conjecture", "abstract": "Based on the propositional description of even Goldbach
      conjecture, in order to verify the truth of even Goldbach conjecture, we will
      deeply discuss this question and present a new computing model of GNeT M Turing
      Machine. This paper proves the infinite existence of even Goldbach\u2019s conjecture
      and obtains the following new results: 1. The criterion of general probability
      speculation of the existence judgment for even Goldbach conjecture is studied,
      and which at least have a formula satisfy the deduction result of matching requirements
      for even Goldbach conjecture in the model mod \u2261 M (Ne). 2. In the controller
      of the GNeT M model, the algorithm problem of the prime matching rule is given,
      regardless of whether the computer can be recursively solved, the rule algorithm
      for designing prime numbers in controllers is computer recursively solvable.
      3. The judgment problem that about even Goldbach conjecture whether infinite
      existence is studied. The new research result has shown that according to the
      constitution model of the full arranged matrix of given even number Ne, and
      if only given an even number Ne, it certainly exists the matrix model Mod \u2261
      X (p) and is proved to be equivalent. Therefore, it proves indirectly that the
      model GNeT M does not exist halting problem, and it also indicate that the even
      Goldbach conjecture is infinity existence.", "venue": "arXiv.org", "year": 2021,
      "referenceCount": 18, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2021-12-25", "journal":
      {"name": "ArXiv", "volume": "abs/2112.13205"}, "citationStyles": {"bibtex":
      "@Article{Lin2021NewCM,\n author = {Bogang Lin},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {New Computing Model of GNeTM Turing Machine On
      Solving Even Goldbach Conjecture},\n volume = {abs/2112.13205},\n year = {2021}\n}\n"},
      "authors": [{"authorId": "9431824", "name": "Bogang Lin"}]}, {"paperId": "577349e25391605c0318b3583983e0f35fe5acae",
      "externalIds": {"ArXiv": "2103.04961", "DBLP": "journals/corr/abs-2103-04961",
      "CorpusId": 232147860}, "corpusId": 232147860, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/577349e25391605c0318b3583983e0f35fe5acae",
      "title": "Multiway Turing Machines", "abstract": "Multiway Turing machines (also
      known as nondeterministic Turing machines or NDTMs) with explicit, simple rules
      are studied. Even very simple rules are found to generate complex behavior,
      characterized by complex multiway graphs, that can be visualized in multispace
      that combines \u201ctape\u201d and branchial space. The threshold for complex
      behavior appears to be machines with just s = 1 head states, k = 2 tape colors
      and p = 3 possible cases, and such machines may potentially be universal. Other
      characteristics of multiway Turing machines are also studied, including causal
      invariance, cyclic tapes and generalized busy beaver problems. Multiway Turing
      machines provide minimal examples of a variety of issues encountered in both
      concurrent computing and the theory of observers in quantum mechanics, especially
      in our recent models of physics.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      0, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2021-03-08", "journal": {"name": "ArXiv", "volume": "abs/2103.04961"},
      "citationStyles": {"bibtex": "@Article{Wolfram2021MultiwayTM,\n author = {S.
      Wolfram},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Multiway
      Turing Machines},\n volume = {abs/2103.04961},\n year = {2021}\n}\n"}, "authors":
      [{"authorId": "143898851", "name": "S. Wolfram"}]}, {"paperId": "49b19576b71cc25877e341d7b7267349de3c2cca",
      "externalIds": {"ArXiv": "2105.02124", "DBLP": "journals/corr/abs-2105-02124",
      "CorpusId": 233740023}, "corpusId": 233740023, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/49b19576b71cc25877e341d7b7267349de3c2cca",
      "title": "Intrinsic Propensity for Vulnerability in Computers? Arbitrary Code
      Execution in the Universal Turing Machine", "abstract": "The universal Turing
      machine is generally considered to be the simplest, most abstract model of a
      computer. This paper reports on the discovery of an accidental arbitrary code
      execution vulnerability in Marvin Minsky''s 1967 implementation of the universal
      Turing machine. By submitting crafted data, the machine may be coerced into
      executing user-provided code. The article presents the discovered vulnerability
      in detail and discusses its potential implications. To the best of our knowledge,
      an arbitrary code execution vulnerability has not previously been reported for
      such a simple system.", "venue": "arXiv.org", "year": 2021, "referenceCount":
      18, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2021-04-22", "journal": {"name": "ArXiv", "volume": "abs/2105.02124"},
      "citationStyles": {"bibtex": "@Article{Johnson2021IntrinsicPF,\n author = {Pontus
      Johnson},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Intrinsic
      Propensity for Vulnerability in Computers? Arbitrary Code Execution in the Universal
      Turing Machine},\n volume = {abs/2105.02124},\n year = {2021}\n}\n"}, "authors":
      [{"authorId": "144124156", "name": "Pontus Johnson"}]}, {"paperId": "01baca4fa7ad5d28b95f6f72fe33de9a34633bc6",
      "externalIds": {"DBLP": "journals/corr/abs-1903-07486", "ArXiv": "1903.07486",
      "MAG": "2920798074", "CorpusId": 81981887}, "corpusId": 81981887, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/01baca4fa7ad5d28b95f6f72fe33de9a34633bc6",
      "title": "Dissecting the NVidia Turing T4 GPU via Microbenchmarking", "abstract":
      "In 2019, the rapid rate at which GPU manufacturers refresh their designs, coupled
      with their reluctance to disclose microarchitectural details, is still a hurdle
      for those software designers who want to extract the highest possible performance.
      Last year, these very reasons motivated us to dissect the Volta GPU architecture
      using microbenchmarks. \nThe introduction in August 2018 of Turing, NVidia''s
      latest architecture, pressed us to update our study. In this report, we examine
      Turing and compare it quantitatively against previous NVidia GPU generations.
      Specifically, we study the T4 GPU: a low-power board aiming at inference applications.
      We describe its improvements against its inference-oriented predecessor: the
      P4 GPU based on the Pascal architecture. Both T4 and P4 GPUs achieve significantly
      higher frequency-per-Watt figures than their full-size counterparts. \nWe study
      the performance of the T4''s TensorCores, finding a much higher throughput on
      low-precision operands than on the P4 GPU. We reveal that Turing introduces
      new instructions that express matrix math more succinctly. We map Turing''s
      instruction space, finding the same encoding as Volta, and additional instructions.
      We reveal that the Turing TU104 chip has the same memory hierarchy depth as
      the Volta GV100; cache levels sizes on the TU104 are frequently twice as large
      as those found on the Pascal GP104. We benchmark each constituent of the T4
      memory hierarchy and find substantial overall performance improvements over
      its P4 predecessor. We studied how clock throttling affects compute-intensive
      workloads that hit power or thermal limits. \nMany of our findings are novel,
      published here for the first time. All of them can guide high-performance software
      developers get closer to the GPU''s peak performance.", "venue": "arXiv.org",
      "year": 2019, "referenceCount": 8, "citationCount": 75, "influentialCitationCount":
      10, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Engineering",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2019-03-18", "journal": {"name": "ArXiv", "volume": "abs/1903.07486"}, "citationStyles":
      {"bibtex": "@Article{Jia2019DissectingTN,\n author = {Zhe Jia and Marco Maggioni
      and Jeffrey K. Smith and D. Scarpazza},\n booktitle = {arXiv.org},\n journal
      = {ArXiv},\n title = {Dissecting the NVidia Turing T4 GPU via Microbenchmarking},\n
      volume = {abs/1903.07486},\n year = {2019}\n}\n"}, "authors": [{"authorId":
      "48813086", "name": "Zhe Jia"}, {"authorId": "138304679", "name": "Marco Maggioni"},
      {"authorId": "2109849147", "name": "Jeffrey K. Smith"}, {"authorId": "3277273",
      "name": "D. Scarpazza"}]}, {"paperId": "79bae31ed966a7a97dbea7292e17fa6274122100",
      "externalIds": {"DBLP": "journals/corr/abs-2305-20010", "ArXiv": "2305.20010",
      "DOI": "10.48550/arXiv.2305.20010", "CorpusId": 258987666}, "corpusId": 258987666,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/79bae31ed966a7a97dbea7292e17fa6274122100",
      "title": "Human or Not? A Gamified Approach to the Turing Test", "abstract":
      "We present\"Human or Not?\", an online game inspired by the Turing test, that
      measures the capability of AI chatbots to mimic humans in dialog, and of humans
      to tell bots from other humans. Over the course of a month, the game was played
      by over 1.5 million users who engaged in anonymous two-minute chat sessions
      with either another human or an AI language model which was prompted to behave
      like humans. The task of the players was to correctly guess whether they spoke
      to a person or to an AI. This largest scale Turing-style test conducted to date
      revealed some interesting facts. For example, overall users guessed the identity
      of their partners correctly in only 68% of the games. In the subset of the games
      in which users faced an AI bot, users had even lower correct guess rates of
      60% (that is, not much higher than chance). This white paper details the development,
      deployment, and results of this unique experiment. While this experiment calls
      for many extensions and refinements, these findings already begin to shed light
      on the inevitable near future which will commingle humans and AI.", "venue":
      "arXiv.org", "year": 2023, "referenceCount": 7, "citationCount": 3, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "http://arxiv.org/pdf/2305.20010",
      "status": "CLOSED"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2023-05-31", "journal": {"name": "ArXiv", "volume": "abs/2305.20010"},
      "citationStyles": {"bibtex": "@Article{Jannai2023HumanON,\n author = {Daniel
      Jannai and Amos Meron and Barak Lenz and Yoav Levine and Y. Shoham},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {Human or Not? A Gamified Approach
      to the Turing Test},\n volume = {abs/2305.20010},\n year = {2023}\n}\n"}, "authors":
      [{"authorId": "2090357207", "name": "Daniel Jannai"}, {"authorId": "2218579362",
      "name": "Amos Meron"}, {"authorId": "1412384990", "name": "Barak Lenz"}, {"authorId":
      "152754428", "name": "Yoav Levine"}, {"authorId": "1701353", "name": "Y. Shoham"}]},
      {"paperId": "3452746bfda18dd59dad9ce5a5802f721a10a4d4", "externalIds": {"ArXiv":
      "2304.04498", "DBLP": "journals/corr/abs-2304-04498", "DOI": "10.48550/arXiv.2304.04498",
      "CorpusId": 258049252}, "corpusId": 258049252, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/3452746bfda18dd59dad9ce5a5802f721a10a4d4",
      "title": "Towards Digital Nature: Bridging the Gap between Turing Machine Objects
      and Linguistic Objects in LLMMs for Universal Interaction of Object-Oriented
      Descriptions", "abstract": "In this paper, we propose a novel approach to establish
      a connection between linguistic objects and classes in Large Language Model
      Machines (LLMMs) such as GPT3.5 and GPT4, and their counterparts in high level
      programming languages like Python. Our goal is to promote the development of
      Digital Nature: a worldview where digital and physical realities are seamlessly
      intertwined and can be easily manipulated by computational means. To achieve
      this, we exploit the inherent abstraction capabilities of LLMMs to build a bridge
      between human perception of the real world and the computational processes that
      mimic it. This approach enables ambiguous class definitions and interactions
      between objects to be realized in programming and ubiquitous computing scenarios.
      By doing so, we aim to facilitate seamless interaction between Turing Machine
      objects and Linguistic Objects, paving the way for universally accessible object
      oriented descriptions. We demonstrate a method for automatically transforming
      real world objects and their corresponding simulations into language simulable
      worlds using LLMMs, thus advancing the digital twin concept. This process can
      then be extended to high level programming languages, making the implementation
      of these simulations more accessible and practical. In summary, our research
      introduces a groundbreaking approach to connect linguistic objects in LLMMs
      with high level programming languages, allowing for the efficient implementation
      of real world simulations. This ultimately contributes to the realization of
      Digital Nature, where digital and physical worlds are interconnected, and objects
      and simulations can be effortlessly manipulated through computational means.",
      "venue": "arXiv.org", "year": 2023, "referenceCount": 23, "citationCount": 2,
      "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "http://arxiv.org/pdf/2304.04498", "status": "CLOSED"}, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Linguistics",
      "source": "s2-fos-model"}, {"category": "Philosophy", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-04-10", "journal":
      {"name": "ArXiv", "volume": "abs/2304.04498"}, "citationStyles": {"bibtex":
      "@Article{Ochiai2023TowardsDN,\n author = {Y. Ochiai and Naruya Kondo and Tatsuki
      Fushimi},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Towards
      Digital Nature: Bridging the Gap between Turing Machine Objects and Linguistic
      Objects in LLMMs for Universal Interaction of Object-Oriented Descriptions},\n
      volume = {abs/2304.04498},\n year = {2023}\n}\n"}, "authors": [{"authorId":
      "2059595927", "name": "Y. Ochiai"}, {"authorId": "2028904904", "name": "Naruya
      Kondo"}, {"authorId": "52567877", "name": "Tatsuki Fushimi"}]}, {"paperId":
      "0ec10eb38a72f60cac856d3341227a1a6be4cd98", "externalIds": {"DBLP": "journals/corr/abs-2305-14252",
      "ArXiv": "2305.14252", "DOI": "10.48550/arXiv.2305.14252", "CorpusId": 258841718},
      "corpusId": 258841718, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/0ec10eb38a72f60cac856d3341227a1a6be4cd98",
      "title": "Quantum Kolmogorov complexity and quantum correlations in deterministic-control
      quantum Turing machines", "abstract": "This work presents a study of Kolmogorov
      complexity for general quantum states from the perspective of deterministic-control
      quantum Turing Machines (dcq-TM). We extend the dcq-TM model to incorporate
      mixed state inputs and outputs, and define dcq-computable states as those that
      can be approximated by a dcq-TM. Moreover, we introduce (conditional) Kolmogorov
      complexity of quantum states and use it to study three particular aspects of
      the algorithmic information contained in a quantum state: a comparison of the
      information in a quantum state with that of its classical representation as
      an array of real numbers, an exploration of the limits of quantum state copying
      in the context of algorithmic complexity, and study of the complexity of correlations
      in quantum systems, resulting in a correlation-aware definition for algorithmic
      mutual information that satisfies symmetry of information property.", "venue":
      "arXiv.org", "year": 2023, "referenceCount": 38, "citationCount": 2, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "http://arxiv.org/pdf/2305.14252",
      "status": "GREEN"}, "fieldsOfStudy": ["Physics", "Computer Science", "Mathematics"],
      "s2FieldsOfStudy": [{"category": "Physics", "source": "external"}, {"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Physics", "source": "s2-fos-model"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2023-05-23", "journal": {"name": "ArXiv", "volume": "abs/2305.14252"},
      "citationStyles": {"bibtex": "@Article{Lemus2023QuantumKC,\n author = {M. Lemus
      and Ricardo Faleiro and P. Mateus and Nikola Paunkovi''c and Andr\u00e9 Souto},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Quantum Kolmogorov
      complexity and quantum correlations in deterministic-control quantum Turing
      machines},\n volume = {abs/2305.14252},\n year = {2023}\n}\n"}, "authors": [{"authorId":
      "145451615", "name": "M. Lemus"}, {"authorId": "103308544", "name": "Ricardo
      Faleiro"}, {"authorId": "144372606", "name": "P. Mateus"}, {"authorId": "2218427588",
      "name": "Nikola Paunkovi''c"}, {"authorId": "151498130", "name": "Andr\u00e9
      Souto"}]}, {"paperId": "2ca09ee92154b4480230654989a3ecec6b29ef10", "externalIds":
      {"ArXiv": "2111.05321", "DBLP": "journals/corr/abs-2111-05321", "CorpusId":
      243860726}, "corpusId": 243860726, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/2ca09ee92154b4480230654989a3ecec6b29ef10",
      "title": "Turing-Universal Learners with Optimal Scaling Laws", "abstract":
      "For a given distribution, learning algorithm, and performance metric, the rate
      of convergence (or data-scaling law) is the asymptotic behavior of the algorithm''s
      test performance as a function of number of train samples. Many learning methods
      in both theory and practice have power-law rates, i.e. performance scales as
      $n^{-\\alpha}$ for some $\\alpha>0$. Moreover, both theoreticians and practitioners
      are concerned with improving the rates of their learning algorithms under settings
      of interest. We observe the existence of a\"universal learner\", which achieves
      the best possible distribution-dependent asymptotic rate among all learning
      algorithms within a specified runtime (e.g. $O(n^2)$), while incurring only
      polylogarithmic slowdown over this runtime. This algorithm is uniform, and does
      not depend on the distribution, and yet achieves best-possible rates for all
      distributions. The construction itself is a simple extension of Levin''s universal
      search (Levin, 1973). And much like universal search, the universal learner
      is not at all practical, and is primarily of theoretical and philosophical interest.",
      "venue": "arXiv.org", "year": 2021, "referenceCount": 29, "citationCount": 1,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category":
      "Mathematics", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2021-11-09", "journal": {"name": "ArXiv", "volume": "abs/2111.05321"},
      "citationStyles": {"bibtex": "@Article{Nakkiran2021TuringUniversalLW,\n author
      = {Preetum Nakkiran},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title
      = {Turing-Universal Learners with Optimal Scaling Laws},\n volume = {abs/2111.05321},\n
      year = {2021}\n}\n"}, "authors": [{"authorId": "2181918", "name": "Preetum Nakkiran"}]},
      {"paperId": "74de8a496f9e921464044b9050f73e6b17130ca9", "externalIds": {"ArXiv":
      "2301.12556", "DBLP": "journals/corr/abs-2301-12556", "DOI": "10.48550/arXiv.2301.12556",
      "CorpusId": 256461497}, "corpusId": 256461497, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/74de8a496f9e921464044b9050f73e6b17130ca9",
      "title": "A Log-Sensitive Encoding of Turing Machines in the \u03bb-Calculus",
      "abstract": "This note modifies the reference encoding of Turing machines in
      the $\\lambda$-calculus by Dal Lago and Accattoli, which is tuned for time efficiency,
      as to accommodate logarithmic space. There are two main changes: Turing machines
      now have *two* tapes, an input tape and a work tape, and the input tape is encoded
      differently, because the reference encoding comes with a linear space overhead
      for managing tapes, which is excessive for studying logarithmic space.", "venue":
      "arXiv.org", "year": 2023, "referenceCount": 7, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "http://arxiv.org/pdf/2301.12556",
      "status": "CLOSED"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-01-29", "journal":
      {"name": "ArXiv", "volume": "abs/2301.12556"}, "citationStyles": {"bibtex":
      "@Article{Accattoli2023ALE,\n author = {Beniamino Accattoli and Ugo Dal Lago
      and G. Vanoni},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A
      Log-Sensitive Encoding of Turing Machines in the \u03bb-Calculus},\n volume
      = {abs/2301.12556},\n year = {2023}\n}\n"}, "authors": [{"authorId": "1745985",
      "name": "Beniamino Accattoli"}, {"authorId": "9127840", "name": "Ugo Dal Lago"},
      {"authorId": "41067044", "name": "G. Vanoni"}]}, {"paperId": "0cbc09097c340f3d54e30dba7347abe3129afa53",
      "externalIds": {"DBLP": "journals/corr/abs-2305-04312", "DOI": "10.48550/arXiv.2305.04312",
      "CorpusId": 258558186}, "corpusId": 258558186, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/0cbc09097c340f3d54e30dba7347abe3129afa53",
      "title": "Human or Machine: Reflections on Turing-Inspired Testing for the Everyday",
      "abstract": ": In his seminal paper \"Computing Machinery and Intelligence\",
      Alan Turing introduced the \"imitation game\" as part of exploring the concept
      of machine intelligence. The Turing Test has since been the subject of much
      analysis, debate, re\ufb01nement and extension. Here we sidestep the question
      of whether a particular machine can be labeled intelligent, or can be said to
      match human capabilities in a given context. Instead, but inspired by Turing,
      we draw attention to the seemingly simpler challenge of determining whether
      one is interacting with a human or with a machine, in the context of everyday
      life. We are interested in re\ufb02ecting upon the importance of this Human-or-Machine
      question and the use one may make of a reliable answer thereto. Whereas Turing\u2019s
      original test is widely considered to be more of a thought experiment, the Human-or-Machine
      question as discussed here has obvious practical signi\ufb01cance. And while
      the jury is still not in regarding the possibility of machines that can mimic
      human behavior with high \ufb01delity in everyday contexts, we argue that near-term
      exploration of the issues raised here can contribute to development methods
      for computerized systems, and may also improve our understanding of human behavior
      in general.", "venue": "arXiv.org", "year": 2023, "referenceCount": 42, "citationCount":
      1, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://arxiv.org/pdf/2305.04312", "status": "GREEN"}, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Philosophy",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      null, "journal": {"name": "ArXiv", "volume": "abs/2305.04312"}, "citationStyles":
      {"bibtex": "@Article{Harel2023HumanOM,\n author = {D. Harel and Assaf Marron},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Human or Machine: Reflections
      on Turing-Inspired Testing for the Everyday},\n volume = {abs/2305.04312},\n
      year = {2023}\n}\n"}, "authors": [{"authorId": "145771081", "name": "D. Harel"},
      {"authorId": "144118264", "name": "Assaf Marron"}]}, {"paperId": "2f42a30a04fa3747fc4fdc07b7793a1fcc50cb5a",
      "externalIds": {"DBLP": "journals/corr/abs-2105-05302", "CorpusId": 263896905},
      "corpusId": 263896905, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/2f42a30a04fa3747fc4fdc07b7793a1fcc50cb5a",
      "title": "Wittgenstein and Turing: Machines, Language games and Forms of life",
      "abstract": null, "venue": "arXiv.org", "year": 2021, "referenceCount": 0, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Philosophy", "source": "s2-fos-model"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": null, "journal": {"name": "ArXiv", "volume":
      "abs/2105.05302"}, "citationStyles": {"bibtex": "@Article{Bodon2021WittgensteinAT,\n
      author = {Charles Bodon},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Wittgenstein and Turing: Machines, Language games and Forms of life},\n
      volume = {abs/2105.05302},\n year = {2021}\n}\n"}, "authors": [{"authorId":
      "2257306812", "name": "Charles Bodon"}]}, {"paperId": "1ab5ef5ab882aabb392454fc6c7ee542a4b1e830",
      "externalIds": {"MAG": "3078290683", "ArXiv": "2008.07743", "DBLP": "journals/corr/abs-2008-07743",
      "CorpusId": 221151031}, "corpusId": 221151031, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/1ab5ef5ab882aabb392454fc6c7ee542a4b1e830",
      "title": "Turing Test and the Practice of Law: The Role of Autonomous Levels
      of AI Legal Reasoning", "abstract": "Artificial Intelligence (AI) is increasingly
      being applied to law and a myriad of legal tasks amid attempts to bolster AI
      Legal Reasoning (AILR) autonomous capabilities. A major question that has generally
      been unaddressed involves how we will know when AILR has achieved autonomous
      capacities. The field of AI has grappled with similar quandaries over how to
      assess the attainment of Artificial General Intelligence (AGI), a persistently
      discussed issue among scholars since the inception of AI, with the Turing Test
      communally being considered as the bellwether for ascertaining such matters.
      This paper proposes a variant of the Turing Test that is customized for specific
      use in the AILR realm, including depicting how this famous gold standard of
      AI fulfillment can be robustly applied across the autonomous levels of AI Legal
      Reasoning.", "venue": "arXiv.org", "year": 2020, "referenceCount": 57, "citationCount":
      8, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Law", "source": "s2-fos-model"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2020-08-18", "journal": {"name": "ArXiv",
      "volume": "abs/2008.07743"}, "citationStyles": {"bibtex": "@Article{Eliot2020TuringTA,\n
      author = {L. Eliot},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title
      = {Turing Test and the Practice of Law: The Role of Autonomous Levels of AI
      Legal Reasoning},\n volume = {abs/2008.07743},\n year = {2020}\n}\n"}, "authors":
      [{"authorId": "10776465", "name": "L. Eliot"}]}, {"paperId": "2da3a84e72a2973504cd9cf1c0a377f5a5a91f09",
      "externalIds": {"DBLP": "journals/corr/abs-2303-14310", "ArXiv": "2303.14310",
      "DOI": "10.48550/arXiv.2303.14310", "CorpusId": 257766379}, "corpusId": 257766379,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/2da3a84e72a2973504cd9cf1c0a377f5a5a91f09",
      "title": "GPT is becoming a Turing machine: Here are some ways to program it",
      "abstract": "We demonstrate that, through appropriate prompting, GPT-3 family
      of models can be triggered to perform iterative behaviours necessary to execute
      (rather than just write or recall) programs that involve loops, including several
      popular algorithms found in computer science curricula or software developer
      interviews. We trigger execution and description of Iterations by Regimenting
      Self-Attention (IRSA) in one (or a combination) of three ways: 1) Using strong
      repetitive structure in an example of an execution path of a target program
      for one particular input, 2) Prompting with fragments of execution paths, and
      3) Explicitly forbidding (skipping) self-attention to parts of the generated
      text. On a dynamic program execution, IRSA leads to larger accuracy gains than
      replacing the model with the much more powerful GPT-4. IRSA has promising applications
      in education, as the prompts and responses resemble student assignments in data
      structures and algorithms classes. Our findings hold implications for evaluating
      LLMs, which typically target the in-context learning: We show that prompts that
      may not even cover one full task example can trigger algorithmic behaviour,
      allowing solving problems previously thought of as hard for LLMs, such as logical
      puzzles. Consequently, prompt design plays an even more critical role in LLM
      performance than previously recognized.", "venue": "arXiv.org", "year": 2023,
      "referenceCount": 45, "citationCount": 9, "influentialCitationCount": 0, "isOpenAccess":
      true, "openAccessPdf": {"url": "http://arxiv.org/pdf/2303.14310", "status":
      "CLOSED"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-03-25", "journal": {"name": "ArXiv", "volume": "abs/2303.14310"}, "citationStyles":
      {"bibtex": "@Article{Jojic2023GPTIB,\n author = {A. Jojic and Zhen Wang and
      N. Jojic},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {GPT is
      becoming a Turing machine: Here are some ways to program it},\n volume = {abs/2303.14310},\n
      year = {2023}\n}\n"}, "authors": [{"authorId": "2156583836", "name": "A. Jojic"},
      {"authorId": "47197370", "name": "Zhen Wang"}, {"authorId": "1698689", "name":
      "N. Jojic"}]}, {"paperId": "02f5aa2fb0f8a956a2acbb7e457d78d416ebf9ad", "externalIds":
      {"ArXiv": "2306.05582", "DBLP": "journals/corr/abs-2306-05582", "DOI": "10.48550/arXiv.2306.05582",
      "CorpusId": 259129336}, "corpusId": 259129336, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/02f5aa2fb0f8a956a2acbb7e457d78d416ebf9ad",
      "title": "A newborn embodied Turing test for view-invariant object recognition",
      "abstract": "Recent progress in artificial intelligence has renewed interest
      in building machines that learn like animals. Almost all of the work comparing
      learning across biological and artificial systems comes from studies where animals
      and machines received different training data, obscuring whether differences
      between animals and machines emerged from differences in learning mechanisms
      versus training data. We present an experimental approach-a\"newborn embodied
      Turing Test\"-that allows newborn animals and machines to be raised in the same
      environments and tested with the same tasks, permitting direct comparison of
      their learning abilities. To make this platform, we first collected controlled-rearing
      data from newborn chicks, then performed\"digital twin\"experiments in which
      machines were raised in virtual environments that mimicked the rearing conditions
      of the chicks. We found that (1) machines (deep reinforcement learning agents
      with intrinsic motivation) can spontaneously develop visually guided preference
      behavior, akin to imprinting in newborn chicks, and (2) machines are still far
      from newborn-level performance on object recognition tasks. Almost all of the
      chicks developed view-invariant object recognition, whereas the machines tended
      to develop view-dependent recognition. The learning outcomes were also far more
      constrained in the chicks versus machines. Ultimately, we anticipate that this
      approach will help researchers develop embodied AI systems that learn like newborn
      animals.", "venue": "arXiv.org", "year": 2023, "referenceCount": 24, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "http://arxiv.org/pdf/2306.05582", "status": "CLOSED"}, "fieldsOfStudy": ["Computer
      Science", "Biology"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
      "external"}, {"category": "Biology", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2023-06-08", "journal": {"name": "ArXiv", "volume": "abs/2306.05582"},
      "citationStyles": {"bibtex": "@Article{Pak2023ANE,\n author = {Denizhan Pak
      and Donsuk Lee and Samantha M. W. Wood and Justin N. Wood},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {A newborn embodied Turing test for view-invariant
      object recognition},\n volume = {abs/2306.05582},\n year = {2023}\n}\n"}, "authors":
      [{"authorId": "2111880202", "name": "Denizhan Pak"}, {"authorId": "2109484738",
      "name": "Donsuk Lee"}, {"authorId": "145208012", "name": "Samantha M. W. Wood"},
      {"authorId": "2237822", "name": "Justin N. Wood"}]}, {"paperId": "47681b0e41a0b9f886208d5bb0b7265703547f3a",
      "externalIds": {"DBLP": "journals/corr/abs-2309-12151", "ArXiv": "2309.12151",
      "DOI": "10.48550/arXiv.2309.12151", "CorpusId": 262083932}, "corpusId": 262083932,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/47681b0e41a0b9f886208d5bb0b7265703547f3a",
      "title": "Semantics for a Turing-complete Reversible Programming Language with
      Inductive Types", "abstract": "This paper is concerned with the expressivity
      and denotational semantics of a functional higher-order reversible programming
      language based on Theseus. In this language, pattern-matching is used to ensure
      the reversibility of functions. We show how one can encode any Reversible Turing
      Machine in said language. We then build a sound and adequate categorical semantics
      based on join inverse categories, with additional structures to capture pattern-matching.
      We then derive a full completeness result, stating that any computable, partial
      injective function is the image of a term in the language.", "venue": "arXiv.org",
      "year": 2023, "referenceCount": 40, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/2309.12151",
      "status": "CLOSED"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-09-21", "journal":
      {"name": "ArXiv", "volume": "abs/2309.12151"}, "citationStyles": {"bibtex":
      "@Article{Chardonnet2023SemanticsFA,\n author = {Kostia Chardonnet and Louis
      Lemonnier and Beno\u00eet Valiron},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Semantics for a Turing-complete Reversible Programming Language with
      Inductive Types},\n volume = {abs/2309.12151},\n year = {2023}\n}\n"}, "authors":
      [{"authorId": "1805946291", "name": "Kostia Chardonnet"}, {"authorId": "153629040",
      "name": "Louis Lemonnier"}, {"authorId": "2243337061", "name": "Beno\u00eet
      Valiron"}]}, {"paperId": "820926337196f774603a236deec2d99901f790c6", "externalIds":
      {"ArXiv": "2303.13248", "DBLP": "journals/corr/abs-2303-13248", "DOI": "10.48550/arXiv.2303.13248",
      "CorpusId": 257687501}, "corpusId": 257687501, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/820926337196f774603a236deec2d99901f790c6",
      "title": "Numerical Bifurcation Analysis of Turing and Symmetry Broken Patterns
      of a Vegetation PDE Model", "abstract": "We study the mechanisms of pattern
      formation for vegetation dynamics in water-limited regions. Our analysis is
      based on a set of two partial differential equations (PDEs) of reaction-diffusion
      type for the biomass and water and one ordinary differential equation (ODE)
      describing the dependence of the toxicity on the biomass. We perform a linear
      stability analysis in the one-dimensional finite space, we derive analytically
      the conditions for the appearance of Turing instability that gives rise to spatio-temporal
      patterns emanating from the homogeneous solution, and provide its dependence
      with respect to the size of the domain. Furthermore, we perform a numerical
      bifurcation analysis in order to study the pattern formation of the inhomogeneous
      solution, with respect to the precipitation rate, thus analyzing the stability
      and symmetry properties of the emanating patterns. Based on the numerical bifurcation
      analysis, we have found new patterns, which form due to the onset of secondary
      bifurcations from the primary Turing instability, thus giving rise to a multistability
      of asymmetric solutions.", "venue": "arXiv.org", "year": 2023, "referenceCount":
      38, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true,
      "openAccessPdf": {"url": "http://arxiv.org/pdf/2303.13248", "status": "CLOSED"},
      "fieldsOfStudy": ["Computer Science", "Mathematics", "Physics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Physics", "source": "external"}, {"category":
      "Environmental Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-03-23", "journal": {"name": "ArXiv", "volume": "abs/2303.13248"}, "citationStyles":
      {"bibtex": "@Article{Spiliotis2023NumericalBA,\n author = {K. Spiliotis and
      L. Russo and F. Giannino and C. Siettos},\n booktitle = {arXiv.org},\n journal
      = {ArXiv},\n title = {Numerical Bifurcation Analysis of Turing and Symmetry
      Broken Patterns of a Vegetation PDE Model},\n volume = {abs/2303.13248},\n year
      = {2023}\n}\n"}, "authors": [{"authorId": "2234681", "name": "K. Spiliotis"},
      {"authorId": "145080345", "name": "L. Russo"}, {"authorId": "2074336", "name":
      "F. Giannino"}, {"authorId": "1715996", "name": "C. Siettos"}]}, {"paperId":
      "b2880b21f0c409ab1d602e18fbacbdb9737e522b", "externalIds": {"DBLP": "journals/corr/abs-2303-06512",
      "ArXiv": "2303.06512", "DOI": "10.48550/arXiv.2303.06512", "CorpusId": 257496820},
      "corpusId": 257496820, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/b2880b21f0c409ab1d602e18fbacbdb9737e522b",
      "title": "Piecewise DMD for oscillatory and Turing spatio-temporal dynamics",
      "abstract": "Dynamic Mode Decomposition (DMD) is an equation-free method that
      aims at reconstructing the best linear fit from temporal datasets. In this paper,
      we show that DMD does not provide accurate approximation for datasets describing
      oscillatory dynamics, like spiral waves and relaxation oscillations, or spatio-temporal
      Turing instability. Inspired from the classical\"divide and conquer\"approach,
      we propose a piecewise version of DMD (pDMD) to overcome this problem. The main
      idea is to split the original dataset in N submatrices and then apply the exact
      (randomized) DMD method in each subset of the obtained partition. We describe
      the pDMD algorithm in detail and we introduce some error indicators to evaluate
      its performance when N is increased. Numerical experiments show that very accurate
      reconstructions are obtained by pDMD for datasets arising from time snapshots
      of some reaction-diffusion PDE systems, like the FitzHugh-Nagumo model, the
      lambda-omega system and the DIB morpho-chemical system for battery modeling.",
      "venue": "arXiv.org", "year": 2023, "referenceCount": 29, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "http://arxiv.org/pdf/2303.06512", "status": "CLOSED"}, "fieldsOfStudy": ["Computer
      Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science",
      "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category":
      "Physics", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2023-03-11", "journal": {"name": "ArXiv", "volume": "abs/2303.06512"},
      "citationStyles": {"bibtex": "@Article{Alla2023PiecewiseDF,\n author = {A. Alla
      and A. Monti and I. Sgura},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Piecewise DMD for oscillatory and Turing spatio-temporal dynamics},\n
      volume = {abs/2303.06512},\n year = {2023}\n}\n"}, "authors": [{"authorId":
      "47766762", "name": "A. Alla"}, {"authorId": "1471727847", "name": "A. Monti"},
      {"authorId": "1914459", "name": "I. Sgura"}]}, {"paperId": "c4ef333deeeee9cc8cbf16a9e76bc4a60a43ae03",
      "externalIds": {"ArXiv": "2311.02049", "DBLP": "journals/corr/abs-2311-02049",
      "DOI": "10.48550/arXiv.2311.02049", "CorpusId": 265019235}, "corpusId": 265019235,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/c4ef333deeeee9cc8cbf16a9e76bc4a60a43ae03",
      "title": "Post Turing: Mapping the landscape of LLM Evaluation", "abstract":
      "In the rapidly evolving landscape of Large Language Models (LLMs), introduction
      of well-defined and standardized evaluation methodologies remains a crucial
      challenge. This paper traces the historical trajectory of LLM evaluations, from
      the foundational questions posed by Alan Turing to the modern era of AI research.
      We categorize the evolution of LLMs into distinct periods, each characterized
      by its unique benchmarks and evaluation criteria. As LLMs increasingly mimic
      human-like behaviors, traditional evaluation proxies, such as the Turing test,
      have become less reliable. We emphasize the pressing need for a unified evaluation
      system, given the broader societal implications of these models. Through an
      analysis of common evaluation methodologies, we advocate for a qualitative shift
      in assessment approaches, underscoring the importance of standardization and
      objective criteria. This work serves as a call for the AI community to collaboratively
      address the challenges of LLM evaluation, ensuring their reliability, fairness,
      and societal benefit.", "venue": "arXiv.org", "year": 2023, "referenceCount":
      88, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Linguistics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-11-03", "journal":
      {"name": "ArXiv", "volume": "abs/2311.02049"}, "citationStyles": {"bibtex":
      "@Article{Tikhonov2023PostTM,\n author = {Alexey Tikhonov and Ivan P. Yamshchikov},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Post Turing: Mapping
      the landscape of LLM Evaluation},\n volume = {abs/2311.02049},\n year = {2023}\n}\n"},
      "authors": [{"authorId": "34501167", "name": "Alexey Tikhonov"}, {"authorId":
      "2130008929", "name": "Ivan P. Yamshchikov"}]}, {"paperId": "f7c31ed51a8a8a0156b5a129168d058bab0e8022",
      "externalIds": {"DBLP": "journals/corr/abs-2307-05285", "ArXiv": "2307.05285",
      "DOI": "10.48550/arXiv.2307.05285", "CorpusId": 259766465}, "corpusId": 259766465,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/f7c31ed51a8a8a0156b5a129168d058bab0e8022",
      "title": "Turing patterns in a 3D morpho-chemical bulk-surface reaction-diffusion
      system for battery modeling", "abstract": "In this paper we introduce a bulk-surface
      reaction-diffusion (BSRD) model in three space dimensions that extends the DIB
      morphochemical model to account for the electrolyte contribution in the application,
      in order to study structure formation during discharge-charge processes in batteries.
      Here we propose to approximate the model by the Bulk-Surface Virtual Element
      Method on a tailor-made mesh that proves to be competitive with fast bespoke
      methods for PDEs on Cartesian grids. We present a selection of numerical simulations
      that accurately match the classical morphologies found in experiments. Finally,
      we compare the Turing patterns obtained by the coupled 3D BS-DIB model with
      those obtained with the original 2D version.", "venue": "arXiv.org", "year":
      2023, "referenceCount": 20, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/2307.05285",
      "status": "CLOSED"}, "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Mathematics",
      "source": "external"}, {"category": "Engineering", "source": "s2-fos-model"},
      {"category": "Materials Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2023-07-11", "journal": {"name": "ArXiv",
      "volume": "abs/2307.05285"}, "citationStyles": {"bibtex": "@Article{Frittelli2023TuringPI,\n
      author = {Massimo Frittelli and I. Sgura and B. Bozzini},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {Turing patterns in a 3D morpho-chemical bulk-surface
      reaction-diffusion system for battery modeling},\n volume = {abs/2307.05285},\n
      year = {2023}\n}\n"}, "authors": [{"authorId": "38056322", "name": "Massimo
      Frittelli"}, {"authorId": "1914459", "name": "I. Sgura"}, {"authorId": "2127715407",
      "name": "B. Bozzini"}]}, {"paperId": "e05c643afd4a2c1889b7f7e3f90ce712026e1d4c",
      "externalIds": {"ArXiv": "2305.15677", "DBLP": "journals/corr/abs-2305-15677",
      "DOI": "10.48550/arXiv.2305.15677", "CorpusId": 258887782}, "corpusId": 258887782,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/e05c643afd4a2c1889b7f7e3f90ce712026e1d4c",
      "title": "Nonlinear Bipartite Output Regulation with Application to Turing Pattern",
      "abstract": "In this paper, a bipartite output regulation problem is solved
      for a class of nonlinear multi-agent systems subject to static signed communication
      networks. A nonlinear distributed observer is proposed for a nonlinear exosystem
      with cooperation-competition interactions to address the problem. Sufficient
      conditions are provided to guarantee its existence and stability. The exponential
      stability of the observer is established. As a practical application, a leader-following
      bipartite consensus problem is solved for a class of nonlinear multi-agent systems
      based on the observer. Finally, a network of multiple pendulum systems is treated
      to support the feasibility of the proposed design. The possible application
      of the approach to generate specific Turing patterns is also presented.", "venue":
      "arXiv.org", "year": 2023, "referenceCount": 41, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "http://arxiv.org/pdf/2305.15677",
      "status": "CLOSED"}, "fieldsOfStudy": ["Computer Science", "Mathematics", "Engineering",
      "Physics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Engineering",
      "source": "external"}, {"category": "Physics", "source": "external"}, {"category":
      "Engineering", "source": "s2-fos-model"}, {"category": "Mathematics", "source":
      "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-05-25", "journal":
      {"name": "ArXiv", "volume": "abs/2305.15677"}, "citationStyles": {"bibtex":
      "@Article{Liang2023NonlinearBO,\n author = {Dong Liang and M. Guay and Shimin
      Wang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Nonlinear
      Bipartite Output Regulation with Application to Turing Pattern},\n volume =
      {abs/2305.15677},\n year = {2023}\n}\n"}, "authors": [{"authorId": "2113984966",
      "name": "Dong Liang"}, {"authorId": "144449892", "name": "M. Guay"}, {"authorId":
      "50694870", "name": "Shimin Wang"}]}, {"paperId": "da7a38d370b7e3d00ab2869b4832d8dda8fb94d3",
      "externalIds": {"ArXiv": "2301.11632", "DBLP": "journals/corr/abs-2301-11632",
      "DOI": "10.48550/arXiv.2301.11632", "CorpusId": 256358733}, "corpusId": 256358733,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/da7a38d370b7e3d00ab2869b4832d8dda8fb94d3",
      "title": "Turing Machines Equipped with CTC in Physical Universes", "abstract":
      "We study the paradoxical aspects of closed time-like curves and their impact
      on the theory of computation. After introducing the $\\text{TM}_\\text{CTC}$,
      a classical Turing machine benefiting CTCs for backward time travel, Aaronson
      et al. proved that $\\text{P} = \\text{PSPACE}$ and the $\\Delta_2$ sets, such
      as the halting problem, are computable within this computational model. Our
      critical view is the physical consistency of this model, which leads to proposing
      the strong axiom, explaining that every particle rounding on a CTC will be destroyed
      before returning to its starting time, and the weak axiom, describing the same
      notion, particularly for Turing machines. We claim that in a universe containing
      CTCs, the two axioms must be true; otherwise, there will be an infinite number
      of any particle rounding on a CTC in the universe. An immediate result of the
      weak axiom is the incapability of Turing machines to convey information for
      a full round on a CTC, leading to the proposed $\\text{TM}_\\text{CTC}$ programs
      for the aforementioned corollaries failing to function. We suggest our solution
      for this problem as the data transferring hypothesis, which applies another
      $\\text{TM}_\\text{CTC}$ as a means for storing data. A prerequisite for it
      is the existence of the concept of Turing machines throughout time, which makes
      it appear infeasible in our universe. Then, we discuss possible physical conditions
      that can be held for a universe containing CTCs and conclude that if returning
      to an approximately equivalent universe by a CTC was conceivable, the above
      corollaries would be valid.", "venue": "arXiv.org", "year": 2023, "referenceCount":
      18, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true,
      "openAccessPdf": {"url": "http://arxiv.org/pdf/2301.11632", "status": "CLOSED"},
      "fieldsOfStudy": ["Computer Science", "Physics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Physics", "source":
      "external"}, {"category": "Physics", "source": "s2-fos-model"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2023-01-27", "journal": {"name": "ArXiv", "volume": "abs/2301.11632"},
      "citationStyles": {"bibtex": "@Article{Khanehsar2023TuringME,\n author = {Sara
      Babaee Khanehsar and F. Didehvar},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Turing Machines Equipped with CTC in Physical Universes},\n volume
      = {abs/2301.11632},\n year = {2023}\n}\n"}, "authors": [{"authorId": "2203247815",
      "name": "Sara Babaee Khanehsar"}, {"authorId": "1793763", "name": "F. Didehvar"}]},
      {"paperId": "573412866a3c60a2ec20f0e66babcb1743f63442", "externalIds": {"DBLP":
      "journals/corr/abs-2309-14690", "ArXiv": "2309.14690", "DOI": "10.48550/arXiv.2309.14690",
      "CorpusId": 262825972}, "corpusId": 262825972, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/573412866a3c60a2ec20f0e66babcb1743f63442",
      "title": "On the Tensor Representation and Algebraic Homomorphism of the Neural
      State Turing Machine", "abstract": "Recurrent neural networks (RNNs) and transformers
      have been shown to be Turing-complete, but this result assumes infinite precision
      in their hidden representations, positional encodings for transformers, and
      unbounded computation time in general. In practical applications, however, it
      is crucial to have real-time models that can recognize Turing complete grammars
      in a single pass. To address this issue and to better understand the true computational
      power of artificial neural networks (ANNs), we introduce a new class of recurrent
      models called the neural state Turing machine (NSTM). The NSTM has bounded weights
      and finite-precision connections and can simulate any Turing Machine in real-time.
      In contrast to prior work that assumes unbounded time and precision in weights,
      to demonstrate equivalence with TMs, we prove that a $13$-neuron bounded tensor
      RNN, coupled with third-order synapses, can model any TM class in real-time.
      Furthermore, under the Markov assumption, we provide a new theoretical bound
      for a non-recurrent network augmented with memory, showing that a tensor feedforward
      network with $25$th-order finite precision weights is equivalent to a universal
      TM.", "venue": "arXiv.org", "year": 2023, "referenceCount": 35, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://arxiv.org/pdf/2309.14690", "status": "CLOSED"}, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-09-26", "journal": {"name": "ArXiv", "volume": "abs/2309.14690"}, "citationStyles":
      {"bibtex": "@Article{Mali2023OnTT,\n author = {A. Mali and Alexander Ororbia
      and Daniel Kifer and L. Giles},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {On the Tensor Representation and Algebraic Homomorphism of the Neural
      State Turing Machine},\n volume = {abs/2309.14690},\n year = {2023}\n}\n"},
      "authors": [{"authorId": "40900825", "name": "A. Mali"}, {"authorId": "3038767",
      "name": "Alexander Ororbia"}, {"authorId": "1852261", "name": "Daniel Kifer"},
      {"authorId": "152276938", "name": "L. Giles"}]}, {"paperId": "842518e260c406f8f17d04a4fcb64a04050b67cd",
      "externalIds": {"ArXiv": "2308.02308", "DBLP": "journals/corr/abs-2308-02308",
      "DOI": "10.48550/arXiv.2308.02308", "CorpusId": 260611559}, "corpusId": 260611559,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/842518e260c406f8f17d04a4fcb64a04050b67cd",
      "title": "A Thermodynamically Universal Turing Machine", "abstract": "Expanding
      upon the widely recognized notion of mathematical universality in Turing machines,
      a concept of thermodynamic universality in Turing machines is introduced. Under
      the physical Church-Turing thesis, the existence of a thermodynamically universal
      Turing machine (TUTM) is demonstrated. A TUTM not only has the capability to
      simulate the input-output behavior of any given Turing machine but also replicate
      the heat production of that machine up to an additive constant. The finding
      shows that the hypothesis that the physical world is simulated by Turing machines
      may not be completely absurd.", "venue": "arXiv.org", "year": 2023, "referenceCount":
      8, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true,
      "openAccessPdf": {"url": "https://arxiv.org/pdf/2308.02308", "status": "CLOSED"},
      "fieldsOfStudy": ["Computer Science", "Physics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Physics", "source":
      "external"}, {"category": "Physics", "source": "s2-fos-model"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2023-07-06", "journal": {"name": "ArXiv", "volume": "abs/2308.02308"},
      "citationStyles": {"bibtex": "@Article{Zhu2023ATU,\n author = {Jihai Zhu},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A Thermodynamically
      Universal Turing Machine},\n volume = {abs/2308.02308},\n year = {2023}\n}\n"},
      "authors": [{"authorId": "2228810671", "name": "Jihai Zhu"}]}, {"paperId": "f73d3129d78cffd9baf3a2eb6dabcb8176a28892",
      "externalIds": {"DBLP": "journals/corr/abs-2310-17363", "ArXiv": "2310.17363",
      "DOI": "10.48550/arXiv.2310.17363", "CorpusId": 264490782}, "corpusId": 264490782,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/f73d3129d78cffd9baf3a2eb6dabcb8176a28892",
      "title": "Controllability of networked multiagent systems based on linearized
      Turing''s model", "abstract": "Turing''s model has been widely used to explain
      how simple, uniform structures can give rise to complex, patterned structures
      during the development of organisms. However, it is very hard to establish rigorous
      theoretical results for the dynamic evolution behavior of Turing''s model since
      it is described by nonlinear partial differential equations. We focus on controllability
      of Turing''s model by linearization and spatial discretization. This linearized
      model is a networked system whose agents are second order linear systems and
      these agents interact with each other by Laplacian dynamics on a graph. A control
      signal can be added to agents of choice. Under mild conditions on the parameters
      of the linearized Turing''s model, we prove the equivalence between controllability
      of the linearized Turing''s model and controllability of a Laplace dynamic system
      with agents of first order dynamics. When the graph is a grid graph or a cylinder
      grid graph, we then give precisely the minimal number of control nodes and a
      corresponding control node set such that the Laplace dynamic systems on these
      graphs with agents of first order dynamics are controllable.", "venue": "arXiv.org",
      "year": 2023, "referenceCount": 37, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Engineering",
      "Computer Science"], "s2FieldsOfStudy": [{"category": "Engineering", "source":
      "external"}, {"category": "Computer Science", "source": "external"}, {"category":
      "Engineering", "source": "s2-fos-model"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-10-26", "journal": {"name": "ArXiv", "volume": "abs/2310.17363"}, "citationStyles":
      {"bibtex": "@Article{Li2023ControllabilityON,\n author = {Tianhao Li and Ruichang
      Zhang and Zhixin Liu and Zhuo Zou and Xiaoming Hu},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {Controllability of networked multiagent systems
      based on linearized Turing''s model},\n volume = {abs/2310.17363},\n year =
      {2023}\n}\n"}, "authors": [{"authorId": "2261986523", "name": "Tianhao Li"},
      {"authorId": "2261751652", "name": "Ruichang Zhang"}, {"authorId": "2261901582",
      "name": "Zhixin Liu"}, {"authorId": "2261739273", "name": "Zhuo Zou"}, {"authorId":
      "2261888326", "name": "Xiaoming Hu"}]}, {"paperId": "4d63eef4c51a1d88e2f5060e93de4ac440dca099",
      "externalIds": {"ArXiv": "2312.02412", "DBLP": "journals/corr/abs-2312-02412",
      "DOI": "10.48550/arXiv.2312.02412", "CorpusId": 265659449}, "corpusId": 265659449,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/4d63eef4c51a1d88e2f5060e93de4ac440dca099",
      "title": "A Turing Incomputable Coloring Function", "abstract": "This paper
      describes a sequence of natural numbers that grows faster than any Turing computable
      function. This sequence is generated from a version of the tiling problem, called
      a coloring system. In our proof that generates the sequence, we use the notions
      of a chain and an unbounded sequence property, which resemble the methods of
      point set topology. From this sequence, we define a Turing incomputable coloring
      function.", "venue": "arXiv.org", "year": 2023, "referenceCount": 5, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Mathematics", "source": "s2-fos-model"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2023-12-05", "journal": {"name": "ArXiv", "volume": "abs/2312.02412"},
      "citationStyles": {"bibtex": "@Article{Fiske2023ATI,\n author = {Michael Stephen
      Fiske},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A Turing
      Incomputable Coloring Function},\n volume = {abs/2312.02412},\n year = {2023}\n}\n"},
      "authors": [{"authorId": "2040922", "name": "Michael Stephen Fiske"}]}, {"paperId":
      "82a25ba09303b0c26d4ca8abd7871fa71799da66", "externalIds": {"ArXiv": "2309.07932",
      "DBLP": "journals/corr/abs-2309-07932", "DOI": "10.48550/arXiv.2309.07932",
      "CorpusId": 262014087}, "corpusId": 262014087, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/82a25ba09303b0c26d4ca8abd7871fa71799da66",
      "title": "Flat origami is Turing Complete", "abstract": "Flat origami refers
      to the folding of flat, zero-curvature paper such that the finished object lies
      in a plane. Mathematically, flat origami consists of a continuous, piecewise
      isometric map $f:P\\subseteq\\mathbb{R}^2\\to\\mathbb{R}^2$ along with a layer
      ordering $\\lambda_f:P\\times P\\to \\{-1,1\\}$ that tracks which points of
      $P$ are above/below others when folded. The set of crease lines that a flat
      origami makes (i.e., the set on which the mapping $f$ is non-differentiable)
      is called its \\textit{crease pattern}. Flat origami mappings and their layer
      orderings can possess surprisingly intricate structure. For instance, determining
      whether or not a given straight-line planar graph drawn on $P$ is the crease
      pattern for some flat origami has been shown to be an NP-complete problem, and
      this result from 1996 led to numerous explorations in computational aspects
      of flat origami. In this paper we prove that flat origami, when viewed as a
      computational device, is Turing complete. We do this by showing that flat origami
      crease patterns with \\textit{optional creases} (creases that might be folded
      or remain unfolded depending on constraints imposed by other creases or inputs)
      can be constructed to simulate Rule 110, a one-dimensional cellular automaton
      that was proven to be Turing complete by Matthew Cook in 2004.", "venue": "arXiv.org",
      "year": 2023, "referenceCount": 0, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/2309.07932",
      "status": "CLOSED"}, "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy":
      [{"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "external"}, {"category": "Mathematics", "source": "s2-fos-model"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2023-09-13", "journal": {"name": "ArXiv",
      "volume": "abs/2309.07932"}, "citationStyles": {"bibtex": "@Article{Hull2023FlatOI,\n
      author = {Thomas C. Hull and Inna Zakharevich},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {Flat origami is Turing Complete},\n volume = {abs/2309.07932},\n
      year = {2023}\n}\n"}, "authors": [{"authorId": "2243018872", "name": "Thomas
      C. Hull"}, {"authorId": "2243014976", "name": "Inna Zakharevich"}]}, {"paperId":
      "682918c9c1705907ca1fe3f1207561f403f6ea0e", "externalIds": {"DBLP": "journals/corr/abs-2310-20216",
      "ArXiv": "2310.20216", "DOI": "10.48550/arXiv.2310.20216", "CorpusId": 264816480},
      "corpusId": 264816480, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/682918c9c1705907ca1fe3f1207561f403f6ea0e",
      "title": "Does GPT-4 Pass the Turing Test?", "abstract": "We evaluated GPT-4
      in a public online Turing Test. The best-performing GPT-4 prompt passed in 41%
      of games, outperforming baselines set by ELIZA (27%) and GPT-3.5 (14%), but
      falling short of chance and the baseline set by human participants (63%). Participants''
      decisions were based mainly on linguistic style (35%) and socio-emotional traits
      (27%), supporting the idea that intelligence is not sufficient to pass the Turing
      Test. Participants'' demographics, including education and familiarity with
      LLMs, did not predict detection rate, suggesting that even those who understand
      systems deeply and interact with them frequently may be susceptible to deception.
      Despite known limitations as a test of intelligence, we argue that the Turing
      Test continues to be relevant as an assessment of naturalistic communication
      and deception. AI models with the ability to masquerade as humans could have
      widespread societal consequences, and we analyse the effectiveness of different
      strategies and criteria for judging humanlikeness.", "venue": "arXiv.org", "year":
      2023, "referenceCount": 34, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2023-10-31", "journal": {"name": "ArXiv",
      "volume": "abs/2310.20216"}, "citationStyles": {"bibtex": "@Article{Jones2023DoesGP,\n
      author = {Cameron Jones and Benjamin Bergen},\n booktitle = {arXiv.org},\n journal
      = {ArXiv},\n title = {Does GPT-4 Pass the Turing Test?},\n volume = {abs/2310.20216},\n
      year = {2023}\n}\n"}, "authors": [{"authorId": "2263939115", "name": "Cameron
      Jones"}, {"authorId": "2264366136", "name": "Benjamin Bergen"}]}, {"paperId":
      "64660987ee2a526ab343f2df7310bf03a0576903", "externalIds": {"DBLP": "journals/corr/abs-2307-11747",
      "ArXiv": "2307.11747", "DOI": "10.48550/arXiv.2307.11747", "CorpusId": 260091638},
      "corpusId": 260091638, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/64660987ee2a526ab343f2df7310bf03a0576903",
      "title": "Simulation of Turing machines with analytic discrete ODEs: FPTIME
      and FPSPACE over the reals characterised with discrete ordinary differential
      equations", "abstract": "We prove that functions over the reals computable in
      polynomial time can be characterised using discrete ordinary differential equations
      (ODE), also known as finite differences. We also provide a characterisation
      of functions computable in polynomial space over the reals. In particular, this
      covers space complexity, while existing characterisations were only able to
      cover time complexity, and were restricted to functions over the integers. We
      prove furthermore that no artificial sign or test function is needed even for
      time complexity. At a technical level, this is obtained by proving that Turing
      machines can be simulated with analytic discrete ordinary differential equations.
      We believe this result opens the way to many applications, as it opens the possibility
      of programming with ODEs, with an underlying well-understood time and space
      complexity.", "venue": "arXiv.org", "year": 2023, "referenceCount": 29, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://arxiv.org/pdf/2307.11747", "status": "GREEN"}, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "s2-fos-model"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2023-07-21", "journal": {"name": "ArXiv", "volume": "abs/2307.11747"},
      "citationStyles": {"bibtex": "@Article{Blanc2023SimulationOT,\n author = {Manon
      Blanc and Olivier Bournez},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Simulation of Turing machines with analytic discrete ODEs: FPTIME and
      FPSPACE over the reals characterised with discrete ordinary differential equations},\n
      volume = {abs/2307.11747},\n year = {2023}\n}\n"}, "authors": [{"authorId":
      "2113388525", "name": "Manon Blanc"}, {"authorId": "1706341", "name": "Olivier
      Bournez"}]}, {"paperId": "4c18561f8693330d0eaef3278fcceef205b1d5b5", "externalIds":
      {"ArXiv": "2306.16872", "DBLP": "journals/corr/abs-2306-16872", "DOI": "10.48550/arXiv.2306.16872",
      "CorpusId": 259287339}, "corpusId": 259287339, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/4c18561f8693330d0eaef3278fcceef205b1d5b5",
      "title": "Towards a Self-Replicating Turing Machine", "abstract": "We provide
      partial implementations of von Neumann''s universal constructor and universal
      copier, starting out with three types of simple building blocks using minimal
      assumptions. Using the same principles, we also construct Turing machines. Combining
      both, we arrive at a proposal for a self-replicating Turing machine. Our construction
      allows for mutations if desired, and we give a simple description language.",
      "venue": "arXiv.org", "year": 2023, "referenceCount": 15, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "http://arxiv.org/pdf/2306.16872", "status": "CLOSED"}, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-06-29", "journal": {"name": "ArXiv", "volume": "abs/2306.16872"}, "citationStyles":
      {"bibtex": "@Article{Lano2023TowardsAS,\n author = {R. Lano},\n booktitle =
      {arXiv.org},\n journal = {ArXiv},\n title = {Towards a Self-Replicating Turing
      Machine},\n volume = {abs/2306.16872},\n year = {2023}\n}\n"}, "authors": [{"authorId":
      "2494914", "name": "R. Lano"}]}, {"paperId": "dc9f9ea229b5e515e89714a538f9f449c8afd1d0",
      "externalIds": {"ArXiv": "2307.08315", "DBLP": "journals/corr/abs-2307-08315",
      "DOI": "10.48550/arXiv.2307.08315", "CorpusId": 259937735}, "corpusId": 259937735,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/dc9f9ea229b5e515e89714a538f9f449c8afd1d0",
      "title": "IterLara: A Turing Complete Algebra for Big Data, AI, Scientific Computing,
      and Database", "abstract": "\\textsc{Lara} is a key-value algebra that aims
      at unifying linear and relational algebra with three types of operation abstraction.
      The study of \\textsc{Lara}''s expressive ability reports that it can represent
      relational algebra and most linear algebra operations. However, several essential
      computations, such as matrix inversion and determinant, cannot be expressed
      in \\textsc{Lara}. \\textsc{Lara} cannot represent global and iterative computation,
      either. This article proposes \\textsc{IterLara}, extending \\textsc{Lara} with
      iterative operators, to provide an algebraic model that unifies operations in
      general-purpose computing, like big data, AI, scientific computing, and database.
      We study the expressive ability of \\textsc{Lara} and \\textsc{IterLara} and
      prove that \\textsc{IterLara} with aggregation functions can represent matrix
      inversion, determinant. Besides, we demonstrate that \\textsc{IterLara} with
      no limitation of function utility is Turing complete. We also propose the Operation
      Count (OP) as a metric of computation amount for \\textsc{IterLara} and ensure
      that the OP metric is in accordance with the existing computation metrics.",
      "venue": "arXiv.org", "year": 2023, "referenceCount": 15, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://arxiv.org/pdf/2307.08315", "status": "CLOSED"}, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-07-17", "journal": {"name": "ArXiv", "volume": "abs/2307.08315"}, "citationStyles":
      {"bibtex": "@Article{Li2023IterLaraAT,\n author = {Hongxiao Li and Wanling Gao
      and Lei Wang and Jianfeng Zhan},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {IterLara: A Turing Complete Algebra for Big Data, AI, Scientific Computing,
      and Database},\n volume = {abs/2307.08315},\n year = {2023}\n}\n"}, "authors":
      [{"authorId": "2108578660", "name": "Hongxiao Li"}, {"authorId": "46874006",
      "name": "Wanling Gao"}, {"authorId": "36547165", "name": "Lei Wang"}, {"authorId":
      "2062319", "name": "Jianfeng Zhan"}]}, {"paperId": "e64959bee8eb02ce5f224e80b8e99282c576bcb3",
      "externalIds": {"DBLP": "journals/corr/abs-2308-14236", "DOI": "10.48550/arXiv.2308.14236",
      "CorpusId": 261432178}, "corpusId": 261432178, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/e64959bee8eb02ce5f224e80b8e99282c576bcb3",
      "title": "A conservative Turing complete S4 flow", "abstract": null, "venue":
      "arXiv.org", "year": 2023, "referenceCount": 0, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/2308.14236",
      "status": "CLOSED"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": null, "journal":
      {"name": "ArXiv", "volume": "abs/2308.14236"}, "citationStyles": {"bibtex":
      "@Article{Su\u00e1rez-Serrato2023ACT,\n author = {P. Su\u00e1rez-Serrato},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A conservative Turing
      complete S4 flow},\n volume = {abs/2308.14236},\n year = {2023}\n}\n"}, "authors":
      [{"authorId": "1388712122", "name": "P. Su\u00e1rez-Serrato"}]}, {"paperId":
      "fb1c54422404d40b0509b4f13c0a25741cbf7dc1", "externalIds": {"MAG": "3096363261",
      "DBLP": "journals/corr/abs-2010-14753", "ArXiv": "2010.14753", "CorpusId": 225094536},
      "corpusId": 225094536, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/fb1c54422404d40b0509b4f13c0a25741cbf7dc1",
      "title": "A short note on the decision tree based neural turing machine", "abstract":
      "Turing machine and decision tree have developed independently for a long time.
      With the recent development of differentiable models, there is an intersection
      between them. Neural turing machine(NTM) opens door for the memory network.
      It use differentiable attention mechanism to read/write external memory bank.
      Differentiable forest brings differentiable properties to classical decision
      tree. In this short note, we show the deep connection between these two models.
      That is: differentiable forest is a special case of NTM. Differentiable forest
      is actually decision tree based neural turing machine. Based on this deep connection,
      we propose a response augmented differential forest (RaDF). The controller of
      RaDF is differentiable forest, the external memory of RaDF are response vectors
      which would be read/write by leaf nodes.", "venue": "arXiv.org", "year": 2020,
      "referenceCount": 29, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2020-10-27", "journal": {"name": "ArXiv", "volume": "abs/2010.14753"},
      "citationStyles": {"bibtex": "@Article{Chen2020ASN,\n author = {Yingshi Chen},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A short note on the
      decision tree based neural turing machine},\n volume = {abs/2010.14753},\n year
      = {2020}\n}\n"}, "authors": [{"authorId": "2109316597", "name": "Yingshi Chen"}]},
      {"paperId": "1fab97516e0545cbe879739c1228f286f8c4b9fe", "externalIds": {"DBLP":
      "journals/corr/abs-2005-09280", "ArXiv": "2005.09280", "MAG": "3027638931",
      "CorpusId": 218684798}, "corpusId": 218684798, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/1fab97516e0545cbe879739c1228f286f8c4b9fe",
      "title": "Controlled Language and Baby Turing Test for General Conversational
      Intelligence", "abstract": "General conversational intelligence appears to be
      an important part of artificial general intelligence. Respectively, it requires
      accessible measures of the intelligence quality and controllable ways of its
      achievement, ideally - having the linguistic and semantic models represented
      in a reasonable way. Our work is suggesting to use Baby Turing Test approach
      to extend the classic Turing Test for conversational intelligence and controlled
      language based on semantic graph representation extensible for arbitrary subject
      domain. We describe how the two can be used together to build a general-purpose
      conversational system such as an intelligent assistant for online media and
      social network data processing.", "venue": "arXiv.org", "year": 2020, "referenceCount":
      21, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2020-05-19", "journal": {"name": "ArXiv", "volume": "abs/2005.09280"},
      "citationStyles": {"bibtex": "@Article{Kolonin2020ControlledLA,\n author = {A.
      Kolonin},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Controlled
      Language and Baby Turing Test for General Conversational Intelligence},\n volume
      = {abs/2005.09280},\n year = {2020}\n}\n"}, "authors": [{"authorId": "1847471",
      "name": "A. Kolonin"}]}, {"paperId": "3bd072b495c54dde9848f420b6071b0bedc05427",
      "externalIds": {"DBLP": "journals/corr/abs-2311-12373", "ArXiv": "2311.12373",
      "DOI": "10.48550/arXiv.2311.12373", "CorpusId": 265309046}, "corpusId": 265309046,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/3bd072b495c54dde9848f420b6071b0bedc05427",
      "title": "Beyond Turing: A Comparative Analysis of Approaches for Detecting
      Machine-Generated Text", "abstract": "Significant progress has been made on
      text generation by pre-trained language models (PLMs), yet distinguishing between
      human and machine-generated text poses an escalating challenge. This paper offers
      an in-depth evaluation of three distinct methods used to address this task:
      traditional shallow learning, Language Model (LM) fine-tuning, and Multilingual
      Model fine-tuning. These approaches are rigorously tested on a wide range of
      machine-generated texts, providing a benchmark of their competence in distinguishing
      between human-authored and machine-authored linguistic constructs. The results
      reveal considerable differences in performance across methods, thus emphasizing
      the continued need for advancement in this crucial area of NLP. This study offers
      valuable insights and paves the way for future research aimed at creating robust
      and highly discriminative models.", "venue": "arXiv.org", "year": 2023, "referenceCount":
      8, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Linguistics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-11-21", "journal":
      {"name": "ArXiv", "volume": "abs/2311.12373"}, "citationStyles": {"bibtex":
      "@Article{Adilazuarda2023BeyondTA,\n author = {Muhammad Farid Adilazuarda and
      N. Arkoulis and Oleksii Chumakov},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Beyond Turing: A Comparative Analysis of Approaches for Detecting Machine-Generated
      Text},\n volume = {abs/2311.12373},\n year = {2023}\n}\n"}, "authors": [{"authorId":
      "2191731497", "name": "Muhammad Farid Adilazuarda"}, {"authorId": "2242153022",
      "name": "N. Arkoulis"}, {"authorId": "2267488633", "name": "Oleksii Chumakov"}]},
      {"paperId": "f5e4184ff3d7589e7416589e0a7853e314f21c9b", "externalIds": {"ArXiv":
      "2309.13094", "DBLP": "journals/corr/abs-2309-13094", "DOI": "10.48550/arXiv.2309.13094",
      "CorpusId": 262465089}, "corpusId": 262465089, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/f5e4184ff3d7589e7416589e0a7853e314f21c9b",
      "title": "Computational Natural Philosophy: A Thread from Presocratics through
      Turing to ChatGPT", "abstract": "Modern computational natural philosophy conceptualizes
      the universe in terms of information and computation, establishing a framework
      for the study of cognition and intelligence. Despite some critiques, this computational
      perspective has significantly influenced our understanding of the natural world,
      leading to the development of AI systems like ChatGPT based on deep neural networks.
      Advancements in this domain have been facilitated by interdisciplinary research,
      integrating knowledge from multiple fields to simulate complex systems. Large
      Language Models (LLMs), such as ChatGPT, represent this approach''s capabilities,
      utilizing reinforcement learning with human feedback (RLHF). Current research
      initiatives aim to integrate neural networks with symbolic computing, introducing
      a new generation of hybrid computational models.", "venue": "arXiv.org", "year":
      2023, "referenceCount": 93, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/2309.13094",
      "status": "CLOSED"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Philosophy", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2023-09-22", "journal":
      {"name": "ArXiv", "volume": "abs/2309.13094"}, "citationStyles": {"bibtex":
      "@Article{Dodig-Crnkovic2023ComputationalNP,\n author = {G. Dodig-Crnkovic},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Computational Natural
      Philosophy: A Thread from Presocratics through Turing to ChatGPT},\n volume
      = {abs/2309.13094},\n year = {2023}\n}\n"}, "authors": [{"authorId": "1403731773",
      "name": "G. Dodig-Crnkovic"}]}, {"paperId": "689857cd0447e43892b20cba03fb89f7b07f1536",
      "externalIds": {"ArXiv": "2309.00115", "DBLP": "journals/corr/abs-2309-00115",
      "DOI": "10.48550/arXiv.2309.00115", "CorpusId": 261494029}, "corpusId": 261494029,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/689857cd0447e43892b20cba03fb89f7b07f1536",
      "title": "Excel as a Turing-complete Functional Programming Environment", "abstract":
      "Since the calculation engine of Excel was the subject of a major upgrade to
      accommodate Dynamic Arrays in 2018 there has been a series of seismic changes
      to the art of building spreadsheet solutions. This paper will show the ad-hoc
      end user practices of traditional spreadsheets can be replaced by radically
      different approaches that have far more in common with formal programming. It
      is too early to guess the extent to which the new functionality will be adopted
      by the business and engineering communities and the impact that may have upon
      risk. Nevertheless, some trends are emerging from pioneering work within the
      Excel community which we will discuss here.", "venue": "arXiv.org", "year":
      2023, "referenceCount": 11, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": true, "openAccessPdf": {"url": "https://arxiv.org/pdf/2309.00115",
      "status": "CLOSED"}, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Engineering", "source": "s2-fos-model"},
      {"category": "Business", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2023-08-31", "journal": {"name": "ArXiv", "volume": "abs/2309.00115"},
      "citationStyles": {"bibtex": "@Article{Bartholomew2023ExcelAA,\n author = {Peter
      Bartholomew},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Excel
      as a Turing-complete Functional Programming Environment},\n volume = {abs/2309.00115},\n
      year = {2023}\n}\n"}, "authors": [{"authorId": "2237427335", "name": "Peter
      Bartholomew"}]}, {"paperId": "c19382eb26ee614a77b6ad52d525b5fa88ebc924", "externalIds":
      {"DBLP": "journals/corr/abs-2309-08913", "ArXiv": "2309.08913", "DOI": "10.48550/arXiv.2309.08913",
      "CorpusId": 262043684}, "corpusId": 262043684, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/c19382eb26ee614a77b6ad52d525b5fa88ebc924",
      "title": "A Statistical Turing Test for Generative Models", "abstract": "The
      emergence of human-like abilities of AI systems for content generation in domains
      such as text, audio, and vision has prompted the development of classifiers
      to determine whether content originated from a human or a machine. Implicit
      in these efforts is an assumption that the generation properties of a human
      are different from that of the machine. In this work, we provide a framework
      in the language of statistical pattern recognition that quantifies the difference
      between the distributions of human and machine-generated content conditioned
      on an evaluation context. We describe current methods in the context of the
      framework and demonstrate how to use the framework to evaluate the progression
      of generative models towards human-like capabilities, among many axes of analysis.",
      "venue": "arXiv.org", "year": 2023, "referenceCount": 47, "citationCount": 0,
      "influentialCitationCount": 0, "isOpenAccess": true, "openAccessPdf": {"url":
      "https://arxiv.org/pdf/2309.08913", "status": "CLOSED"}, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2023-09-16", "journal": {"name": "ArXiv",
      "volume": "abs/2309.08913"}, "citationStyles": {"bibtex": "@Article{Helm2023AST,\n
      author = {Hayden S. Helm and Carey E. Priebe and Weiwei Yang},\n booktitle =
      {arXiv.org},\n journal = {ArXiv},\n title = {A Statistical Turing Test for Generative
      Models},\n volume = {abs/2309.08913},\n year = {2023}\n}\n"}, "authors": [{"authorId":
      "134059919", "name": "Hayden S. Helm"}, {"authorId": "2068800231", "name": "Carey
      E. Priebe"}, {"authorId": "2117131236", "name": "Weiwei Yang"}]}, {"paperId":
      "e16bde8fee55c3ffd240a9e7e47e1742ee5afb97", "externalIds": {"ArXiv": "2311.16342",
      "DBLP": "journals/corr/abs-2311-16342", "DOI": "10.48550/arXiv.2311.16342",
      "CorpusId": 265466351}, "corpusId": 265466351, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/e16bde8fee55c3ffd240a9e7e47e1742ee5afb97",
      "title": "Matrix Multiplication in Quadratic Time and Energy? Towards a Fine-Grained
      Energy-Centric Church-Turing Thesis", "abstract": "We describe two algorithms
      for multiplying n x n matrices using time and energy n^2 polylog(n) under basic
      models of classical physics. The first algorithm is for multiplying integer-valued
      matrices, and the second, quite different algorithm, is for Boolean matrix multiplication.
      We hope this work inspires a deeper consideration of physically plausible/realizable
      models of computing that might allow for algorithms which improve upon the runtimes
      and energy usages suggested by the parallel RAM model in which each operation
      requires one unit of time and one unit of energy.", "venue": "arXiv.org", "year":
      2023, "referenceCount": 17, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Physics", "source": "s2-fos-model"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2023-11-27", "journal": {"name": "ArXiv", "volume": "abs/2311.16342"}, "citationStyles":
      {"bibtex": "@Article{Valiant2023MatrixMI,\n author = {Gregory Valiant},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {Matrix Multiplication in Quadratic
      Time and Energy? Towards a Fine-Grained Energy-Centric Church-Turing Thesis},\n
      volume = {abs/2311.16342},\n year = {2023}\n}\n"}, "authors": [{"authorId":
      "2265960806", "name": "Gregory Valiant"}]}, {"paperId": "9b15d747d8341cc12e74a9dc539f93d57842cf21",
      "externalIds": {"MAG": "3036645521", "ArXiv": "2006.11373", "DBLP": "journals/corr/abs-2006-11373",
      "DOI": "10.2139/ssrn.3624282", "CorpusId": 219966912}, "corpusId": 219966912,
      "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org",
      "alternate_names": ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"},
      "url": "https://www.semanticscholar.org/paper/9b15d747d8341cc12e74a9dc539f93d57842cf21",
      "title": "Deceiving Computers in Reverse Turing Test through Deep Learning",
      "abstract": "It is increasingly becoming difficult for human beings to work
      on their day to day life without going through the process of reverse Turing
      test, where the Computers tests the users to be humans or not. Almost every
      website and service providers today have the process of checking whether their
      website is being crawled or not by automated bots which could extract valuable
      information from their site. In the process the bots are getting more intelligent
      by the use of Deep Learning techniques to decipher those tests and gain unwanted
      automated access to data while create nuisance by posting spam. Humans spend
      a considerable amount of time almost every day when trying to decipher CAPTCHAs.
      The aim of this investigation is to check whether the use of a subset of commonly
      used CAPTCHAs, known as the text CAPTCHA is a reliable process for verifying
      their human customers. We mainly focused on the preprocessing step for every
      CAPTCHA which converts them in binary intensity and removes the confusion as
      much as possible and developed various models to correctly label as many CAPTCHAs
      as possible. We also suggested some ways to improve the process of verifying
      the humans which makes it easy for humans to solve the existing CAPTCHAs and
      difficult for bots to do the same.", "venue": "arXiv.org", "year": 2020, "referenceCount":
      14, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": true,
      "openAccessPdf": {"url": "https://arxiv.org/pdf/2006.11373", "status": "GREEN"},
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2020-06-01", "journal": {"name": "EngRN: Electronic"}, "citationStyles": {"bibtex":
      "@Article{Pal2020DeceivingCI,\n author = {Jimut Bahan Pal},\n booktitle = {arXiv.org},\n
      journal = {EngRN: Electronic},\n title = {Deceiving Computers in Reverse Turing
      Test through Deep Learning},\n year = {2020}\n}\n"}, "authors": [{"authorId":
      "108673467", "name": "Jimut Bahan Pal"}]}, {"paperId": "59fbd590e09c7b4dd18373e4990e7254cef984b7",
      "externalIds": {"DBLP": "journals/corr/abs-2001-07592", "MAG": "3003287862",
      "CorpusId": 208147652}, "corpusId": 208147652, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/59fbd590e09c7b4dd18373e4990e7254cef984b7",
      "title": "Turing analogues of G\u00f6del statements and computability of intelligence",
      "abstract": "We show that there is a mathematical obstruction to complete Turing
      computability of intelligence. This obstruction can be circumvented only if
      human reasoning is fundamentally unsound. The most compelling original argument
      for existence of such an obstruction was proposed by Penrose, however G\\\"odel,
      Turing and Lucas have also proposed such arguments. We first partially reformulate
      the argument of Penrose. In this formulation we argue that his argument works
      up to possibility of construction of a certain G\\\"odel statement. We then
      completely re-frame the argument in the language of Turing machines, and by
      partially defining our subject just enough, we show that a certain analogue
      of a G\\\"odel statement, or a G\\\"odel string as we call it in the language
      of Turing machines, can be readily constructed directly, without appeal to the
      G\\\"odel incompleteness theorem, and thus removing the final objection.", "venue":
      "arXiv.org", "year": 2020, "referenceCount": 20, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science",
      "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}, {"category": "Philosophy", "source":
      "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2020-01-21", "journal": {"name": "ArXiv",
      "volume": "abs/2001.07592"}, "citationStyles": {"bibtex": "@Article{Savelyev2020TuringAO,\n
      author = {Y. Savelyev},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title
      = {Turing analogues of G\u00f6del statements and computability of intelligence},\n
      volume = {abs/2001.07592},\n year = {2020}\n}\n"}, "authors": [{"authorId":
      "2042592", "name": "Y. Savelyev"}]}, {"paperId": "2c9bc37ffb555ca327aeebf769f2436fac1685d2",
      "externalIds": {"MAG": "3048401942", "ArXiv": "2008.04640", "DBLP": "journals/corr/abs-2008-04640",
      "CorpusId": 221095748}, "corpusId": 221095748, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/2c9bc37ffb555ca327aeebf769f2436fac1685d2",
      "title": "High-concurrency Custom-build Relational Database System''s design
      and SQL parser design based on Turing-complete automata", "abstract": "Database
      system is an indispensable part of software projects. It plays an important
      role in data organization and storage. Its performance and efficiency are directly
      related to the performance of software. Nowadays, we have many general relational
      database systems that can be used in our projects, such as SQL Server, MySQL,
      Oracle, etc. It is undeniable that in most cases, we can easily use these database
      systems to complete our projects, but considering the generality, the general
      database systems often can''t play the ultimate speed and fully adapt to our
      projects. In very few projects, we will need to design a database system that
      fully adapt to our projects and have a high efficiency and concurrency. Therefore,
      it is very important to consider a feasible solution of designing a database
      system (We only consider the relational database system here). Meanwhile, for
      a database system, SQL interpretation and execution module is necessary. According
      to the theory of formal language and automata, the realization of this module
      can be completed by automata. In our experiment, we made the following contributions:
      1) We designed a small relational database, and used the database to complete
      a highly concurrent student course selection system. 2) We design a general
      automaton module, which can complete the operation from parsing to execution.
      The using of strategy model and event driven design scheme is used and some
      improvement on general automata, for example a memory like structure is added
      to automata to make it better to store context. All these make the automata
      model can be used in a variety of occasions, not only the parsing and execution
      of SQL statements.", "venue": "arXiv.org", "year": 2020, "referenceCount": 0,
      "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf":
      null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2020-08-11", "journal": {"name": "ArXiv", "volume": "abs/2008.04640"}, "citationStyles":
      {"bibtex": "@Article{Huang2020HighconcurrencyCR,\n author = {Wanhong Huang},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {High-concurrency Custom-build
      Relational Database System''s design and SQL parser design based on Turing-complete
      automata},\n volume = {abs/2008.04640},\n year = {2020}\n}\n"}, "authors": [{"authorId":
      "2217789", "name": "Wanhong Huang"}]}, {"paperId": "b4240aecb20ba5f7575c0d68999337f7a8d811c7",
      "externalIds": {"MAG": "2935969996", "DBLP": "journals/corr/abs-1904-05061",
      "ArXiv": "1904.05061", "CorpusId": 131774001}, "corpusId": 131774001, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/b4240aecb20ba5f7575c0d68999337f7a8d811c7",
      "title": "A review on Neural Turing Machine", "abstract": "One of the major
      objectives of Artificial Intelligence is to design learning algorithms that
      are executed on a general purposes computational machines such as human brain.
      Neural Turing Machine (NTM) is a step towards realizing such a computational
      machine. The attempt is made here to run a systematic review on Neural Turing
      Machine. First, the mind-map and taxonomy of machine learning, neural networks,
      and Turing machine are introduced. Next, NTM is inspected in terms of concepts,
      structure, variety of versions, implemented tasks, comparisons, etc. Finally,
      the paper discusses on issues and ends up with several future works.", "venue":
      "arXiv.org", "year": 2019, "referenceCount": 81, "citationCount": 4, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle", "Review"], "publicationDate": "2019-04-10", "journal": {"name":
      "ArXiv", "volume": "abs/1904.05061"}, "citationStyles": {"bibtex": "@Article{Faradonbe2019ARO,\n
      author = {Soroor Malekmohamadi Faradonbe and Faramarz Safi Esfahani},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {A review on Neural Turing Machine},\n
      volume = {abs/1904.05061},\n year = {2019}\n}\n"}, "authors": [{"authorId":
      "123556355", "name": "Soroor Malekmohamadi Faradonbe"}, {"authorId": "3084734",
      "name": "Faramarz Safi Esfahani"}]}, {"paperId": "c9d7afd65b2127e6f0651bc7e13eeec1897ac8dd",
      "externalIds": {"MAG": "2125308790", "DBLP": "journals/corr/ZarembaS15", "ArXiv":
      "1505.00521", "CorpusId": 16228924}, "corpusId": 16228924, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/c9d7afd65b2127e6f0651bc7e13eeec1897ac8dd",
      "title": "Reinforcement Learning Neural Turing Machines", "abstract": "The expressive
      power of a machine learning model is closely related to the number of sequential
      computational steps it can learn. For example, Deep Neural Networks have been
      more successful than shallow networks because they can perform a greater number
      of sequential computational steps (each highly parallel). The Neural Turing
      Machine (NTM) [8] is a model that can compactly express an even greater number
      of sequential computational steps, so it is even more powerful than a DNN. Its
      memory addressing operations are designed to be differentiable; thus the NTM
      can be trained with backpropagation. While differentiable memory is relatively
      easy to implement and train, it necessitates accessing the entire memory content
      at each computational step. This makes it difficult to implement a fast NTM.
      In this work, we use the Re inforce algorithm to learn where to access the memory,
      while using backpropagation to learn what to write to the memory. We call this
      model the RL-NTM. Reinforce allows our model to access a constant number of
      memory cells at each computational step, so its implementation can be faster.
      The RL-NTM is the first mo del that can, in principle, learn programs of unbounded
      running time. We successfully trained the RL-NTM to solve a number of algorithmic
      tasks that are simpler than the ones solvable by the fully differentiable NTM.
      As the RL-NTM is a fairly intricate model, we needed a method for verifying
      the correctness of our implementation. To do so, we developed a simple technique
      for numerically checking arbitrary implementations of models that use Reinforce,
      which may be of independent interest.", "venue": "arXiv.org", "year": 2015,
      "referenceCount": 24, "citationCount": 165, "influentialCitationCount": 9, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2015-05-04", "journal": {"name": "ArXiv", "volume": "abs/1505.00521"},
      "citationStyles": {"bibtex": "@Article{Zaremba2015ReinforcementLN,\n author
      = {Wojciech Zaremba and I. Sutskever},\n booktitle = {arXiv.org},\n journal
      = {ArXiv},\n title = {Reinforcement Learning Neural Turing Machines},\n volume
      = {abs/1505.00521},\n year = {2015}\n}\n"}, "authors": [{"authorId": "2563432",
      "name": "Wojciech Zaremba"}, {"authorId": "1701686", "name": "I. Sutskever"}]},
      {"paperId": "e4d23379621a978fb51c4ddd727cda1da8dc428c", "externalIds": {"MAG":
      "2930954426", "DBLP": "journals/corr/abs-1904-02478", "ArXiv": "1904.02478",
      "CorpusId": 102353399}, "corpusId": 102353399, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/e4d23379621a978fb51c4ddd727cda1da8dc428c",
      "title": "Learning Numeracy: Binary Arithmetic with Neural Turing Machines",
      "abstract": "One of the main problems encountered so far with recurrent neural
      networks is that they struggle to retain long-time information dependencies
      in their recurrent connections. Neural Turing Machines (NTMs) attempt to mitigate
      this issue by providing the neural network with an external portion of memory,
      in which information can be stored and manipulated later on. The whole mechanism
      is differentiable end-to-end, allowing the network to learn how to utilise this
      long-term memory via stochastic gradient descent. This allows NTMs to infer
      simple algorithms directly from data sequences. Nonetheless, the model can be
      hard to train due to a large number of parameters and interacting components
      and little related work is present. In this work we use NTMs to learn and generalise
      two arithmetical tasks: binary addition and multiplication. These tasks are
      two fundamental algorithmic examples in computer science, and are a lot more
      challenging than the previously explored ones, with which we aim to shed some
      light on the real capabilities on this neural model.", "venue": "arXiv.org",
      "year": 2019, "referenceCount": 30, "citationCount": 2, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2019-04-04", "journal": {"name": "ArXiv", "volume": "abs/1904.02478"}, "citationStyles":
      {"bibtex": "@Article{Castellini2019LearningNB,\n author = {Jacopo Castellini},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Learning Numeracy:
      Binary Arithmetic with Neural Turing Machines},\n volume = {abs/1904.02478},\n
      year = {2019}\n}\n"}, "authors": [{"authorId": "8755079", "name": "Jacopo Castellini"}]},
      {"paperId": "20b7ccf5b76d876973d6ba82c8fa3a1b9b16aa34", "externalIds": {"DBLP":
      "journals/corr/abs-1903-07837", "MAG": "2922218648", "ArXiv": "1903.07837",
      "CorpusId": 83458758}, "corpusId": 83458758, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/20b7ccf5b76d876973d6ba82c8fa3a1b9b16aa34",
      "title": "Turing-Completeness of Dynamics in Abstract Persuasion Argumentation",
      "abstract": "Abstract Persuasion Argumentation (APA) is a dynamic argumentation
      formalism that extends Dung argumentation with persuasion relations. In this
      work, we show through two-counter Minsky machine encoding that APA dynamics
      is Turing-complete.", "venue": "arXiv.org", "year": 2019, "referenceCount":
      3, "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Mathematics"],
      "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2019-03-19", "journal":
      {"name": "ArXiv", "volume": "abs/1903.07837"}, "citationStyles": {"bibtex":
      "@Article{Arisaka2019TuringCompletenessOD,\n author = {Ryuta Arisaka},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {Turing-Completeness of Dynamics
      in Abstract Persuasion Argumentation},\n volume = {abs/1903.07837},\n year =
      {2019}\n}\n"}, "authors": [{"authorId": "2104370", "name": "Ryuta Arisaka"}]},
      {"paperId": "154e736e2ddbcd71e090403e9b28b26d52ec0d55", "externalIds": {"MAG":
      "2949710727", "DBLP": "journals/corr/abs-1906-05833", "CorpusId": 189762070},
      "corpusId": 189762070, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/154e736e2ddbcd71e090403e9b28b26d52ec0d55",
      "title": "There is no general AI: Why Turing machines cannot pass the Turing
      test", "abstract": "Since 1950, when Alan Turing proposed what has since come
      to be called the Turing test, the ability of a machine to pass this test has
      established itself as the primary hallmark of general AI. To pass the test,
      a machine would have to be able to engage in dialogue in such a way that a human
      interrogator could not distinguish its behaviour from that of a human being.
      AI researchers have attempted to build machines that could meet this requirement,
      but they have so far failed. To pass the test, a machine would have to meet
      two conditions: (i) react appropriately to the variance in human dialogue and
      (ii) display a human-like personality and intentions. We argue, first, that
      it is for mathematical reasons impossible to program a machine which can master
      the enormously complex and constantly evolving pattern of variance which human
      dialogues contain. And second, that we do not know how to make machines that
      possess personality and intentions of the sort we find in humans. Since a Turing
      machine cannot master human dialogue behaviour, we conclude that a Turing machine
      also cannot possess what is called ``general'''' Artificial Intelligence. We
      do, however, acknowledge the potential of Turing machines to master dialogue
      behaviour in highly restricted contexts, where what is called ``narrow'''' AI
      can still be of considerable utility.", "venue": "arXiv.org", "year": 2019,
      "referenceCount": 85, "citationCount": 2, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Philosophy", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2019-06-09", "journal":
      {"name": "ArXiv", "volume": "abs/1906.05833"}, "citationStyles": {"bibtex":
      "@Article{Landgrebe2019ThereIN,\n author = {J. Landgrebe and B. Smith},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {There is no general AI: Why Turing
      machines cannot pass the Turing test},\n volume = {abs/1906.05833},\n year =
      {2019}\n}\n"}, "authors": [{"authorId": "120743060", "name": "J. Landgrebe"},
      {"authorId": "2157085550", "name": "B. Smith"}]}, {"paperId": "839e30cc776a999a1a6da72621d52d3a556ad1c7",
      "externalIds": {"ArXiv": "1901.06613", "MAG": "2911899023", "DBLP": "journals/corr/abs-1901-06613",
      "CorpusId": 58981345}, "corpusId": 58981345, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/839e30cc776a999a1a6da72621d52d3a556ad1c7",
      "title": "Beyond Turing: Intelligent Agents Centered on the User", "abstract":
      "Most research on intelligent agents centers on the agent and not on the user.
      We look at the origins of agent-centric research for slot-filling, gaming and
      chatbot agents. We then argue that it is important to concentrate more on the
      user. After reviewing relevant literature, some approaches for creating and
      assessing user-centric systems are proposed.", "venue": "arXiv.org", "year":
      2019, "referenceCount": 42, "citationCount": 12, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}, {"category": "Philosophy",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Review"],
      "publicationDate": "2019-01-20", "journal": {"name": "ArXiv", "volume": "abs/1901.06613"},
      "citationStyles": {"bibtex": "@Article{Esk\u00e9nazi2019BeyondTI,\n author =
      {M. Esk\u00e9nazi and Shikib Mehri and E. Razumovskaia and Tiancheng Zhao},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Beyond Turing: Intelligent
      Agents Centered on the User},\n volume = {abs/1901.06613},\n year = {2019}\n}\n"},
      "authors": [{"authorId": "1716325", "name": "M. Esk\u00e9nazi"}, {"authorId":
      "32251567", "name": "Shikib Mehri"}, {"authorId": "66879943", "name": "E. Razumovskaia"},
      {"authorId": "8200875", "name": "Tiancheng Zhao"}]}, {"paperId": "dda1822872942f658b89e7e1c1ffe08c35e7b290",
      "externalIds": {"ArXiv": "1709.08693", "MAG": "2759063673", "DBLP": "journals/corr/abs-1709-08693",
      "CorpusId": 195346581}, "corpusId": 195346581, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290",
      "title": "Can you fool AI with adversarial examples on a visual Turing test?",
      "abstract": "Deep learning has achieved impressive results in many areas of
      Computer Vision and Natural Language Pro- cessing. Among others, Visual Question
      Answering (VQA), also referred to a visual Turing test, is considered one of
      the most compelling problems, and recent deep learning models have reported
      significant progress in vision and language modeling. Although Artificial Intelligence
      (AI) is getting closer to passing the visual Turing test, at the same time the
      existence of adversarial examples to deep learning systems may hinder the practical
      application of such systems. In this work, we conduct the first extensive study
      on adversarial examples for VQA systems. In particular, we focus on generating
      targeted adversarial examples for a VQA system while the target is considered
      to be a question-answer pair. Our evaluation shows that the success rate of
      whether a targeted adversarial example can be generated is mostly dependent
      on the choice of the target question-answer pair, and less on the choice of
      images to which the question refers. We also report the language prior phenomenon
      of a VQA model, which can explain why targeted adversarial examples are hard
      to generate for some question-answer targets. We also demonstrate that a compositional
      VQA architecture is slightly more resilient to adversarial attacks than a non-compositional
      one. Our study sheds new light on how to build deep vision and language resilient
      models robust against adversarial examples.", "venue": "arXiv.org", "year":
      2017, "referenceCount": 70, "citationCount": 41, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2017-09-25", "journal": {"name": "ArXiv",
      "volume": "abs/1709.08693"}, "citationStyles": {"bibtex": "@Article{Xu2017CanYF,\n
      author = {Xiaojun Xu and Xinyun Chen and Chang Liu and Anna Rohrbach and Trevor
      Darrell and D. Song},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title
      = {Can you fool AI with adversarial examples on a visual Turing test?},\n volume
      = {abs/1709.08693},\n year = {2017}\n}\n"}, "authors": [{"authorId": "2108880352",
      "name": "Xiaojun Xu"}, {"authorId": "1425082935", "name": "Xinyun Chen"}, {"authorId":
      "2118484320", "name": "Chang Liu"}, {"authorId": "34721166", "name": "Anna Rohrbach"},
      {"authorId": "1753210", "name": "Trevor Darrell"}, {"authorId": "143711382",
      "name": "D. Song"}]}, {"paperId": "6a10ce04a28d2b34c102133fcf94ff299d1e1780",
      "externalIds": {"DBLP": "journals/corr/abs-1905-12734", "ArXiv": "1905.12734",
      "MAG": "2947997817", "CorpusId": 170078578}, "corpusId": 170078578, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/6a10ce04a28d2b34c102133fcf94ff299d1e1780",
      "title": "Sub-Turing Islands in the Wild", "abstract": "Recently, there has
      been growing debate as to whether or not static analysis can be truly sound.
      In spite of this concern, research on techniques seeking to at least partially
      answer undecidable questions has a long history. However, little attention has
      been given to the more empirical question of how often an exact solution might
      be given to a question despite the question being, at least in theory, undecidable.
      This paper investigates this issue by exploring sub-Turing islands -- regions
      of code for which a question of interest is decidable. We define such islands
      and then consider how to identify them. We implemented Cook, a prototype for
      finding sub-Turing islands and applied it to a corpus of 1100 Android applications,
      containing over 2 million methods. Results reveal that 55\\% of the all methods
      are sub-Turing. Our results also provide empirical, scientific evidence for
      the scalability of sub-Turing island identification. Sub-Turing identification
      has many downstream applications, because islands are so amenable to static
      analysis. We illustrate two downstream uses of the analysis. In the first, we
      found that over 37\\% of the verification conditions associated with runtime
      exceptions fell within sub-Turing islands and thus are statically decidable.
      A second use of our analysis is during code review where it provides guidance
      to developers. The sub-Turing islands from our study turns out to contain significantly
      fewer bugs than `theswamp'' (non sub-Turing methods). The greater bug density
      in the swamp is unsurprising; the fact that bugs remain prevalent in islands
      is, however, surprising: these are bugs whose repair can be fully automated.",
      "venue": "arXiv.org", "year": 2019, "referenceCount": 71, "citationCount": 1,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle", "Review"], "publicationDate":
      "2019-05-29", "journal": {"name": "ArXiv", "volume": "abs/1905.12734"}, "citationStyles":
      {"bibtex": "@Article{Barr2019SubTuringII,\n author = {Earl T. Barr and D. Binkley
      and M. Harman and M. Seghir},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Sub-Turing Islands in the Wild},\n volume = {abs/1905.12734},\n year
      = {2019}\n}\n"}, "authors": [{"authorId": "1757975", "name": "Earl T. Barr"},
      {"authorId": "3408880", "name": "D. Binkley"}, {"authorId": "145836176", "name":
      "M. Harman"}, {"authorId": "31433415", "name": "M. Seghir"}]}, {"paperId": "10234b876b1e0cec42db32f560f8a8cbae7d40cf",
      "externalIds": {"DBLP": "journals/corr/abs-1902-00975", "MAG": "2913719695",
      "ArXiv": "1902.00975", "CorpusId": 59599703}, "corpusId": 59599703, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/10234b876b1e0cec42db32f560f8a8cbae7d40cf",
      "title": "Some Remarks on Real-Time Turing Machines", "abstract": "The power
      of real-time Turing machines using sublinear space is investigated. In contrast
      to a claim appearing in the literature, such machines can accept non-regular
      languages, even if working in deterministic mode. While maintaining a standard
      binary counter appears to be impossible in real-time, we present a guess and
      check approach that yields a binary representation of the input length. Based
      on this technique, we show that unary encodings of languages accepted in exponential
      time can be recognized by nondeterministic real-time Turing machines.", "venue":
      "arXiv.org", "year": 2019, "referenceCount": 10, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics",
      "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2019-02-03", "journal": {"name": "ArXiv", "volume": "abs/1902.00975"}, "citationStyles":
      {"bibtex": "@Article{Petersen2019SomeRO,\n author = {H. Petersen},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {Some Remarks on Real-Time Turing
      Machines},\n volume = {abs/1902.00975},\n year = {2019}\n}\n"}, "authors": [{"authorId":
      "144511065", "name": "H. Petersen"}]}, {"paperId": "1335201fb3ed413fa7879d732bc47623c65d2683",
      "externalIds": {"ArXiv": "1907.04211", "MAG": "2962211741", "DBLP": "journals/corr/abs-1907-04211",
      "CorpusId": 195847986}, "corpusId": 195847986, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/1335201fb3ed413fa7879d732bc47623c65d2683",
      "title": "Universal One-Dimensional Cellular Automata Derived for Turing Machines
      and its Dynamical Behaviour", "abstract": "Universality in cellular automata
      theory is a central problem studied and developed from their origins by John
      von Neumann. In this paper, we present an algorithm where any Turing machine
      can be converted to one-dimensional cellular automaton with a 2-linear time
      and display its spatial dynamics. Three particular Turing machines are converted
      in three universal one-dimensional cellular automata, they are: binary sum,
      rule 110 and a universal reversible Turing machine.", "venue": "arXiv.org",
      "year": 2019, "referenceCount": 31, "citationCount": 1, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Physics"], "s2FieldsOfStudy": [{"category": "Computer Science", "source":
      "external"}, {"category": "Physics", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2019-07-06", "journal":
      {"name": "ArXiv", "volume": "abs/1907.04211"}, "citationStyles": {"bibtex":
      "@Article{Mart\u00ednez2019UniversalOC,\n author = {Sergio J. Mart\u00ednez
      and Iv\u00e1n M. Mendoza and G. J. Mart\u00ednez and S. Ninagawa},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {Universal One-Dimensional Cellular
      Automata Derived for Turing Machines and its Dynamical Behaviour},\n volume
      = {abs/1907.04211},\n year = {2019}\n}\n"}, "authors": [{"authorId": "148090801",
      "name": "Sergio J. Mart\u00ednez"}, {"authorId": "49521580", "name": "Iv\u00e1n
      M. Mendoza"}, {"authorId": "2245642443", "name": "G. J. Mart\u00ednez"}, {"authorId":
      "1726520", "name": "S. Ninagawa"}]}, {"paperId": "445dbe5368386e984a019fd4f372950836274cdb",
      "externalIds": {"MAG": "2972179875", "ArXiv": "1909.02399", "DBLP": "journals/corr/abs-1909-02399",
      "CorpusId": 202538964}, "corpusId": 202538964, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/445dbe5368386e984a019fd4f372950836274cdb",
      "title": "Reading Comprehension Ability Test-A Turing Test for Reading Comprehension",
      "abstract": "Reading comprehension is an important ability of human intelligence.
      Literacy and numeracy are two most essential foundation for people to succeed
      at study, at work and in life. Reading comprehension ability is a core component
      of literacy. In most of the education systems, developing reading comprehension
      ability is compulsory in the curriculum from year one to year 12. It is an indispensable
      ability in the dissemination of knowledge. With the emerging artificial intelligence,
      computers start to be able to read and understand like people in some context.
      They can even read better than human beings for some tasks, but have little
      clue in other tasks. It will be very beneficial if we can identify the levels
      of machine comprehension ability, which will direct us on the further improvement.
      Turing test is a well-known test of the difference between computer intelligence
      and human intelligence. In order to be able to compare the difference between
      people reading and machines reading, we proposed a test called (reading) Comprehension
      Ability Test (CAT).CAT is similar to Turing test, passing of which means we
      cannot differentiate people from algorithms in term of their comprehension ability.
      CAT has multiple levels showing the different abilities in reading comprehension,
      from identifying basic facts, performing inference, to understanding the intent
      and sentiment.", "venue": "arXiv.org", "year": 2019, "referenceCount": 7, "citationCount":
      1, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Education", "source": "s2-fos-model"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-09-05", "journal": {"name": "ArXiv",
      "volume": "abs/1909.02399"}, "citationStyles": {"bibtex": "@Article{Miao2019ReadingCA,\n
      author = {Yuan Miao and Gongqi Lin and Yidan Hu and C. Miao},\n booktitle =
      {arXiv.org},\n journal = {ArXiv},\n title = {Reading Comprehension Ability Test-A
      Turing Test for Reading Comprehension},\n volume = {abs/1909.02399},\n year
      = {2019}\n}\n"}, "authors": [{"authorId": "50273189", "name": "Yuan Miao"},
      {"authorId": "2113477918", "name": "Gongqi Lin"}, {"authorId": "3371473", "name":
      "Yidan Hu"}, {"authorId": "1679209", "name": "C. Miao"}]}, {"paperId": "906ac7584faf8ead6004be4cc5122320c87df59c",
      "externalIds": {"ArXiv": "1607.00036", "MAG": "2470713034", "DBLP": "journals/corr/GulcehreCCB16",
      "CorpusId": 1399676}, "corpusId": 1399676, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/906ac7584faf8ead6004be4cc5122320c87df59c",
      "title": "Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes",
      "abstract": "We extend neural Turing machine (NTM) model into a dynamic neural
      Turing machine (D-NTM) by introducing a trainable memory addressing scheme.
      This addressing scheme maintains for each memory cell two separate vectors,
      content and address vectors. This allows the D-NTM to learn a wide variety of
      location-based addressing strategies including both linear and nonlinear ones.
      We implement the D-NTM with both continuous, differentiable and discrete, non-differentiable
      read/write mechanisms. We investigate the mechanisms and effects of learning
      to read and write into a memory through experiments on Facebook bAbI tasks using
      both a feedforward and GRUcontroller. The D-NTM is evaluated on a set of Facebook
      bAbI tasks and shown to outperform NTM and LSTM baselines. We have done extensive
      analysis of our model and different variations of NTM on bAbI task. We also
      provide further experimental results on sequential pMNIST, Stanford Natural
      Language Inference, associative recall and copy tasks.", "venue": "arXiv.org",
      "year": 2016, "referenceCount": 46, "citationCount": 57, "influentialCitationCount":
      8, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2016-06-30", "journal": {"name": "ArXiv",
      "volume": "abs/1607.00036"}, "citationStyles": {"bibtex": "@Article{G\u00fcl\u00e7ehre2016DynamicNT,\n
      author = {\u00c7aglar G\u00fcl\u00e7ehre and A. Chandar and Kyunghyun Cho and
      Yoshua Bengio},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Dynamic
      Neural Turing Machine with Soft and Hard Addressing Schemes},\n volume = {abs/1607.00036},\n
      year = {2016}\n}\n"}, "authors": [{"authorId": "1854385", "name": "\u00c7aglar
      G\u00fcl\u00e7ehre"}, {"authorId": "144631588", "name": "A. Chandar"}, {"authorId":
      "1979489", "name": "Kyunghyun Cho"}, {"authorId": "1751762", "name": "Yoshua
      Bengio"}]}, {"paperId": "13d6471ff8a1d05f5d0c7e7a72603d9769e3ffb4", "externalIds":
      {"DBLP": "journals/corr/abs-1905-06311", "MAG": "2944980240", "ArXiv": "1905.06311",
      "CorpusId": 155093102}, "corpusId": 155093102, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/13d6471ff8a1d05f5d0c7e7a72603d9769e3ffb4",
      "title": "Inquiry of P-reduction in Cook''s 1971 Paper - from Oracle machine
      to Turing machine", "abstract": "In this paper, we inquire the key concept P-reduction
      in Cook''s theorem and reveal that there exists the fallacy of definition in
      P-reduction caused by the disguised displacement of NDTM from Oracle machine
      to Turing machine. The definition or derivation of P-reduction is essentially
      equivalent to Turing''s computability. Whether NP problems might been reduced
      to logical forms (tautology or SAT) or NP problems might been reduced each other,
      they have not been really proven in Cook''s 1971 paper.", "venue": "arXiv.org",
      "year": 2019, "referenceCount": 14, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-04-30", "journal": {"name": "ArXiv",
      "volume": "abs/1905.06311"}, "citationStyles": {"bibtex": "@Article{Zhou2019InquiryOP,\n
      author = {JianMing Zhou and Yu Li},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Inquiry of P-reduction in Cook''s 1971 Paper - from Oracle machine
      to Turing machine},\n volume = {abs/1905.06311},\n year = {2019}\n}\n"}, "authors":
      [{"authorId": "2112367844", "name": "JianMing Zhou"}, {"authorId": "2116612064",
      "name": "Yu Li"}]}, {"paperId": "a893430c89cf27e5b6fd9e19e6cee4f2b8d52dbc",
      "externalIds": {"ArXiv": "1901.07125", "DBLP": "journals/corr/abs-1901-07125",
      "MAG": "2914561188", "CorpusId": 58981696}, "corpusId": 58981696, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/a893430c89cf27e5b6fd9e19e6cee4f2b8d52dbc",
      "title": "The Power of One-State Turing Machines", "abstract": "At first glance,
      one-state Turing machines are very weak: the halting problem for them is decidable,
      and, without memory, they cannot even accept a simple one element language such
      as $L = \\{ 1 \\}$ . Nevertheless it has been showed that a one-state Turing
      machine can accept non regular languages. We extend such result and prove that
      they can also recognize non context-free languages, so for some tasks they are
      more powerful than pushdown automata.", "venue": "arXiv.org", "year": 2019,
      "referenceCount": 7, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics", "Computer Science"],
      "s2FieldsOfStudy": [{"category": "Mathematics", "source": "external"}, {"category":
      "Computer Science", "source": "external"}, {"category": "Computer Science",
      "source": "s2-fos-model"}, {"category": "Mathematics", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2019-01-22", "journal":
      {"name": "ArXiv", "volume": "abs/1901.07125"}, "citationStyles": {"bibtex":
      "@Article{Biasi2019ThePO,\n author = {M. D. Biasi},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {The Power of One-State Turing Machines},\n volume
      = {abs/1901.07125},\n year = {2019}\n}\n"}, "authors": [{"authorId": "35048687",
      "name": "M. D. Biasi"}]}, {"paperId": "2ccd1a446c3e512104a6cfdc6367ec435b803bd9",
      "externalIds": {"ArXiv": "1907.06432", "DBLP": "journals/corr/abs-1907-06432",
      "MAG": "2956310154", "CorpusId": 196621673}, "corpusId": 196621673, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/2ccd1a446c3e512104a6cfdc6367ec435b803bd9",
      "title": "A Neural Turing~Machine for Conditional Transition Graph Modeling",
      "abstract": "Graphs are an essential part of many machine learning problems
      such as analysis of parse trees, social networks, knowledge graphs, transportation
      systems, and molecular structures. Applying machine learning in these areas
      typically involves learning the graph structure and the relationship between
      the nodes of the graph. However, learning the graph structure is often complex,
      particularly when the graph is cyclic, and the transitions from one node to
      another are conditioned such as graphs used to represent a finite state machine.
      To solve this problem, we propose to extend the memory based Neural Turing Machine
      (NTM) with two novel additions. We allow for transitions between nodes to be
      influenced by information received from external environments, and we let the
      NTM learn the context of those transitions. We refer to this extension as the
      Conditional Neural Turing Machine (CNTM). \nWe show that the CNTM can infer
      conditional transition graphs by empirically verifiying the model on two data
      sets: a large set of randomly generated graphs, and a graph modeling the information
      retrieval process during certain crisis situations. The results show that the
      CNTM is able to reproduce the paths inside the graph with accuracy ranging from
      82,12% for 10 nodes graphs to 65,25% for 100 nodes graphs.", "venue": "arXiv.org",
      "year": 2019, "referenceCount": 27, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-07-15", "journal": {"name": "ArXiv",
      "volume": "abs/1907.06432"}, "citationStyles": {"bibtex": "@Article{Lazreg2019ANT,\n
      author = {M. B. Lazreg and M. G. Olsen and Ole-Christoffer Granmo},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {A Neural Turing~Machine for Conditional
      Transition Graph Modeling},\n volume = {abs/1907.06432},\n year = {2019}\n}\n"},
      "authors": [{"authorId": "1840275", "name": "M. B. Lazreg"}, {"authorId": "1833672",
      "name": "M. G. Olsen"}, {"authorId": "2493161", "name": "Ole-Christoffer Granmo"}]},
      {"paperId": "9c90c0fa5d247066c81fffc8bf01dcde2d7f7086", "externalIds": {"MAG":
      "2918081331", "DBLP": "journals/corr/abs-1902-07245", "CorpusId": 67770964},
      "corpusId": 67770964, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/9c90c0fa5d247066c81fffc8bf01dcde2d7f7086",
      "title": "Continuous Ordinary Differential Equations and Infinite Time Turing
      Machines", "abstract": "We consider Continuous Ordinary Differential Equations
      (CODE) y''=f(y), where f is a continuous function. They are known to always
      have solutions for a given initial condition y(0)=y0, these solutions being
      possibly non unique. We restrict to our attention to a class of continuous functions,
      that we call greedy: they always admit unique greedy solutions, i.e. going in
      greedy way in some fixed direction. \nWe prove that they can be seen as models
      of computation over the ordinals (Infinite Time Turing Machines, ITTM) and conversely
      in a very strong sense. \nIn particular, for such ODEs, to a greedy trajectory
      can be associated some ordinal corresponding to some time of computation, and
      conversely models of computation over the ordinals can be associated to some
      CODE. In particular, analyzing reachability for one or the other concept with
      respect to greedy trajectories has the same hardness. This also brings new perspectives
      on analysis in Mathematics, by providing ways to translate results for ITTMs
      to CODEs. This also extends some recent results about the relations between
      ordinary differential equations and Turing machines, and more widely with (generalized)
      computability theory.", "venue": "arXiv.org", "year": 2019, "referenceCount":
      30, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science", "Mathematics"],
      "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Mathematics", "source": "external"}, {"category": "Mathematics",
      "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2019-02-19", "journal":
      {"name": "ArXiv", "volume": "abs/1902.07245"}, "citationStyles": {"bibtex":
      "@Article{Bournez2019ContinuousOD,\n author = {Olivier Bournez and S. Ouazzani},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Continuous Ordinary
      Differential Equations and Infinite Time Turing Machines},\n volume = {abs/1902.07245},\n
      year = {2019}\n}\n"}, "authors": [{"authorId": "1706341", "name": "Olivier Bournez"},
      {"authorId": "11263956", "name": "S. Ouazzani"}]}, {"paperId": "b6496718fc89f5c096bbb6706bb7d676c599a5f9",
      "externalIds": {"ArXiv": "1903.09653", "MAG": "2922737564", "DBLP": "journals/corr/abs-1903-09653",
      "CorpusId": 85498441}, "corpusId": 85498441, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/b6496718fc89f5c096bbb6706bb7d676c599a5f9",
      "title": "Anti-Turing Machine", "abstract": "The invention of CPU-centric computing
      paradigm was incredible breakthrough of computer science that revolutionized
      our everyday life dramatically. However, the CPU- centric paradigm is based
      on the Turing machine concept and, as a result, expensive and power-hungry data
      transferring between the memory and CPU core is inevitable operation. Anti-Turing
      machine paradigm can be based on two fundamental principles: (1) data-centric
      computing, and (2) decentralized computing. Anti-Turing machine is able to execute
      a special type of programs. The commands of such program have to be addressed
      to the 2D or 3D persistent memory space is able to process data in-place. This
      program should not define the position or structure of data but it has to define
      the goal of data processing activity. Generally speaking, it needs to consider
      the whole memory space like the data transformation space. But the data placement,
      particular algorithm implementation, and strategy of algorithm execution are
      out of scope of the program.", "venue": "arXiv.org", "year": 2019, "referenceCount":
      7, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2019-03-22", "journal": {"name": "ArXiv", "volume": "abs/1903.09653"},
      "citationStyles": {"bibtex": "@Article{Dubeyko2019AntiTuringM,\n author = {Viacheslav
      Dubeyko},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Anti-Turing
      Machine},\n volume = {abs/1903.09653},\n year = {2019}\n}\n"}, "authors": [{"authorId":
      "35625237", "name": "Viacheslav Dubeyko"}]}, {"paperId": "11b3bb83b8e871f75ba08214f9977b5b4a4cd434",
      "externalIds": {"MAG": "2966467752", "DBLP": "journals/corr/abs-1908-01994",
      "ArXiv": "1908.01994", "CorpusId": 199452992}, "corpusId": 199452992, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/11b3bb83b8e871f75ba08214f9977b5b4a4cd434",
      "title": "Comprehensive Fuzzy Turing Machines, An Evolution to the Concept of
      Finite State Machine Control", "abstract": "The Turing machine is an abstract
      concept of a computing device which introduced new models for computation. The
      idea of Fuzzy algorithms defined by Zadeh and Lee was followed by introducing
      Fuzzy Turing Machine (FTM) to create a platform for a new fuzzy computation
      model. Then, in his investigations on its computational power, Wiedermann showed
      that FTM is able to solve undecidable problems. His suggested FTM structure,
      which highly resembles the original definition was one of the most well-known
      classical definitions of FTM this http URL improve some of its weaknesses and
      vague points which will be discussed extensively in this paper, we will develop
      a more complete definition for fuzzy Turing machines. Our proposed definition
      of FTM, which encompasses the conventional definition, is motivated from the
      definition of General Fuzzy Automata (GFA) introduced by Doostfatemeh and Kremer.
      As it improved the conventional definition of fuzzy automata, especially the
      problem of membership assignment and multi-membership resolution, we also improved
      the same aspects of FTM through the definition of Comprehensive Fuzzy Turing
      Machine (CFTM). In addition, we address on some possible vaguenesses in FTM
      was not the subject of focus in fuzzy automata. As example, we investigate the
      issue of multi-path and multi-direction which are possible in case of nondeterminism.
      Finally, we show the simplicity, applicability and computational efficiency
      of the CFTM through an explanatory example.", "venue": "arXiv.org", "year":
      2019, "referenceCount": 12, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Engineering"], "s2FieldsOfStudy": [{"category": "Computer Science",
      "source": "external"}, {"category": "Engineering", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2019-08-06", "journal": {"name": "ArXiv", "volume": "abs/1908.01994"},
      "citationStyles": {"bibtex": "@Article{Ahang2019ComprehensiveFT,\n author =
      {N. Ahang and A. Torabi and M. Doostfatemeh},\n booktitle = {arXiv.org},\n journal
      = {ArXiv},\n title = {Comprehensive Fuzzy Turing Machines, An Evolution to the
      Concept of Finite State Machine Control},\n volume = {abs/1908.01994},\n year
      = {2019}\n}\n"}, "authors": [{"authorId": "103473852", "name": "N. Ahang"},
      {"authorId": "34654901", "name": "A. Torabi"}, {"authorId": "2083881", "name":
      "M. Doostfatemeh"}]}, {"paperId": "8ff2ed2ac3b5c91261fd1f8b5694b12886aeca95",
      "externalIds": {"DBLP": "journals/corr/abs-1911-05832", "ArXiv": "1911.05832",
      "MAG": "2988969040", "CorpusId": 208006389}, "corpusId": 208006389, "publicationVenue":
      {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10", "name": "arXiv.org", "alternate_names":
      ["ArXiv"], "issn": "2331-8422", "url": "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/8ff2ed2ac3b5c91261fd1f8b5694b12886aeca95",
      "title": "Inverse design of fluid flow structure with Turing pattern", "abstract":
      "Microchannel reactors are critical in biological plus energy-related applications
      and require meticulous design of hundreds-to-thousands of fluid flow channels.
      Such systems commonly comprise intricate space-filling microstructures to control
      the fluid flow distribution for the reaction process. Traditional flow channel
      design schemes are intuition-based or utilize analytical rule-based optimization
      strategies that are oversimplified for large-scale domains of arbitrary geometry.
      Here, a gradient-based optimization method is proposed, where effective porous
      media and fluid velocity vector design information is exploited and linked to
      explicit microchannel parameterizations. Reaction-diffusion equations are then
      utilized to generate space-filling Turing pattern microchannel flow structures
      from the porous media field. With this computationally efficient and broadly
      applicable technique, precise control of fluid flow distribution is demonstrated
      across large numbers (on the order of hundreds) of microchannels.", "venue":
      "arXiv.org", "year": 2019, "referenceCount": 23, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Engineering", "source": "s2-fos-model"}, {"category": "Physics",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2019-11-13", "journal": {"name": "ArXiv", "volume": "abs/1911.05832"}, "citationStyles":
      {"bibtex": "@Article{Dede2019InverseDO,\n author = {E. Dede and Yuqing Zhou
      and T. Nomura},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Inverse
      design of fluid flow structure with Turing pattern},\n volume = {abs/1911.05832},\n
      year = {2019}\n}\n"}, "authors": [{"authorId": "2191712", "name": "E. Dede"},
      {"authorId": "49454977", "name": "Yuqing Zhou"}, {"authorId": "32554646", "name":
      "T. Nomura"}]}, {"paperId": "bf3a6bb7afffadb93013844f64bb9c40911325df", "externalIds":
      {"DBLP": "journals/corr/abs-1906-11068", "ArXiv": "1906.11068", "MAG": "2955389962",
      "CorpusId": 195741908}, "corpusId": 195741908, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/bf3a6bb7afffadb93013844f64bb9c40911325df",
      "title": "Turing Test Revisited: A Framework for an Alternative", "abstract":
      "This paper aims to question the suitability of the Turing Test, for testing
      machine intelligence, in the light of advances made in the last 60 years in
      science, medicine, and philosophy of mind. While the main concept of the test
      may seem sound and valid, a detailed analysis of what is required to pass the
      test highlights a significant flow. Once the analysis of the test is presented,
      a systematic approach is followed in analysing what is needed to devise a test
      or tests for intelligent machines. The paper presents a plausible generic framework
      based on categories of factors implied by subjective perception of intelligence.
      An evaluative discussion concludes the paper highlighting some of the unaddressed
      issues within this generic framework.", "venue": "arXiv.org", "year": 2019,
      "referenceCount": 37, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Philosophy",
      "source": "s2-fos-model"}, {"category": "Computer Science", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2019-06-26", "journal":
      {"name": "ArXiv", "volume": "abs/1906.11068"}, "citationStyles": {"bibtex":
      "@Article{Ayesh2019TuringTR,\n author = {A. Ayesh},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {Turing Test Revisited: A Framework for an Alternative},\n
      volume = {abs/1906.11068},\n year = {2019}\n}\n"}, "authors": [{"authorId":
      "2886506", "name": "A. Ayesh"}]}, {"paperId": "575a082dd24730dfc1c4bae27cd6fa0142028050",
      "externalIds": {"MAG": "2911479284", "ArXiv": "1901.11090", "DBLP": "journals/corr/abs-1901-11090",
      "CorpusId": 59523756}, "corpusId": 59523756, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/575a082dd24730dfc1c4bae27cd6fa0142028050",
      "title": "Neuroevolution with Perceptron Turing Machines", "abstract": "We introduce
      the perceptron Turing machine and show how it can be used to create a system
      of neuroevolution. Advantages of this approach include automatic scaling of
      solutions to larger problem sizes, the ability to experiment with hand-coded
      solutions, and an enhanced potential for understanding evolved solutions. Hand-coded
      solutions may be implemented in the low-level language of Turing machines, which
      is the genotype used in neuroevolution, but a high-level language called Lopro
      is introduced to make the job easier.", "venue": "arXiv.org", "year": 2019,
      "referenceCount": 8, "citationCount": 0, "influentialCitationCount": 0, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2019-01-30", "journal": {"name": "ArXiv", "volume": "abs/1901.11090"},
      "citationStyles": {"bibtex": "@Article{Landaeta2019NeuroevolutionWP,\n author
      = {D. Landaeta},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Neuroevolution
      with Perceptron Turing Machines},\n volume = {abs/1901.11090},\n year = {2019}\n}\n"},
      "authors": [{"authorId": "1971021", "name": "D. Landaeta"}]}, {"paperId": "c411c1861f4a6048dc1efd038624ba46a80f7b00",
      "externalIds": {"ArXiv": "1907.07767", "MAG": "2959626867", "DBLP": "journals/corr/abs-1907-07767",
      "CorpusId": 197544897}, "corpusId": 197544897, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/c411c1861f4a6048dc1efd038624ba46a80f7b00",
      "title": "Delta - new logic programming language and Delta-methodology for p-computable
      programs on Turing Complete Languages", "abstract": "In paper describes the
      new logic programming language Delta, which have a many good properties. Delta-programs
      is p-computable, verifiable and can translation on other languages. Also we
      describe the Delta-methodology for constructing p-computable programs in high-level
      languages such as PHP, Java, JavaScript, C++, Pascal, Delphi, Python, Solidity
      and other. We would like to especially note the use of the Delta methodology
      for creating Smart Contracts and for Internet of things. We change the concept
      of the formula and define D-formulas(or Delta programs) are special list-formulas.
      Then we define the execution of a program how is the process of checking truth
      D-formula on a dynamic model. Main idea our paper consider program how list-formula
      from another formulas on dynamic models. And we created by iterations new Delta-programs
      use simple base formulas for this. Also we entered a dynamic models how models
      where we save final values of variables when check formula on this model.",
      "venue": "arXiv.org", "year": 2019, "referenceCount": 7, "citationCount": 2,
      "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2019-07-12", "journal": {"name": "ArXiv",
      "volume": "abs/1907.07767"}, "citationStyles": {"bibtex": "@Article{Nechesov2019DeltaN,\n
      author = {A. Nechesov},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title
      = {Delta - new logic programming language and Delta-methodology for p-computable
      programs on Turing Complete Languages},\n volume = {abs/1907.07767},\n year
      = {2019}\n}\n"}, "authors": [{"authorId": "87670088", "name": "A. Nechesov"}]},
      {"paperId": "89f5af9fc5a8d79f89b53886f1ad18804696b70f", "externalIds": {"MAG":
      "2794062168", "DBLP": "journals/corr/abs-1803-04548", "ArXiv": "1803.04548",
      "CorpusId": 3834853}, "corpusId": 3834853, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/89f5af9fc5a8d79f89b53886f1ad18804696b70f",
      "title": "Taking Turing by Surprise? Designing Digital Computers for morally-loaded
      contexts", "abstract": "There is much to learn from what Turing hastily dismissed
      as Lady Lovelace s objection. Digital computers can indeed surprise us. Just
      like a piece of art, algorithms can be designed in such a way as to lead us
      to question our understanding of the world, or our place within it. Some humans
      do lose the capacity to be surprised in that way. It might be fear, or it might
      be the comfort of ideological certainties. As lazy normative animals, we do
      need to be able to rely on authorities to simplify our reasoning: that is ok.
      Yet the growing sophistication of systems designed to free us from the constraints
      of normative engagement may take us past a point of no-return. What if, through
      lack of normative exercise, our moral muscles became so atrophied as to leave
      us unable to question our social practices? This paper makes two distinct normative
      claims: \n1. Decision-support systems should be designed with a view to regularly
      jolting us out of our moral torpor. \n2. Without the depth of habit to somatically
      anchor model certainty, a computer s experience of something new is very different
      from that which in humans gives rise to non-trivial surprises. This asymmetry
      has key repercussions when it comes to the shape of ethical agency in artificial
      moral agents. The worry is not just that they would be likely to leap morally
      ahead of us, unencumbered by habits. The main reason to doubt that the moral
      trajectories of humans v. autonomous systems might remain compatible stems from
      the asymmetry in the mechanisms underlying moral change. Whereas in humans surprises
      will continue to play an important role in waking us to the need for moral change,
      cognitive processes will rule when it comes to machines. This asymmetry will
      translate into increasingly different moral outlooks, to the point of likely
      unintelligibility. The latter prospect is enough to doubt the desirability of
      autonomous moral agents.", "venue": "arXiv.org", "year": 2018, "referenceCount":
      40, "citationCount": 4, "influentialCitationCount": 1, "isOpenAccess": false,
      "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}, {"category": "Philosophy", "source": "s2-fos-model"}],
      "publicationTypes": ["JournalArticle"], "publicationDate": "2018-03-12", "journal":
      {"name": "ArXiv", "volume": "abs/1803.04548"}, "citationStyles": {"bibtex":
      "@Article{Delacroix2018TakingTB,\n author = {S. Delacroix},\n booktitle = {arXiv.org},\n
      journal = {ArXiv},\n title = {Taking Turing by Surprise? Designing Digital Computers
      for morally-loaded contexts},\n volume = {abs/1803.04548},\n year = {2018}\n}\n"},
      "authors": [{"authorId": "8288362", "name": "S. Delacroix"}]}, {"paperId": "45c182f8d003a2d505e4d1d491b5d03159a70b81",
      "externalIds": {"ArXiv": "1810.10948", "MAG": "2898148404", "DBLP": "journals/corr/abs-1810-10948",
      "CorpusId": 53032549}, "corpusId": 53032549, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/45c182f8d003a2d505e4d1d491b5d03159a70b81",
      "title": "Training Generative Adversarial Networks Via Turing Test", "abstract":
      "In this article, we introduce a new mode for training Generative Adversarial
      Networks (GANs). Rather than minimizing the distance of evidence distribution
      $\\tilde{p}(x)$ and the generative distribution $q(x)$, we minimize the distance
      of $\\tilde{p}(x_r)q(x_f)$ and $\\tilde{p}(x_f)q(x_r)$. This adversarial pattern
      can be interpreted as a Turing test in GANs. It allows us to use information
      of real samples during training generator and accelerates the whole training
      procedure. We even find that just proportionally increasing the size of discriminator
      and generator, it succeeds on 256x256 resolution without adjusting hyperparameters
      carefully.", "venue": "arXiv.org", "year": 2018, "referenceCount": 15, "citationCount":
      5, "influentialCitationCount": 1, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Mathematics", "Computer Science"], "s2FieldsOfStudy": [{"category":
      "Mathematics", "source": "external"}, {"category": "Computer Science", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2018-10-25", "journal": {"name": "ArXiv",
      "volume": "abs/1810.10948"}, "citationStyles": {"bibtex": "@Article{Su2018TrainingGA,\n
      author = {Jianlin Su},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title
      = {Training Generative Adversarial Networks Via Turing Test},\n volume = {abs/1810.10948},\n
      year = {2018}\n}\n"}, "authors": [{"authorId": "51111230", "name": "Jianlin
      Su"}]}, {"paperId": "f963ad52f13e7edae84743e31381fff5b77bede5", "externalIds":
      {"DBLP": "journals/corr/abs-1711-08819", "MAG": "2768376195", "ArXiv": "1711.08819",
      "CorpusId": 583148}, "corpusId": 583148, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/f963ad52f13e7edae84743e31381fff5b77bede5",
      "title": "Improvised Comedy as a Turing Test", "abstract": "The best improvisational
      theatre actors can make any scene partner, of any skill level or ability, appear
      talented and proficient in the art form, and thus \"make them shine\". To challenge
      this improvisational paradigm, we built an artificial intelligence (AI) trained
      to perform live shows alongside human actors for human audiences. Over the course
      of 30 performances to a combined audience of almost 3000 people, we have refined
      theatrical games which involve combinations of human and (at times, adversarial)
      AI actors. We have developed specific scene structures to include audience participants
      in interesting ways. Finally, we developed a complete show structure that submitted
      the audience to a Turing test and observed their suspension of disbelief, which
      we believe is key for human/non-human theatre co-creation.", "venue": "arXiv.org",
      "year": 2017, "referenceCount": 10, "citationCount": 13, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Art", "source": "s2-fos-model"}, {"category": "Computer Science",
      "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2017-11-23", "journal": {"name": "ArXiv", "volume": "abs/1711.08819"}, "citationStyles":
      {"bibtex": "@Article{Mathewson2017ImprovisedCA,\n author = {K. Mathewson and
      Piotr Wojciech Mirowski},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Improvised Comedy as a Turing Test},\n volume = {abs/1711.08819},\n
      year = {2017}\n}\n"}, "authors": [{"authorId": "3422828", "name": "K. Mathewson"},
      {"authorId": "144705062", "name": "Piotr Wojciech Mirowski"}]}, {"paperId":
      "c4a343d017569129c57e0f3dbb383d56cbf85707", "externalIds": {"ArXiv": "1904.09163",
      "MAG": "2939115675", "DBLP": "journals/corr/abs-1904-09163", "CorpusId": 126166939},
      "corpusId": 126166939, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/c4a343d017569129c57e0f3dbb383d56cbf85707",
      "title": "Transfer Entropy: where Shannon meets Turing", "abstract": "Transfer
      entropy is capable of capturing nonlinear source-destination relations between
      multi-variate time series. It is a measure of association between source data
      that are transformed into destination data via a set of linear transformations
      between their probability mass functions. The resulting tensor formalism is
      used to show that in specific cases, e.g., in the case the system consists of
      three stochastic processes, bivariate analysis suffices to distinguish true
      relations from false relations. This allows us to determine the causal structure
      as far as encoded in the probability mass functions of noisy data. The tensor
      formalism was also used to derive the Data Processing Inequality for transfer
      entropy.", "venue": "arXiv.org", "year": 2019, "referenceCount": 13, "citationCount":
      0, "influentialCitationCount": 0, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science", "Mathematics"], "s2FieldsOfStudy": [{"category":
      "Computer Science", "source": "external"}, {"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "s2-fos-model"}, {"category":
      "Mathematics", "source": "s2-fos-model"}, {"category": "Physics", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2019-04-19", "journal": {"name": "ArXiv", "volume": "abs/1904.09163"}, "citationStyles":
      {"bibtex": "@Article{Sigtermans2019TransferEW,\n author = {David Sigtermans},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Transfer Entropy: where
      Shannon meets Turing},\n volume = {abs/1904.09163},\n year = {2019}\n}\n"},
      "authors": [{"authorId": "104300595", "name": "David Sigtermans"}]}, {"paperId":
      "3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9", "externalIds": {"ArXiv": "1410.8027",
      "MAG": "300525892", "DBLP": "journals/corr/MalinowskiF14a", "CorpusId": 811868},
      "corpusId": 811868, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9",
      "title": "Towards a Visual Turing Challenge", "abstract": "As language and visual
      understanding by machines progresses rapidly, we are observing an increasing
      interest in holistic architectures that tightly interlink both modalities in
      a joint learning and inference process. This trend has allowed the community
      to progress towards more challenging and open tasks and refueled the hope at
      achieving the old AI dream of building machines that could pass a turing test
      in open domains. In order to steadily make progress towards this goal, we realize
      that quantifying performance becomes increasingly difficult. Therefore we ask
      how we can precisely define such challenges and how we can evaluate different
      algorithms on this open tasks? In this paper, we summarize and discuss such
      challenges as well as try to give answers where appropriate options are available
      in the literature. We exemplify some of the solutions on a recently presented
      dataset of question-answering task based on real-world indoor images that establishes
      a visual turing challenge. Finally, we argue despite the success of unique ground-truth
      annotation, we likely have to step away from carefully curated dataset and rather
      rely on ''social consensus'' as the main driving force to create suitable benchmarks.
      Providing coverage in this inherently ambiguous output space is an emerging
      challenge that we face in order to make quantifiable progress in this area.",
      "venue": "arXiv.org", "year": 2014, "referenceCount": 64, "citationCount": 70,
      "influentialCitationCount": 10, "isOpenAccess": false, "openAccessPdf": null,
      "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy": [{"category": "Computer
      Science", "source": "external"}, {"category": "Computer Science", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2014-10-29", "journal": {"name": "ArXiv", "volume": "abs/1410.8027"}, "citationStyles":
      {"bibtex": "@Article{Malinowski2014TowardsAV,\n author = {Mateusz Malinowski
      and Mario Fritz},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title =
      {Towards a Visual Turing Challenge},\n volume = {abs/1410.8027},\n year = {2014}\n}\n"},
      "authors": [{"authorId": "145478807", "name": "Mateusz Malinowski"}, {"authorId":
      "1739548", "name": "Mario Fritz"}]}, {"paperId": "f19795ca9798adbf1ee6928add55e8c2438f8a32",
      "externalIds": {"ArXiv": "1803.10648", "MAG": "2795355335", "DBLP": "journals/corr/abs-1803-10648",
      "CorpusId": 4392393}, "corpusId": 4392393, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/f19795ca9798adbf1ee6928add55e8c2438f8a32",
      "title": "A Distributed Extension of the Turing Machine", "abstract": "The Turing
      Machine has two implicit properties that depend on its underlying notion of
      computing: the format is fully determinate and computations are information
      preserving. Distributed representations lack these properties and cannot be
      fully captured by Turing''s standard model. To address this limitation a distributed
      extension of the Turing Machine is introduced in this paper. In the extended
      machine, functions and abstractions are expressed extensionally and computations
      are entropic. The machine is applied to the definition of an associative memory,
      with its corresponding memory register, recognition and retrieval operations.
      The memory is tested with an experiment for storing and recognizing hand written
      digits with satisfactory results. The experiment can be seen as a proof of concept
      that information can be stored and processed effectively in a highly distributed
      fashion using a symbolic but not fully determinate format. The new machine augments
      the symbolic mode of computing with consequences on the way Church Thesis is
      understood. The paper is concluded with a discussion of some implications of
      the extended machine for Artificial Intelligence and Cognition.", "venue": "arXiv.org",
      "year": 2018, "referenceCount": 50, "citationCount": 2, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2018-03-28", "journal": {"name": "ArXiv",
      "volume": "abs/1803.10648"}, "citationStyles": {"bibtex": "@Article{Pineda2018ADE,\n
      author = {L. Pineda},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title
      = {A Distributed Extension of the Turing Machine},\n volume = {abs/1803.10648},\n
      year = {2018}\n}\n"}, "authors": [{"authorId": "144014054", "name": "L. Pineda"}]},
      {"paperId": "4a4b5c8511f7a2a26f5847437d9fcdcf4a72c0f4", "externalIds": {"MAG":
      "2765789270", "DBLP": "journals/corr/abs-1710-04748", "ArXiv": "1710.04748",
      "CorpusId": 3784100}, "corpusId": 3784100, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/4a4b5c8511f7a2a26f5847437d9fcdcf4a72c0f4",
      "title": "HyperENTM: Evolving Scalable Neural Turing Machines through HyperNEAT",
      "abstract": "Recent developments within memory-augmented neural networks have
      solved sequential problems requiring long-term memory, which are intractable
      for traditional neural networks. However, current approaches still struggle
      to scale to large memory sizes and sequence lengths. In this paper we show how
      access to memory can be encoded geometrically through a HyperNEAT-based Neural
      Turing Machine (HyperENTM). We demonstrate that using the indirect HyperNEAT
      encoding allows for training on small memory vectors in a bit-vector copy task
      and then applying the knowledge gained from such training to speed up training
      on larger size memory vectors. Additionally, we demonstrate that in some instances,
      networks trained to copy bit-vectors of size 9 can be scaled to sizes of 1,000
      without further training. While the task in this paper is simple, these results
      could open up the problems amendable to networks with external memories to problems
      with larger memory vectors and theoretically unbounded memory sizes.", "venue":
      "arXiv.org", "year": 2017, "referenceCount": 23, "citationCount": 9, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science"], "s2FieldsOfStudy": [{"category": "Computer Science", "source": "external"},
      {"category": "Computer Science", "source": "s2-fos-model"}], "publicationTypes":
      ["JournalArticle"], "publicationDate": "2017-10-12", "journal": {"name": "ArXiv",
      "volume": "abs/1710.04748"}, "citationStyles": {"bibtex": "@Article{Merrild2017HyperENTMES,\n
      author = {Jakob Merrild and Mikkel Angaju Rasmussen and S. Risi},\n booktitle
      = {arXiv.org},\n journal = {ArXiv},\n title = {HyperENTM: Evolving Scalable
      Neural Turing Machines through HyperNEAT},\n volume = {abs/1710.04748},\n year
      = {2017}\n}\n"}, "authors": [{"authorId": "27635664", "name": "Jakob Merrild"},
      {"authorId": "2066553523", "name": "Mikkel Angaju Rasmussen"}, {"authorId":
      "1745664", "name": "S. Risi"}]}, {"paperId": "c86d6f344e4cf62af216bea8d51ad500bf9edfd4",
      "externalIds": {"MAG": "2290588870", "ArXiv": "1602.08671", "DBLP": "journals/corr/Yang16",
      "CorpusId": 9152132}, "corpusId": 9152132, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/c86d6f344e4cf62af216bea8d51ad500bf9edfd4",
      "title": "Lie Access Neural Turing Machine", "abstract": "Following the recent
      trend in explicit neural memory structures, we present a new design of an external
      memory, wherein memories are stored in an Euclidean key space $\\mathbb R^n$.
      An LSTM controller performs read and write via specialized read and write heads.
      It can move a head by either providing a new address in the key space (aka random
      access) or moving from its previous position via a Lie group action (aka Lie
      access). In this way, the \"L\" and \"R\" instructions of a traditional Turing
      Machine are generalized to arbitrary elements of a fixed Lie group action. For
      this reason, we name this new model the Lie Access Neural Turing Machine, or
      LANTM. \nWe tested two different configurations of LANTM against an LSTM baseline
      in several basic experiments. We found the right configuration of LANTM to outperform
      the baseline in all of our experiments. In particular, we trained LANTM on addition
      of $k$-digit numbers for $2 \\le k \\le 16$, but it was able to generalize almost
      perfectly to $17 \\le k \\le 32$, all with the number of parameters 2 orders
      of magnitude below the LSTM baseline.", "venue": "arXiv.org", "year": 2016,
      "referenceCount": 35, "citationCount": 14, "influentialCitationCount": 2, "isOpenAccess":
      false, "openAccessPdf": null, "fieldsOfStudy": ["Computer Science"], "s2FieldsOfStudy":
      [{"category": "Computer Science", "source": "external"}, {"category": "Computer
      Science", "source": "s2-fos-model"}], "publicationTypes": ["JournalArticle"],
      "publicationDate": "2016-02-28", "journal": {"name": "ArXiv", "volume": "abs/1602.08671"},
      "citationStyles": {"bibtex": "@Article{Yang2016LieAN,\n author = {Greg Yang},\n
      booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Lie Access Neural Turing
      Machine},\n volume = {abs/1602.08671},\n year = {2016}\n}\n"}, "authors": [{"authorId":
      "35064203", "name": "Greg Yang"}]}, {"paperId": "b71ee76a1fd357aeacad7768aa9c8528d2611783",
      "externalIds": {"MAG": "2788996312", "DBLP": "journals/corr/abs-1802-05734",
      "CorpusId": 59158844}, "corpusId": 59158844, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/b71ee76a1fd357aeacad7768aa9c8528d2611783",
      "title": "Writability and reachability for alpha-tape infinite time Turing machines",
      "abstract": "Infinite time Turing machines with tape length $\\alpha$ (denoted
      $T_\\alpha$) were introduced by Rin to strengthen the $\\omega$-tape machines
      of Hamkins and Kidder. It is known that for some countable ordinals $\\alpha$,
      these machines'' properties are quite different from those of the $\\omega$-tape
      case. We answer a question of Rin about the size of the least ordinal $\\delta$
      such that not all cells are halting positions of $T_\\delta$ by giving various
      characterizations of $\\delta$. For instance, it is the least ordinal with any
      of the properties (a) there is a $T_\\alpha$-writable real that is not $T_\\delta$-writable
      for some $\\alpha<\\delta$, (b) $\\delta$ is uncountable in $L_{\\lambda_\\delta}$,
      or (c) $\\delta$ is a regular cardinal in $L_{\\lambda_\\delta}$, where $\\lambda_\\delta$
      denotes the supremum of ordinals with a $T_\\delta$-writable code of length
      $\\delta$. We further use these characterizations together with an analogue
      to Welch''s submodel characterization of the ordinals $\\lambda$, $\\zeta$ and
      $\\Sigma$, to show that $\\delta$ is closed under the function $\\alpha \\mapsto
      \\Sigma_\\alpha$, where $\\Sigma_\\alpha$ denotes the supremum of the ordinals
      with a $T_\\alpha$-accidentally writable code of length $\\alpha$.", "venue":
      "arXiv.org", "year": 2018, "referenceCount": 10, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Computer
      Science", "Mathematics"], "s2FieldsOfStudy": [{"category": "Computer Science",
      "source": "external"}, {"category": "Mathematics", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2018-02-15", "journal": {"name": "ArXiv", "volume": "abs/1802.05734"}, "citationStyles":
      {"bibtex": "@Article{Carl2018WritabilityAR,\n author = {M. Carl and Benjamin
      G. Rin and Philipp Schlicht},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n
      title = {Writability and reachability for alpha-tape infinite time Turing machines},\n
      volume = {abs/1802.05734},\n year = {2018}\n}\n"}, "authors": [{"authorId":
      "2618125", "name": "M. Carl"}, {"authorId": "1838366", "name": "Benjamin G.
      Rin"}, {"authorId": "2268646", "name": "Philipp Schlicht"}]}, {"paperId": "6d4553d571939763e585b2dfbf8129b2d3f38c44",
      "externalIds": {"ArXiv": "1807.02287", "MAG": "2814812544", "DBLP": "journals/corr/abs-1807-02287",
      "CorpusId": 49654281}, "corpusId": 49654281, "publicationVenue": {"id": "1901e811-ee72-4b20-8f7e-de08cd395a10",
      "name": "arXiv.org", "alternate_names": ["ArXiv"], "issn": "2331-8422", "url":
      "https://arxiv.org"}, "url": "https://www.semanticscholar.org/paper/6d4553d571939763e585b2dfbf8129b2d3f38c44",
      "title": "Outperforming Good-Turing: Preliminary Report", "abstract": "Estimating
      a large alphabet probability distribution from a limited number of samples is
      a fundamental problem in machine learning and statistics. A variety of estimation
      schemes have been proposed over the years, mostly inspired by the early work
      of Laplace and the seminal contribution of Good and Turing. One of the basic
      assumptions shared by most commonly-used estimators is the unique correspondence
      between the symbol''s sample frequency and its estimated probability. In this
      work we tackle this paradigmatic assumption; we claim that symbols with \"similar\"
      frequencies shall be assigned the same estimated probability value. This way
      we regulate the number of parameters and improve generalization. In this preliminary
      report we show that by applying an ensemble of such regulated estimators, we
      introduce a dramatic enhancement in the estimation accuracy (typically up to
      50%), compared to currently known methods. An implementation of our suggested
      method is publicly available at the first author''s web-page.", "venue": "arXiv.org",
      "year": 2018, "referenceCount": 13, "citationCount": 0, "influentialCitationCount":
      0, "isOpenAccess": false, "openAccessPdf": null, "fieldsOfStudy": ["Mathematics",
      "Computer Science"], "s2FieldsOfStudy": [{"category": "Mathematics", "source":
      "external"}, {"category": "Computer Science", "source": "external"}, {"category":
      "Computer Science", "source": "s2-fos-model"}, {"category": "Mathematics", "source":
      "s2-fos-model"}], "publicationTypes": ["JournalArticle"], "publicationDate":
      "2018-07-06", "journal": {"name": "ArXiv", "volume": "abs/1807.02287"}, "citationStyles":
      {"bibtex": "@Article{Painsky2018OutperformingGP,\n author = {Amichai Painsky
      and M. Feder},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Outperforming
      Good-Turing: Preliminary Report},\n volume = {abs/1807.02287},\n year = {2018}\n}\n"},
      "authors": [{"authorId": "3092268", "name": "Amichai Painsky"}, {"authorId":
      "144519810", "name": "M. Feder"}]}]}

      '
    headers:
      Access-Control-Allow-Origin:
      - '*'
      Connection:
      - keep-alive
      Content-Length:
      - '250008'
      Content-Type:
      - application/json
      Date:
      - Wed, 27 Dec 2023 21:57:10 GMT
      Via:
      - 1.1 1ca987d140ec07a0ce579c056163edaa.cloudfront.net (CloudFront)
      X-Amz-Cf-Id:
      - fS5K3mzNAJHPiXxX_-jISSmnmgE-0dKwD47SIhbQgPvdpw3ULZ-ZvQ==
      X-Amz-Cf-Pop:
      - GRU3-P4
      X-Cache:
      - Miss from cloudfront
      x-amz-apigw-id:
      - Qn2UfFQivHcEemw=
      x-amzn-Remapped-Connection:
      - keep-alive
      x-amzn-Remapped-Content-Length:
      - '250008'
      x-amzn-Remapped-Date:
      - Wed, 27 Dec 2023 21:57:10 GMT
      x-amzn-Remapped-Server:
      - gunicorn
      x-amzn-RequestId:
      - 3af01b0f-a2e2-414f-9760-b98b8103ecf1
    http_version: HTTP/1.1
    status_code: 200
version: 1
